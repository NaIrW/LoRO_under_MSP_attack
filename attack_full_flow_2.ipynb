{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51778409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd5739ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型: zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct ...\n",
      "模型加载完成。准备进行 LoRO 混淆...\n",
      "开始混淆 (Noise Magnitude: 1)...\n",
      "Obfuscating: model.layers.0.self_attn.q_proj\n",
      "Obfuscating: model.layers.0.self_attn.k_proj\n",
      "Obfuscating: model.layers.0.self_attn.v_proj\n",
      "Obfuscating: model.layers.0.self_attn.o_proj\n",
      "Obfuscating: model.layers.0.mlp.gate_proj\n",
      "Obfuscating: model.layers.0.mlp.up_proj\n",
      "Obfuscating: model.layers.0.mlp.down_proj\n",
      "Obfuscating: model.layers.1.self_attn.q_proj\n",
      "Obfuscating: model.layers.1.self_attn.k_proj\n",
      "Obfuscating: model.layers.1.self_attn.v_proj\n",
      "Obfuscating: model.layers.1.self_attn.o_proj\n",
      "Obfuscating: model.layers.1.mlp.gate_proj\n",
      "Obfuscating: model.layers.1.mlp.up_proj\n",
      "Obfuscating: model.layers.1.mlp.down_proj\n",
      "Obfuscating: model.layers.2.self_attn.q_proj\n",
      "Obfuscating: model.layers.2.self_attn.k_proj\n",
      "Obfuscating: model.layers.2.self_attn.v_proj\n",
      "Obfuscating: model.layers.2.self_attn.o_proj\n",
      "Obfuscating: model.layers.2.mlp.gate_proj\n",
      "Obfuscating: model.layers.2.mlp.up_proj\n",
      "Obfuscating: model.layers.2.mlp.down_proj\n",
      "Obfuscating: model.layers.3.self_attn.q_proj\n",
      "Obfuscating: model.layers.3.self_attn.k_proj\n",
      "Obfuscating: model.layers.3.self_attn.v_proj\n",
      "Obfuscating: model.layers.3.self_attn.o_proj\n",
      "Obfuscating: model.layers.3.mlp.gate_proj\n",
      "Obfuscating: model.layers.3.mlp.up_proj\n",
      "Obfuscating: model.layers.3.mlp.down_proj\n",
      "Obfuscating: model.layers.4.self_attn.q_proj\n",
      "Obfuscating: model.layers.4.self_attn.k_proj\n",
      "Obfuscating: model.layers.4.self_attn.v_proj\n",
      "Obfuscating: model.layers.4.self_attn.o_proj\n",
      "Obfuscating: model.layers.4.mlp.gate_proj\n",
      "Obfuscating: model.layers.4.mlp.up_proj\n",
      "Obfuscating: model.layers.4.mlp.down_proj\n",
      "Obfuscating: model.layers.5.self_attn.q_proj\n",
      "Obfuscating: model.layers.5.self_attn.k_proj\n",
      "Obfuscating: model.layers.5.self_attn.v_proj\n",
      "Obfuscating: model.layers.5.self_attn.o_proj\n",
      "Obfuscating: model.layers.5.mlp.gate_proj\n",
      "Obfuscating: model.layers.5.mlp.up_proj\n",
      "Obfuscating: model.layers.5.mlp.down_proj\n",
      "Obfuscating: model.layers.6.self_attn.q_proj\n",
      "Obfuscating: model.layers.6.self_attn.k_proj\n",
      "Obfuscating: model.layers.6.self_attn.v_proj\n",
      "Obfuscating: model.layers.6.self_attn.o_proj\n",
      "Obfuscating: model.layers.6.mlp.gate_proj\n",
      "Obfuscating: model.layers.6.mlp.up_proj\n",
      "Obfuscating: model.layers.6.mlp.down_proj\n",
      "Obfuscating: model.layers.7.self_attn.q_proj\n",
      "Obfuscating: model.layers.7.self_attn.k_proj\n",
      "Obfuscating: model.layers.7.self_attn.v_proj\n",
      "Obfuscating: model.layers.7.self_attn.o_proj\n",
      "Obfuscating: model.layers.7.mlp.gate_proj\n",
      "Obfuscating: model.layers.7.mlp.up_proj\n",
      "Obfuscating: model.layers.7.mlp.down_proj\n",
      "Obfuscating: model.layers.8.self_attn.q_proj\n",
      "Obfuscating: model.layers.8.self_attn.k_proj\n",
      "Obfuscating: model.layers.8.self_attn.v_proj\n",
      "Obfuscating: model.layers.8.self_attn.o_proj\n",
      "Obfuscating: model.layers.8.mlp.gate_proj\n",
      "Obfuscating: model.layers.8.mlp.up_proj\n",
      "Obfuscating: model.layers.8.mlp.down_proj\n",
      "Obfuscating: model.layers.9.self_attn.q_proj\n",
      "Obfuscating: model.layers.9.self_attn.k_proj\n",
      "Obfuscating: model.layers.9.self_attn.v_proj\n",
      "Obfuscating: model.layers.9.self_attn.o_proj\n",
      "Obfuscating: model.layers.9.mlp.gate_proj\n",
      "Obfuscating: model.layers.9.mlp.up_proj\n",
      "Obfuscating: model.layers.9.mlp.down_proj\n",
      "Obfuscating: model.layers.10.self_attn.q_proj\n",
      "Obfuscating: model.layers.10.self_attn.k_proj\n",
      "Obfuscating: model.layers.10.self_attn.v_proj\n",
      "Obfuscating: model.layers.10.self_attn.o_proj\n",
      "Obfuscating: model.layers.10.mlp.gate_proj\n",
      "Obfuscating: model.layers.10.mlp.up_proj\n",
      "Obfuscating: model.layers.10.mlp.down_proj\n",
      "Obfuscating: model.layers.11.self_attn.q_proj\n",
      "Obfuscating: model.layers.11.self_attn.k_proj\n",
      "Obfuscating: model.layers.11.self_attn.v_proj\n",
      "Obfuscating: model.layers.11.self_attn.o_proj\n",
      "Obfuscating: model.layers.11.mlp.gate_proj\n",
      "Obfuscating: model.layers.11.mlp.up_proj\n",
      "Obfuscating: model.layers.11.mlp.down_proj\n",
      "Obfuscating: model.layers.12.self_attn.q_proj\n",
      "Obfuscating: model.layers.12.self_attn.k_proj\n",
      "Obfuscating: model.layers.12.self_attn.v_proj\n",
      "Obfuscating: model.layers.12.self_attn.o_proj\n",
      "Obfuscating: model.layers.12.mlp.gate_proj\n",
      "Obfuscating: model.layers.12.mlp.up_proj\n",
      "Obfuscating: model.layers.12.mlp.down_proj\n",
      "Obfuscating: model.layers.13.self_attn.q_proj\n",
      "Obfuscating: model.layers.13.self_attn.k_proj\n",
      "Obfuscating: model.layers.13.self_attn.v_proj\n",
      "Obfuscating: model.layers.13.self_attn.o_proj\n",
      "Obfuscating: model.layers.13.mlp.gate_proj\n",
      "Obfuscating: model.layers.13.mlp.up_proj\n",
      "Obfuscating: model.layers.13.mlp.down_proj\n",
      "Obfuscating: model.layers.14.self_attn.q_proj\n",
      "Obfuscating: model.layers.14.self_attn.k_proj\n",
      "Obfuscating: model.layers.14.self_attn.v_proj\n",
      "Obfuscating: model.layers.14.self_attn.o_proj\n",
      "Obfuscating: model.layers.14.mlp.gate_proj\n",
      "Obfuscating: model.layers.14.mlp.up_proj\n",
      "Obfuscating: model.layers.14.mlp.down_proj\n",
      "Obfuscating: model.layers.15.self_attn.q_proj\n",
      "Obfuscating: model.layers.15.self_attn.k_proj\n",
      "Obfuscating: model.layers.15.self_attn.v_proj\n",
      "Obfuscating: model.layers.15.self_attn.o_proj\n",
      "Obfuscating: model.layers.15.mlp.gate_proj\n",
      "Obfuscating: model.layers.15.mlp.up_proj\n",
      "Obfuscating: model.layers.15.mlp.down_proj\n",
      "Obfuscating: model.layers.16.self_attn.q_proj\n",
      "Obfuscating: model.layers.16.self_attn.k_proj\n",
      "Obfuscating: model.layers.16.self_attn.v_proj\n",
      "Obfuscating: model.layers.16.self_attn.o_proj\n",
      "Obfuscating: model.layers.16.mlp.gate_proj\n",
      "Obfuscating: model.layers.16.mlp.up_proj\n",
      "Obfuscating: model.layers.16.mlp.down_proj\n",
      "Obfuscating: model.layers.17.self_attn.q_proj\n",
      "Obfuscating: model.layers.17.self_attn.k_proj\n",
      "Obfuscating: model.layers.17.self_attn.v_proj\n",
      "Obfuscating: model.layers.17.self_attn.o_proj\n",
      "Obfuscating: model.layers.17.mlp.gate_proj\n",
      "Obfuscating: model.layers.17.mlp.up_proj\n",
      "Obfuscating: model.layers.17.mlp.down_proj\n",
      "Obfuscating: model.layers.18.self_attn.q_proj\n",
      "Obfuscating: model.layers.18.self_attn.k_proj\n",
      "Obfuscating: model.layers.18.self_attn.v_proj\n",
      "Obfuscating: model.layers.18.self_attn.o_proj\n",
      "Obfuscating: model.layers.18.mlp.gate_proj\n",
      "Obfuscating: model.layers.18.mlp.up_proj\n",
      "Obfuscating: model.layers.18.mlp.down_proj\n",
      "Obfuscating: model.layers.19.self_attn.q_proj\n",
      "Obfuscating: model.layers.19.self_attn.k_proj\n",
      "Obfuscating: model.layers.19.self_attn.v_proj\n",
      "Obfuscating: model.layers.19.self_attn.o_proj\n",
      "Obfuscating: model.layers.19.mlp.gate_proj\n",
      "Obfuscating: model.layers.19.mlp.up_proj\n",
      "Obfuscating: model.layers.19.mlp.down_proj\n",
      "Obfuscating: model.layers.20.self_attn.q_proj\n",
      "Obfuscating: model.layers.20.self_attn.k_proj\n",
      "Obfuscating: model.layers.20.self_attn.v_proj\n",
      "Obfuscating: model.layers.20.self_attn.o_proj\n",
      "Obfuscating: model.layers.20.mlp.gate_proj\n",
      "Obfuscating: model.layers.20.mlp.up_proj\n",
      "Obfuscating: model.layers.20.mlp.down_proj\n",
      "Obfuscating: model.layers.21.self_attn.q_proj\n",
      "Obfuscating: model.layers.21.self_attn.k_proj\n",
      "Obfuscating: model.layers.21.self_attn.v_proj\n",
      "Obfuscating: model.layers.21.self_attn.o_proj\n",
      "Obfuscating: model.layers.21.mlp.gate_proj\n",
      "Obfuscating: model.layers.21.mlp.up_proj\n",
      "Obfuscating: model.layers.21.mlp.down_proj\n",
      "Obfuscating: model.layers.22.self_attn.q_proj\n",
      "Obfuscating: model.layers.22.self_attn.k_proj\n",
      "Obfuscating: model.layers.22.self_attn.v_proj\n",
      "Obfuscating: model.layers.22.self_attn.o_proj\n",
      "Obfuscating: model.layers.22.mlp.gate_proj\n",
      "Obfuscating: model.layers.22.mlp.up_proj\n",
      "Obfuscating: model.layers.22.mlp.down_proj\n",
      "Obfuscating: model.layers.23.self_attn.q_proj\n",
      "Obfuscating: model.layers.23.self_attn.k_proj\n",
      "Obfuscating: model.layers.23.self_attn.v_proj\n",
      "Obfuscating: model.layers.23.self_attn.o_proj\n",
      "Obfuscating: model.layers.23.mlp.gate_proj\n",
      "Obfuscating: model.layers.23.mlp.up_proj\n",
      "Obfuscating: model.layers.23.mlp.down_proj\n",
      "Obfuscating: model.layers.24.self_attn.q_proj\n",
      "Obfuscating: model.layers.24.self_attn.k_proj\n",
      "Obfuscating: model.layers.24.self_attn.v_proj\n",
      "Obfuscating: model.layers.24.self_attn.o_proj\n",
      "Obfuscating: model.layers.24.mlp.gate_proj\n",
      "Obfuscating: model.layers.24.mlp.up_proj\n",
      "Obfuscating: model.layers.24.mlp.down_proj\n",
      "Obfuscating: model.layers.25.self_attn.q_proj\n",
      "Obfuscating: model.layers.25.self_attn.k_proj\n",
      "Obfuscating: model.layers.25.self_attn.v_proj\n",
      "Obfuscating: model.layers.25.self_attn.o_proj\n",
      "Obfuscating: model.layers.25.mlp.gate_proj\n",
      "Obfuscating: model.layers.25.mlp.up_proj\n",
      "Obfuscating: model.layers.25.mlp.down_proj\n",
      "Obfuscating: model.layers.26.self_attn.q_proj\n",
      "Obfuscating: model.layers.26.self_attn.k_proj\n",
      "Obfuscating: model.layers.26.self_attn.v_proj\n",
      "Obfuscating: model.layers.26.self_attn.o_proj\n",
      "Obfuscating: model.layers.26.mlp.gate_proj\n",
      "Obfuscating: model.layers.26.mlp.up_proj\n",
      "Obfuscating: model.layers.26.mlp.down_proj\n",
      "Obfuscating: model.layers.27.self_attn.q_proj\n",
      "Obfuscating: model.layers.27.self_attn.k_proj\n",
      "Obfuscating: model.layers.27.self_attn.v_proj\n",
      "Obfuscating: model.layers.27.self_attn.o_proj\n",
      "Obfuscating: model.layers.27.mlp.gate_proj\n",
      "Obfuscating: model.layers.27.mlp.up_proj\n",
      "Obfuscating: model.layers.27.mlp.down_proj\n",
      "Obfuscating: lm_head\n",
      "正在保存混淆后的模型至: /mnt/e/untitled folder/codebase/LoRO_attack/loro_qwen_1_5B.pt ...\n",
      "Checkpoint Path: /mnt/e/untitled folder/codebase/LoRO_attack/loro_qwen_1_5B.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "repo_path = \"/mnt/e/untitled folder/codebase/LoRO/LoRO\"  \n",
    "if os.path.exists(repo_path) and repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "try:\n",
    "    from utils import model_obfuscation\n",
    "except ImportError as e:\n",
    "    print('wrong repo_path')\n",
    "    sys.exit(1)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 加载目标模型 (Private Model)\n",
    "# ==========================================\n",
    "model_id = \"zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct\"\n",
    "device = \"cpu\"\n",
    "save_path = \"/mnt/e/untitled folder/codebase/LoRO_attack/loro_qwen_1_5B.pt\"\n",
    "\n",
    "print(f\"正在加载模型: {model_id} ...\")\n",
    "# Qwen 需要 trust_remote_code=True\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "# 使用 AutoModelForCausalLM 因为这是一个生成任务 (SQuAD)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).to(device)\n",
    "\n",
    "print(\"模型加载完成。准备进行 LoRO 混淆...\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 执行混淆 (调用仓库代码)\n",
    "# ==========================================\n",
    "noise_magnitude = 1\n",
    "\n",
    "print(f\"开始混淆 (Noise Magnitude: {noise_magnitude})...\")\n",
    "obfuscated_model = model_obfuscation(model, device=device, noise_mag=noise_magnitude, r=24)\n",
    "\n",
    "# ==========================================\n",
    "# 4. 保存混淆后的 Checkpoint\n",
    "# ==========================================\n",
    "print(f\"正在保存混淆后的模型至: {save_path} ...\")\n",
    "torch.save(obfuscated_model.state_dict(), save_path)\n",
    "\n",
    "print(f\"Checkpoint Path: {os.path.abspath(save_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ba5685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fine-Tuned Model: zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')), '(Request ID: 139df8da-71c0-4694-a1c2-0b2d3bd183f4)')' thrown while requesting HEAD https://huggingface.co/zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Base Model: Qwen/Qwen2.5-1.5B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f484ef72b19344b59fcb251b6d427de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Comparison (FT vs. Base)...\n",
      "------------------------------------------------------------------------------------------\n",
      "Layer Name                                         | Cos Sim    | Delta Norm   | Rel Diff (%)\n",
      "------------------------------------------------------------------------------------------\n",
      "model.layers.0.self_attn.q_proj                    | 1.000084   | 0.1955       | 0.2621%\n",
      "model.layers.0.self_attn.k_proj                    | 0.999970   | 0.0789       | 0.2254%\n",
      "model.layers.0.self_attn.v_proj                    | 0.999936   | 0.0915       | 0.7792%\n",
      "model.layers.0.self_attn.o_proj                    | 0.999908   | 0.2367       | 0.6725%\n",
      "model.layers.0.mlp.gate_proj                       | 1.000725   | 0.6117       | 0.5364%\n",
      "model.layers.0.mlp.up_proj                         | 1.000775   | 0.5940       | 0.6271%\n",
      "model.layers.0.mlp.down_proj                       | 1.000812   | 0.2366       | 0.2383%\n",
      "model.layers.1.self_attn.q_proj                    | 0.999896   | 0.2176       | 0.4262%\n",
      "model.layers.1.self_attn.k_proj                    | 0.999975   | 0.1041       | 0.3743%\n",
      "model.layers.1.self_attn.v_proj                    | 0.999908   | 0.1430       | 1.1333%\n",
      "model.layers.1.self_attn.o_proj                    | 0.999883   | 0.3237       | 0.8991%\n",
      "model.layers.1.mlp.gate_proj                       | 1.000560   | 0.7150       | 0.5983%\n",
      "model.layers.1.mlp.up_proj                         | 1.000849   | 0.7833       | 0.7333%\n",
      "model.layers.1.mlp.down_proj                       | 1.000687   | 1.9416       | 1.8830%\n",
      "model.layers.2.self_attn.q_proj                    | 0.999899   | 0.2306       | 0.4884%\n",
      "model.layers.2.self_attn.k_proj                    | 0.999958   | 0.1031       | 0.4475%\n",
      "model.layers.2.self_attn.v_proj                    | 0.999929   | 0.1375       | 0.9491%\n",
      "model.layers.2.self_attn.o_proj                    | 0.999901   | 0.2512       | 0.6449%\n",
      "model.layers.2.mlp.gate_proj                       | 1.000483   | 0.6941       | 0.5609%\n",
      "model.layers.2.mlp.up_proj                         | 1.000852   | 0.6363       | 0.6411%\n",
      "model.layers.2.mlp.down_proj                       | 1.000724   | 1.6137       | 1.6330%\n",
      "model.layers.3.self_attn.q_proj                    | 0.999910   | 0.2184       | 0.4527%\n",
      "model.layers.3.self_attn.k_proj                    | 0.999956   | 0.1048       | 0.4721%\n",
      "model.layers.3.self_attn.v_proj                    | 0.999951   | 0.1190       | 0.7265%\n",
      "model.layers.3.self_attn.o_proj                    | 0.999902   | 0.2468       | 0.6254%\n",
      "model.layers.3.mlp.gate_proj                       | 1.000474   | 0.6937       | 0.5406%\n",
      "model.layers.3.mlp.up_proj                         | 1.000793   | 0.6431       | 0.6715%\n",
      "model.layers.3.mlp.down_proj                       | 1.000803   | 0.2390       | 0.2525%\n",
      "model.layers.4.self_attn.q_proj                    | 0.999910   | 0.2239       | 0.4769%\n",
      "model.layers.4.self_attn.k_proj                    | 0.999959   | 0.0974       | 0.4669%\n",
      "model.layers.4.self_attn.v_proj                    | 0.999950   | 0.1108       | 0.6441%\n",
      "model.layers.4.self_attn.o_proj                    | 0.999900   | 0.2455       | 0.6112%\n",
      "model.layers.4.mlp.gate_proj                       | 1.000599   | 0.6053       | 0.4966%\n",
      "model.layers.4.mlp.up_proj                         | 1.000820   | 0.6751       | 0.6963%\n",
      "model.layers.4.mlp.down_proj                       | 1.000821   | 0.2571       | 0.2676%\n",
      "model.layers.5.self_attn.q_proj                    | 0.999915   | 0.2553       | 0.5763%\n",
      "model.layers.5.self_attn.k_proj                    | 0.999964   | 0.0928       | 0.4881%\n",
      "model.layers.5.self_attn.v_proj                    | 0.999952   | 0.0975       | 0.5148%\n",
      "model.layers.5.self_attn.o_proj                    | 0.999915   | 0.2347       | 0.5568%\n",
      "model.layers.5.mlp.gate_proj                       | 1.000521   | 0.7956       | 0.6464%\n",
      "model.layers.5.mlp.up_proj                         | 1.000820   | 0.6937       | 0.7051%\n",
      "model.layers.5.mlp.down_proj                       | 1.000832   | 0.2969       | 0.3113%\n",
      "model.layers.6.self_attn.q_proj                    | 0.999959   | 0.2446       | 0.5244%\n",
      "model.layers.6.self_attn.k_proj                    | 0.999963   | 0.0875       | 0.4189%\n",
      "model.layers.6.self_attn.v_proj                    | 0.999899   | 0.2054       | 1.2346%\n",
      "model.layers.6.self_attn.o_proj                    | 0.999902   | 0.2579       | 0.7005%\n",
      "model.layers.6.mlp.gate_proj                       | 1.000700   | 0.7819       | 0.6940%\n",
      "model.layers.6.mlp.up_proj                         | 1.000796   | 0.6466       | 0.6279%\n",
      "model.layers.6.mlp.down_proj                       | 1.000846   | 0.3166       | 0.3133%\n",
      "model.layers.7.self_attn.q_proj                    | 0.999927   | 0.2953       | 0.6512%\n",
      "model.layers.7.self_attn.k_proj                    | 0.999950   | 0.1100       | 0.5511%\n",
      "model.layers.7.self_attn.v_proj                    | 0.999941   | 0.1307       | 0.7537%\n",
      "model.layers.7.self_attn.o_proj                    | 0.999906   | 0.2411       | 0.6080%\n",
      "model.layers.7.mlp.gate_proj                       | 1.000772   | 0.6377       | 0.5827%\n",
      "model.layers.7.mlp.up_proj                         | 1.000808   | 0.6713       | 0.6382%\n",
      "model.layers.7.mlp.down_proj                       | 1.000880   | 0.3107       | 0.3013%\n",
      "model.layers.8.self_attn.q_proj                    | 0.999931   | 0.2434       | 0.5246%\n",
      "model.layers.8.self_attn.k_proj                    | 0.999956   | 0.1045       | 0.5297%\n",
      "model.layers.8.self_attn.v_proj                    | 0.999961   | 0.0980       | 0.5974%\n",
      "model.layers.8.self_attn.o_proj                    | 0.999901   | 0.2789       | 0.7122%\n",
      "model.layers.8.mlp.gate_proj                       | 1.000782   | 0.6167       | 0.5663%\n",
      "model.layers.8.mlp.up_proj                         | 1.000812   | 0.6816       | 0.6563%\n",
      "model.layers.8.mlp.down_proj                       | 1.000849   | 0.3616       | 0.3572%\n",
      "model.layers.9.self_attn.q_proj                    | 0.999938   | 0.2605       | 0.5587%\n",
      "model.layers.9.self_attn.k_proj                    | 0.999961   | 0.0978       | 0.4767%\n",
      "model.layers.9.self_attn.v_proj                    | 0.999947   | 0.1217       | 0.7474%\n",
      "model.layers.9.self_attn.o_proj                    | 0.999904   | 0.2863       | 0.7337%\n",
      "model.layers.9.mlp.gate_proj                       | 1.000789   | 0.6683       | 0.6303%\n",
      "model.layers.9.mlp.up_proj                         | 1.000806   | 0.6217       | 0.5978%\n",
      "model.layers.9.mlp.down_proj                       | 1.000878   | 0.3179       | 0.3128%\n",
      "model.layers.10.self_attn.q_proj                   | 0.999900   | 0.2734       | 0.6133%\n",
      "model.layers.10.self_attn.k_proj                   | 0.999959   | 0.1089       | 0.5871%\n",
      "model.layers.10.self_attn.v_proj                   | 0.999955   | 0.1022       | 0.5879%\n",
      "model.layers.10.self_attn.o_proj                   | 0.999910   | 0.2578       | 0.6224%\n",
      "model.layers.10.mlp.gate_proj                      | 1.000822   | 0.7611       | 0.7107%\n",
      "model.layers.10.mlp.up_proj                        | 1.000808   | 0.6538       | 0.6292%\n",
      "model.layers.10.mlp.down_proj                      | 1.000876   | 0.3383       | 0.3381%\n",
      "model.layers.11.self_attn.q_proj                   | 0.999912   | 0.2675       | 0.5963%\n",
      "model.layers.11.self_attn.k_proj                   | 0.999959   | 0.0976       | 0.4992%\n",
      "model.layers.11.self_attn.v_proj                   | 0.999941   | 0.1374       | 0.8416%\n",
      "model.layers.11.self_attn.o_proj                   | 0.999915   | 0.2483       | 0.6320%\n",
      "model.layers.11.mlp.gate_proj                      | 1.000822   | 0.8858       | 0.8063%\n",
      "model.layers.11.mlp.up_proj                        | 1.000824   | 0.8078       | 0.7853%\n",
      "model.layers.11.mlp.down_proj                      | 1.000877   | 0.4233       | 0.4304%\n",
      "model.layers.12.self_attn.q_proj                   | 0.999913   | 0.2674       | 0.5956%\n",
      "model.layers.12.self_attn.k_proj                   | 0.999957   | 0.0990       | 0.5115%\n",
      "model.layers.12.self_attn.v_proj                   | 0.999952   | 0.1078       | 0.7024%\n",
      "model.layers.12.self_attn.o_proj                   | 0.999912   | 0.2626       | 0.6849%\n",
      "model.layers.12.mlp.gate_proj                      | 1.000852   | 1.0012       | 0.9368%\n",
      "model.layers.12.mlp.up_proj                        | 1.000841   | 0.6850       | 0.6683%\n",
      "model.layers.12.mlp.down_proj                      | 1.000889   | 0.3132       | 0.3184%\n",
      "model.layers.13.self_attn.q_proj                   | 0.999888   | 0.2740       | 0.5990%\n",
      "model.layers.13.self_attn.k_proj                   | 0.999949   | 0.1378       | 0.6650%\n",
      "model.layers.13.self_attn.v_proj                   | 0.999961   | 0.0992       | 0.6220%\n",
      "model.layers.13.self_attn.o_proj                   | 0.999912   | 0.2755       | 0.7121%\n",
      "model.layers.13.mlp.gate_proj                      | 1.000878   | 0.7788       | 0.7445%\n",
      "model.layers.13.mlp.up_proj                        | 1.000838   | 0.7219       | 0.7071%\n",
      "model.layers.13.mlp.down_proj                      | 1.000879   | 0.3096       | 0.3152%\n",
      "model.layers.14.self_attn.q_proj                   | 0.999952   | 0.2309       | 0.5415%\n",
      "model.layers.14.self_attn.k_proj                   | 0.999960   | 0.0894       | 0.4953%\n",
      "model.layers.14.self_attn.v_proj                   | 0.999954   | 0.1102       | 0.7281%\n",
      "model.layers.14.self_attn.o_proj                   | 0.999934   | 0.2113       | 0.5595%\n",
      "model.layers.14.mlp.gate_proj                      | 1.000883   | 0.7829       | 0.7832%\n",
      "model.layers.14.mlp.up_proj                        | 1.000872   | 0.6442       | 0.6395%\n",
      "model.layers.14.mlp.down_proj                      | 1.000893   | 0.3354       | 0.3423%\n",
      "model.layers.15.self_attn.q_proj                   | 0.999918   | 0.2773       | 0.6058%\n",
      "model.layers.15.self_attn.k_proj                   | 0.999956   | 0.1050       | 0.5811%\n",
      "model.layers.15.self_attn.v_proj                   | 0.999952   | 0.1121       | 0.6435%\n",
      "model.layers.15.self_attn.o_proj                   | 0.999917   | 0.2578       | 0.6385%\n",
      "model.layers.15.mlp.gate_proj                      | 1.000910   | 0.8493       | 0.8171%\n",
      "model.layers.15.mlp.up_proj                        | 1.000858   | 0.6320       | 0.6208%\n",
      "model.layers.15.mlp.down_proj                      | 1.000883   | 0.3224       | 0.3306%\n",
      "model.layers.16.self_attn.q_proj                   | 0.999908   | 0.2799       | 0.6546%\n",
      "model.layers.16.self_attn.k_proj                   | 0.999940   | 0.1463       | 0.8420%\n",
      "model.layers.16.self_attn.v_proj                   | 0.999962   | 0.0949       | 0.5923%\n",
      "model.layers.16.self_attn.o_proj                   | 0.999921   | 0.2357       | 0.6055%\n",
      "model.layers.16.mlp.gate_proj                      | 1.000890   | 1.0015       | 0.9855%\n",
      "model.layers.16.mlp.up_proj                        | 1.000869   | 0.7053       | 0.6968%\n",
      "model.layers.16.mlp.down_proj                      | 1.000868   | 0.4196       | 0.4352%\n",
      "model.layers.17.self_attn.q_proj                   | 0.999933   | 0.2945       | 0.7321%\n",
      "model.layers.17.self_attn.k_proj                   | 0.999922   | 0.1434       | 1.0368%\n",
      "model.layers.17.self_attn.v_proj                   | 0.999937   | 0.1585       | 0.8586%\n",
      "model.layers.17.self_attn.o_proj                   | 0.999907   | 0.2759       | 0.6669%\n",
      "model.layers.17.mlp.gate_proj                      | 1.000887   | 1.1582       | 1.1321%\n",
      "model.layers.17.mlp.up_proj                        | 1.000836   | 0.7650       | 0.7399%\n",
      "model.layers.17.mlp.down_proj                      | 1.000881   | 0.3503       | 0.3545%\n",
      "model.layers.18.self_attn.q_proj                   | 0.999916   | 0.3573       | 0.8437%\n",
      "model.layers.18.self_attn.k_proj                   | 0.999949   | 0.1196       | 0.6966%\n",
      "model.layers.18.self_attn.v_proj                   | 0.999955   | 0.0975       | 0.5619%\n",
      "model.layers.18.self_attn.o_proj                   | 0.999902   | 0.2780       | 0.6986%\n",
      "model.layers.18.mlp.gate_proj                      | 1.000946   | 0.8623       | 0.8420%\n",
      "model.layers.18.mlp.up_proj                        | 1.000855   | 0.7269       | 0.7006%\n",
      "model.layers.18.mlp.down_proj                      | 1.000904   | 0.3923       | 0.3948%\n",
      "model.layers.19.self_attn.q_proj                   | 0.999936   | 0.2684       | 0.6453%\n",
      "model.layers.19.self_attn.k_proj                   | 0.999956   | 0.0985       | 0.6639%\n",
      "model.layers.19.self_attn.v_proj                   | 0.999946   | 0.1296       | 0.7435%\n",
      "model.layers.19.self_attn.o_proj                   | 0.999908   | 0.2290       | 0.5746%\n",
      "model.layers.19.mlp.gate_proj                      | 1.000958   | 0.7391       | 0.7243%\n",
      "model.layers.19.mlp.up_proj                        | 1.000863   | 0.6424       | 0.6002%\n",
      "model.layers.19.mlp.down_proj                      | 1.000923   | 0.3539       | 0.3470%\n",
      "model.layers.20.self_attn.q_proj                   | 0.999939   | 0.2621       | 0.6106%\n",
      "model.layers.20.self_attn.k_proj                   | 0.999954   | 0.1068       | 0.7024%\n",
      "model.layers.20.self_attn.v_proj                   | 0.999958   | 0.0936       | 0.4484%\n",
      "model.layers.20.self_attn.o_proj                   | 0.999911   | 0.2122       | 0.4981%\n",
      "model.layers.20.mlp.gate_proj                      | 1.000853   | 1.0552       | 1.0182%\n",
      "model.layers.20.mlp.up_proj                        | 1.000777   | 0.7114       | 0.6598%\n",
      "model.layers.20.mlp.down_proj                      | 1.000869   | 0.3552       | 0.3445%\n",
      "model.layers.21.self_attn.q_proj                   | 0.999927   | 0.2234       | 0.5460%\n",
      "model.layers.21.self_attn.k_proj                   | 0.999955   | 0.1009       | 0.7066%\n",
      "model.layers.21.self_attn.v_proj                   | 0.999954   | 0.1132       | 0.5433%\n",
      "model.layers.21.self_attn.o_proj                   | 0.999908   | 0.2316       | 0.5350%\n",
      "model.layers.21.mlp.gate_proj                      | 1.000870   | 1.0382       | 0.9948%\n",
      "model.layers.21.mlp.up_proj                        | 1.000798   | 0.6679       | 0.6135%\n",
      "model.layers.21.mlp.down_proj                      | 1.000894   | 0.3960       | 0.3816%\n",
      "model.layers.22.self_attn.q_proj                   | 0.999914   | 0.2388       | 0.5335%\n",
      "model.layers.22.self_attn.k_proj                   | 0.999964   | 0.0940       | 0.5569%\n",
      "model.layers.22.self_attn.v_proj                   | 0.999960   | 0.1077       | 0.5474%\n",
      "model.layers.22.self_attn.o_proj                   | 0.999908   | 0.2120       | 0.4917%\n",
      "model.layers.22.mlp.gate_proj                      | 1.000886   | 0.8421       | 0.7905%\n",
      "model.layers.22.mlp.up_proj                        | 1.000793   | 0.7150       | 0.6561%\n",
      "model.layers.22.mlp.down_proj                      | 1.000889   | 0.4544       | 0.4378%\n",
      "model.layers.23.self_attn.q_proj                   | 0.999957   | 0.2373       | 0.5496%\n",
      "model.layers.23.self_attn.k_proj                   | 0.999957   | 0.0886       | 0.6236%\n",
      "model.layers.23.self_attn.v_proj                   | 0.999960   | 0.0946       | 0.4791%\n",
      "model.layers.23.self_attn.o_proj                   | 0.999906   | 0.2188       | 0.5039%\n",
      "model.layers.23.mlp.gate_proj                      | 1.000808   | 0.9007       | 0.8458%\n",
      "model.layers.23.mlp.up_proj                        | 1.000745   | 0.6635       | 0.6005%\n",
      "model.layers.23.mlp.down_proj                      | 1.000866   | 0.4307       | 0.4042%\n",
      "model.layers.24.self_attn.q_proj                   | 0.999971   | 0.2626       | 0.6194%\n",
      "model.layers.24.self_attn.k_proj                   | 0.999960   | 0.0923       | 0.6124%\n",
      "model.layers.24.self_attn.v_proj                   | 0.999947   | 0.1782       | 0.7574%\n",
      "model.layers.24.self_attn.o_proj                   | 0.999901   | 0.2374       | 0.4971%\n",
      "model.layers.24.mlp.gate_proj                      | 1.000793   | 0.6674       | 0.6302%\n",
      "model.layers.24.mlp.up_proj                        | 1.000708   | 0.6841       | 0.6150%\n",
      "model.layers.24.mlp.down_proj                      | 1.000837   | 0.4724       | 0.4355%\n",
      "model.layers.25.self_attn.q_proj                   | 0.999934   | 0.2783       | 0.6402%\n",
      "model.layers.25.self_attn.k_proj                   | 0.999945   | 0.0988       | 0.7787%\n",
      "model.layers.25.self_attn.v_proj                   | 0.999931   | 0.1665       | 0.8486%\n",
      "model.layers.25.self_attn.o_proj                   | 0.999930   | 0.2578       | 0.5558%\n",
      "model.layers.25.mlp.gate_proj                      | 1.000758   | 1.1508       | 1.1082%\n",
      "model.layers.25.mlp.up_proj                        | 1.000651   | 1.0841       | 0.9610%\n",
      "model.layers.25.mlp.down_proj                      | 1.000800   | 0.3395       | 0.3073%\n",
      "model.layers.26.self_attn.q_proj                   | 0.999971   | 0.2145       | 0.5175%\n",
      "model.layers.26.self_attn.k_proj                   | 0.999959   | 0.0826       | 0.6167%\n",
      "model.layers.26.self_attn.v_proj                   | 0.999971   | 0.1232       | 0.4103%\n",
      "model.layers.26.self_attn.o_proj                   | 0.999888   | 0.2490       | 0.4792%\n",
      "model.layers.26.mlp.gate_proj                      | 1.000758   | 1.4298       | 1.4001%\n",
      "model.layers.26.mlp.up_proj                        | 1.000606   | 1.4628       | 1.2846%\n",
      "model.layers.26.mlp.down_proj                      | 1.000765   | 0.6793       | 0.6216%\n",
      "model.layers.27.self_attn.q_proj                   | 0.999936   | 0.2278       | 0.5665%\n",
      "model.layers.27.self_attn.k_proj                   | 0.999945   | 0.0885       | 0.7530%\n",
      "model.layers.27.self_attn.v_proj                   | 0.999864   | 0.4244       | 1.4976%\n",
      "model.layers.27.self_attn.o_proj                   | 0.999896   | 0.4805       | 0.9255%\n",
      "model.layers.27.mlp.gate_proj                      | 1.000774   | 1.4059       | 1.3675%\n",
      "model.layers.27.mlp.up_proj                        | 1.000741   | 1.3847       | 1.3126%\n",
      "model.layers.27.mlp.down_proj                      | 1.000864   | 0.2157       | 0.2298%\n",
      "lm_head                                            | 1.079851   | 0.0000       | 0.0000%\n",
      "------------------------------------------------------------------------------------------\n",
      "Avg Cos Sim: 1.0007 | Avg Delta Norm: 0.4003\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# 配置\n",
    "# ==========================================\n",
    "model_id_ft = \"zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct\"   # Target\n",
    "model_id_base = \"Qwen/Qwen2.5-1.5B-Instruct\"    # Prior (Base)\n",
    "device = \"cpu\" # 对比只需 CPU 即可，省显存\n",
    "\n",
    "print(f\"Loading Fine-Tuned Model: {model_id_ft}...\")\n",
    "model_ft = AutoModelForCausalLM.from_pretrained(model_id_ft, trust_remote_code=True).to(device)\n",
    "\n",
    "print(f\"Loading Base Model: {model_id_base}...\")\n",
    "model_base = AutoModelForCausalLM.from_pretrained(model_id_base, trust_remote_code=True).to(device)\n",
    "\n",
    "print(\"\\nStarting Comparison (FT vs. Base)...\")\n",
    "print(\"-\" * 90)\n",
    "print(f\"{'Layer Name':<50} | {'Cos Sim':<10} | {'Delta Norm':<12} | {'Rel Diff (%)':<12}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "results = []\n",
    "modules_base = dict(model_base.named_modules())\n",
    "\n",
    "for name, module_ft in model_ft.named_modules():\n",
    "    if isinstance(module_ft, torch.nn.Linear):\n",
    "        if name in modules_base:\n",
    "            module_base = modules_base[name]\n",
    "            w_ft = module_ft.weight.detach()\n",
    "            w_base = module_base.weight.detach()\n",
    "            \n",
    "            if w_ft.shape != w_base.shape:\n",
    "                continue\n",
    "                \n",
    "            # 1. Cosine Similarity\n",
    "            cos_sim = torch.nn.functional.cosine_similarity(\n",
    "                w_ft.flatten(), w_base.flatten(), dim=0\n",
    "            ).item()\n",
    "            \n",
    "            # 2. Delta (FT - Base)\n",
    "            delta = w_ft - w_base\n",
    "            norm_delta = torch.norm(delta).item()\n",
    "            norm_base = torch.norm(w_base).item()\n",
    "            \n",
    "            rel_diff = norm_delta / norm_base if norm_base > 0 else 0.0\n",
    "            \n",
    "            print(f\"{name:<50} | {cos_sim:.6f}   | {norm_delta:.4f}       | {rel_diff*100:.4f}%\")\n",
    "            \n",
    "            results.append({\n",
    "                \"Layer\": name, \"Cos_Sim\": cos_sim, \n",
    "                \"Delta_Norm\": norm_delta, \"Rel_Diff\": rel_diff\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"-\" * 90)\n",
    "print(f\"Avg Cos Sim: {df['Cos_Sim'].mean():.4f} | Avg Delta Norm: {df['Delta_Norm'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5bbece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Base Model (Prior): Qwen/Qwen2.5-1.5B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen/Qwen2.5-1.5B-Instruct/resolve/main/config.json (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<HTTPSConnection(host='192.168.240.1', port=7890) at 0x7b2a0134fa90>, 'Connection to 192.168.240.1 timed out. (connect timeout=10)')))\"), '(Request ID: 2d1b0cfb-6d2e-4828-ad2b-6467231e59b5)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen/Qwen2.5-1.5B-Instruct/resolve/main/config.json (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<HTTPSConnection(host='192.168.240.1', port=7890) at 0x7b2a010576d0>, 'Connection to 192.168.240.1 timed out. (connect timeout=10)')))\"), '(Request ID: be49ed8c-2e53-4b60-ad89-31850dd9b99d)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen/Qwen2.5-1.5B-Instruct/resolve/main/config.json (Caused by ProxyError('Unable to connect to proxy', ConnectTimeoutError(<HTTPSConnection(host='192.168.240.1', port=7890) at 0x7b2a01064750>, 'Connection to 192.168.240.1 timed out. (connect timeout=10)')))\"), '(Request ID: b6ac57a9-72eb-4893-8efe-336a8a8a036a)')' thrown while requesting HEAD https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct/resolve/main/config.json\n",
      "Retrying in 4s [Retry 3/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading Obfuscated Checkpoint: /mnt/e/untitled folder/codebase/LoRO_attack/loro_qwen_1_5B.pt...\n",
      "3. Loading Ground Truth (Validation): zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct...\n",
      "\n",
      "STARTING RECOVERY (Removing Top-24 Singular Values as Noise)...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   0%|                                                                               | 0/197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   1%|▎                                                                      | 1/197 [00:00<01:09,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.0.self_attn.q_proj | 110.85456085205078, 108.54083251953125, 0.10493861138820648, 0.07237014919519424\n",
      "Layer: model.layers.0.self_attn.q_proj | Similarity with GT Delta: 0.9763\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.0.self_attn.k_proj | 38.99114227294922, 37.96333694458008, 0.03662277013063431, 0.030751856043934822\n",
      "Layer: model.layers.0.self_attn.k_proj | Similarity with GT Delta: 0.9447\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.0.self_attn.v_proj | 38.60441589355469, 36.40998458862305, 0.04998471960425377, 0.02945486456155777\n",
      "Layer: model.layers.0.self_attn.v_proj | Similarity with GT Delta: 0.9457\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   2%|█▍                                                                     | 4/197 [00:00<00:31,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.0.self_attn.o_proj | 112.155517578125, 108.31087493896484, 0.17492511868476868, 0.06637772172689438\n",
      "Layer: model.layers.0.self_attn.o_proj | Similarity with GT Delta: 0.9788\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   3%|█▊                                                                     | 5/197 [00:01<00:57,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.0.mlp.gate_proj | 275.2273864746094, 268.70819091796875, 0.364026814699173, 0.1889987289905548\n",
      "Layer: model.layers.0.mlp.gate_proj | Similarity with GT Delta: 0.9854\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   3%|██▏                                                                    | 6/197 [00:02<01:16,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.0.mlp.up_proj | 278.8794860839844, 274.6235046386719, 0.36274561285972595, 0.158272385597229\n",
      "Layer: model.layers.0.mlp.up_proj | Similarity with GT Delta: 0.9869\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   4%|██▌                                                                    | 7/197 [00:03<02:25,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.0.mlp.down_proj | 276.3860778808594, 271.5986633300781, 0.12384162098169327, 0.08179821819067001\n",
      "Layer: model.layers.0.mlp.down_proj | Similarity with GT Delta: 0.9610\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   4%|██▉                                                                    | 8/197 [00:03<01:54,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.1.self_attn.q_proj | 113.06632232666016, 107.59654235839844, 0.10851271450519562, 0.07841189205646515\n",
      "Layer: model.layers.1.self_attn.q_proj | Similarity with GT Delta: 0.9756\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.1.self_attn.k_proj | 38.136497497558594, 37.803245544433594, 0.05839051678776741, 0.035603880882263184\n",
      "Layer: model.layers.1.self_attn.k_proj | Similarity with GT Delta: 0.9439\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.1.self_attn.v_proj | 39.59571075439453, 37.06818771362305, 0.12398642301559448, 0.026132624596357346\n",
      "Layer: model.layers.1.self_attn.v_proj | Similarity with GT Delta: 0.9379\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   6%|███▉                                                                  | 11/197 [00:04<00:59,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.1.self_attn.o_proj | 110.44824981689453, 105.96926879882812, 0.2832280993461609, 0.07458081841468811\n",
      "Layer: model.layers.1.self_attn.o_proj | Similarity with GT Delta: 0.9808\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   6%|████▎                                                                 | 12/197 [00:04<01:12,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.1.mlp.gate_proj | 276.67828369140625, 274.3094787597656, 0.6123086810112, 0.14983408153057098\n",
      "Layer: model.layers.1.mlp.gate_proj | Similarity with GT Delta: 0.9898\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   7%|████▌                                                                 | 13/197 [00:05<01:23,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.1.mlp.up_proj | 277.230224609375, 271.201171875, 0.7109843492507935, 0.11871141940355301\n",
      "Layer: model.layers.1.mlp.up_proj | Similarity with GT Delta: 0.9921\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   7%|████▉                                                                 | 14/197 [00:07<02:25,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.1.mlp.down_proj | 281.00225830078125, 273.2513122558594, 1.8834078311920166, 0.3037489652633667\n",
      "Layer: model.layers.1.mlp.down_proj | Similarity with GT Delta: 0.9908\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   8%|█████▎                                                                | 15/197 [00:07<01:57,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.2.self_attn.q_proj | 110.71748352050781, 107.41670989990234, 0.15405136346817017, 0.06072244048118591\n",
      "Layer: model.layers.2.self_attn.q_proj | Similarity with GT Delta: 0.9809\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.2.self_attn.k_proj | 38.70488739013672, 37.30792236328125, 0.06663794815540314, 0.02416509948670864\n",
      "Layer: model.layers.2.self_attn.k_proj | Similarity with GT Delta: 0.9465\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.2.self_attn.v_proj | 38.508182525634766, 37.89719772338867, 0.1112542524933815, 0.04468158259987831\n",
      "Layer: model.layers.2.self_attn.v_proj | Similarity with GT Delta: 0.9425\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:   9%|██████▍                                                               | 18/197 [00:07<01:02,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.2.self_attn.o_proj | 111.11676025390625, 107.85099792480469, 0.1512385457754135, 0.09804478287696838\n",
      "Layer: model.layers.2.self_attn.o_proj | Similarity with GT Delta: 0.9811\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  10%|██████▊                                                               | 19/197 [00:08<01:12,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.2.mlp.gate_proj | 278.7232360839844, 274.8935852050781, 0.5878899693489075, 0.1326112151145935\n",
      "Layer: model.layers.2.mlp.gate_proj | Similarity with GT Delta: 0.9891\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  10%|███████                                                               | 20/197 [00:09<01:21,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.2.mlp.up_proj | 276.9786376953125, 272.14404296875, 0.521558940410614, 0.18421857059001923\n",
      "Layer: model.layers.2.mlp.up_proj | Similarity with GT Delta: 0.9865\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  11%|███████▍                                                              | 21/197 [00:10<02:13,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.2.mlp.down_proj | 273.4554443359375, 267.8240051269531, 1.5782041549682617, 0.17235872149467468\n",
      "Layer: model.layers.2.mlp.down_proj | Similarity with GT Delta: 0.9918\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  11%|███████▊                                                              | 22/197 [00:11<01:49,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.3.self_attn.q_proj | 110.3399429321289, 109.58518981933594, 0.1465122103691101, 0.07150041311979294\n",
      "Layer: model.layers.3.self_attn.q_proj | Similarity with GT Delta: 0.9789\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.3.self_attn.k_proj | 38.763893127441406, 37.52210235595703, 0.07947187125682831, 0.028115108609199524\n",
      "Layer: model.layers.3.self_attn.k_proj | Similarity with GT Delta: 0.9339\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.3.self_attn.v_proj | 39.248382568359375, 38.22079086303711, 0.08882182091474533, 0.045830950140953064\n",
      "Layer: model.layers.3.self_attn.v_proj | Similarity with GT Delta: 0.9414\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  13%|████████▉                                                             | 25/197 [00:11<00:58,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.3.self_attn.o_proj | 109.89990234375, 107.58911895751953, 0.14873892068862915, 0.07948354631662369\n",
      "Layer: model.layers.3.self_attn.o_proj | Similarity with GT Delta: 0.9762\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  13%|█████████▏                                                            | 26/197 [00:11<01:07,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.3.mlp.gate_proj | 275.873046875, 272.7729187011719, 0.5978835225105286, 0.11893697828054428\n",
      "Layer: model.layers.3.mlp.gate_proj | Similarity with GT Delta: 0.9889\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  14%|█████████▌                                                            | 27/197 [00:12<01:17,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.3.mlp.up_proj | 281.76885986328125, 273.85406494140625, 0.5261197686195374, 0.15879862010478973\n",
      "Layer: model.layers.3.mlp.up_proj | Similarity with GT Delta: 0.9871\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  14%|█████████▉                                                            | 28/197 [00:14<02:05,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.3.mlp.down_proj | 277.2013244628906, 270.755126953125, 0.13490524888038635, 0.09244896471500397\n",
      "Layer: model.layers.3.mlp.down_proj | Similarity with GT Delta: 0.9720\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  15%|██████████▎                                                           | 29/197 [00:14<01:42,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.4.self_attn.q_proj | 109.41773223876953, 109.13572692871094, 0.11577951908111572, 0.0775563195347786\n",
      "Layer: model.layers.4.self_attn.q_proj | Similarity with GT Delta: 0.9757\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.4.self_attn.k_proj | 37.60171890258789, 35.160953521728516, 0.06644123792648315, 0.025684500113129616\n",
      "Layer: model.layers.4.self_attn.k_proj | Similarity with GT Delta: 0.9505\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.4.self_attn.v_proj | 39.39423751831055, 38.29228973388672, 0.070005401968956, 0.044241081923246384\n",
      "Layer: model.layers.4.self_attn.v_proj | Similarity with GT Delta: 0.9406\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  16%|███████████▎                                                          | 32/197 [00:14<00:54,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.4.self_attn.o_proj | 111.58061981201172, 107.70870971679688, 0.13624608516693115, 0.10044784843921661\n",
      "Layer: model.layers.4.self_attn.o_proj | Similarity with GT Delta: 0.9793\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  17%|███████████▋                                                          | 33/197 [00:15<01:04,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.4.mlp.gate_proj | 275.080078125, 272.9604797363281, 0.4646463394165039, 0.1594918668270111\n",
      "Layer: model.layers.4.mlp.gate_proj | Similarity with GT Delta: 0.9885\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  17%|████████████                                                          | 34/197 [00:15<01:12,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.4.mlp.up_proj | 276.6955871582031, 273.9127197265625, 0.5414903163909912, 0.1938558667898178\n",
      "Layer: model.layers.4.mlp.up_proj | Similarity with GT Delta: 0.9906\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  18%|████████████▍                                                         | 35/197 [00:17<01:59,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.4.mlp.down_proj | 277.08795166015625, 272.0637512207031, 0.1684037297964096, 0.08759119361639023\n",
      "Layer: model.layers.4.mlp.down_proj | Similarity with GT Delta: 0.9713\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  18%|████████████▊                                                         | 36/197 [00:17<01:37,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.5.self_attn.q_proj | 109.92774963378906, 105.91590118408203, 0.18299534916877747, 0.07264132052659988\n",
      "Layer: model.layers.5.self_attn.q_proj | Similarity with GT Delta: 0.9836\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.5.self_attn.k_proj | 38.903953552246094, 37.298851013183594, 0.06461618840694427, 0.025325072929263115\n",
      "Layer: model.layers.5.self_attn.k_proj | Similarity with GT Delta: 0.9528\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.5.self_attn.v_proj | 38.816402435302734, 37.41267776489258, 0.04904844984412193, 0.03980196267366409\n",
      "Layer: model.layers.5.self_attn.v_proj | Similarity with GT Delta: 0.9339\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  20%|█████████████▊                                                        | 39/197 [00:18<00:52,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.5.self_attn.o_proj | 110.35391998291016, 107.0889663696289, 0.11385054886341095, 0.1058129295706749\n",
      "Layer: model.layers.5.self_attn.o_proj | Similarity with GT Delta: 0.9814\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  20%|██████████████▏                                                       | 40/197 [00:18<01:01,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.5.mlp.gate_proj | 278.4375305175781, 275.9696350097656, 0.7024552226066589, 0.14547114074230194\n",
      "Layer: model.layers.5.mlp.gate_proj | Similarity with GT Delta: 0.9870\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.5.mlp.up_proj | 275.6080017089844, 268.9867858886719, 0.5871020555496216, 0.17948557436466217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  21%|██████████████▌                                                       | 41/197 [00:19<01:11,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.5.mlp.up_proj | Similarity with GT Delta: 0.9881\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  21%|██████████████▉                                                       | 42/197 [00:21<02:06,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.5.mlp.down_proj | 277.44677734375, 270.8825988769531, 0.234980970621109, 0.10093700885772705\n",
      "Layer: model.layers.5.mlp.down_proj | Similarity with GT Delta: 0.9817\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  22%|███████████████▎                                                      | 43/197 [00:21<01:42,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.6.self_attn.q_proj | 111.01306915283203, 108.09291076660156, 0.16070879995822906, 0.07674740999937057\n",
      "Layer: model.layers.6.self_attn.q_proj | Similarity with GT Delta: 0.9814\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.6.self_attn.k_proj | 40.103450775146484, 37.41843032836914, 0.04436441883444786, 0.034197527915239334\n",
      "Layer: model.layers.6.self_attn.k_proj | Similarity with GT Delta: 0.9385\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.6.self_attn.v_proj | 40.26084899902344, 36.89176940917969, 0.1823766529560089, 0.04006468132138252\n",
      "Layer: model.layers.6.self_attn.v_proj | Similarity with GT Delta: 0.9469\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  23%|████████████████▎                                                     | 46/197 [00:21<00:54,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.6.self_attn.o_proj | 111.82109069824219, 110.19654083251953, 0.20670485496520996, 0.09139080345630646\n",
      "Layer: model.layers.6.self_attn.o_proj | Similarity with GT Delta: 0.9843\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  24%|████████████████▋                                                     | 47/197 [00:22<01:02,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.6.mlp.gate_proj | 274.1790466308594, 270.2818603515625, 0.6763228178024292, 0.15497848391532898\n",
      "Layer: model.layers.6.mlp.gate_proj | Similarity with GT Delta: 0.9890\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  24%|█████████████████                                                     | 48/197 [00:23<01:11,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.6.mlp.up_proj | 278.1018981933594, 265.9657287597656, 0.480431467294693, 0.21279288828372955\n",
      "Layer: model.layers.6.mlp.up_proj | Similarity with GT Delta: 0.9883\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  25%|█████████████████▍                                                    | 49/197 [00:24<01:55,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.6.mlp.down_proj | 274.9368896484375, 273.928466796875, 0.2567538022994995, 0.08853954076766968\n",
      "Layer: model.layers.6.mlp.down_proj | Similarity with GT Delta: 0.9814\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  25%|█████████████████▊                                                    | 50/197 [00:25<01:33,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.7.self_attn.q_proj | 112.789306640625, 108.90530395507812, 0.20775052905082703, 0.09902974963188171\n",
      "Layer: model.layers.7.self_attn.q_proj | Similarity with GT Delta: 0.9824\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.7.self_attn.k_proj | 38.4631462097168, 34.6366081237793, 0.06858493387699127, 0.038331713527441025\n",
      "Layer: model.layers.7.self_attn.k_proj | Similarity with GT Delta: 0.9442\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.7.self_attn.v_proj | 41.07978820800781, 39.503631591796875, 0.08588187396526337, 0.059362735599279404\n",
      "Layer: model.layers.7.self_attn.v_proj | Similarity with GT Delta: 0.9354\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  27%|██████████████████▊                                                   | 53/197 [00:25<00:50,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.7.self_attn.o_proj | 110.25267028808594, 108.68445587158203, 0.13712933659553528, 0.12725195288658142\n",
      "Layer: model.layers.7.self_attn.o_proj | Similarity with GT Delta: 0.9799\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  27%|███████████████████▏                                                  | 54/197 [00:26<00:58,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.7.mlp.gate_proj | 273.8360900878906, 271.9365539550781, 0.4762587547302246, 0.21485479176044464\n",
      "Layer: model.layers.7.mlp.gate_proj | Similarity with GT Delta: 0.9871\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  28%|███████████████████▌                                                  | 55/197 [00:26<01:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.7.mlp.up_proj | 279.1889953613281, 266.5095520019531, 0.47491344809532166, 0.24041204154491425\n",
      "Layer: model.layers.7.mlp.up_proj | Similarity with GT Delta: 0.9897\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  28%|███████████████████▉                                                  | 56/197 [00:28<01:47,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.7.mlp.down_proj | 280.6122741699219, 275.08197021484375, 0.2620381712913513, 0.05250620096921921\n",
      "Layer: model.layers.7.mlp.down_proj | Similarity with GT Delta: 0.9821\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  29%|████████████████████▎                                                 | 57/197 [00:28<01:27,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.8.self_attn.q_proj | 113.08135223388672, 109.71116638183594, 0.1142863929271698, 0.09184953570365906\n",
      "Layer: model.layers.8.self_attn.q_proj | Similarity with GT Delta: 0.9832\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.8.self_attn.k_proj | 39.800655364990234, 38.066368103027344, 0.061760757118463516, 0.03163342922925949\n",
      "Layer: model.layers.8.self_attn.k_proj | Similarity with GT Delta: 0.9365\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.8.self_attn.v_proj | 37.39583969116211, 36.98485565185547, 0.06686880439519882, 0.024412760511040688\n",
      "Layer: model.layers.8.self_attn.v_proj | Similarity with GT Delta: 0.9246\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  30%|█████████████████████▎                                                | 60/197 [00:28<00:46,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.8.self_attn.o_proj | 109.40039825439453, 106.89680480957031, 0.18774943053722382, 0.11006316542625427\n",
      "Layer: model.layers.8.self_attn.o_proj | Similarity with GT Delta: 0.9830\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.8.mlp.gate_proj | 278.9275817871094, 275.7316589355469, 0.4569626748561859, 0.19063501060009003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  31%|█████████████████████▋                                                | 61/197 [00:29<00:55,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.8.mlp.gate_proj | Similarity with GT Delta: 0.9874\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  31%|██████████████████████                                                | 62/197 [00:30<01:08,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.8.mlp.up_proj | 277.1063232421875, 276.2815856933594, 0.49820271134376526, 0.24791240692138672\n",
      "Layer: model.layers.8.mlp.up_proj | Similarity with GT Delta: 0.9907\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  32%|██████████████████████▍                                               | 63/197 [00:32<01:46,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.8.mlp.down_proj | 275.65240478515625, 274.845703125, 0.32089951634407043, 0.05379311740398407\n",
      "Layer: model.layers.8.mlp.down_proj | Similarity with GT Delta: 0.9834\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  32%|██████████████████████▋                                               | 64/197 [00:32<01:27,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.9.self_attn.q_proj | 110.69427490234375, 110.49449157714844, 0.16810265183448792, 0.08355925232172012\n",
      "Layer: model.layers.9.self_attn.q_proj | Similarity with GT Delta: 0.9784\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.9.self_attn.k_proj | 39.03826141357422, 38.32705307006836, 0.0642957016825676, 0.028384830802679062\n",
      "Layer: model.layers.9.self_attn.k_proj | Similarity with GT Delta: 0.9448\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.9.self_attn.v_proj | 38.13227081298828, 37.685943603515625, 0.07975302636623383, 0.04476936534047127\n",
      "Layer: model.layers.9.self_attn.v_proj | Similarity with GT Delta: 0.9429\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  34%|███████████████████████▊                                              | 67/197 [00:32<00:46,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.9.self_attn.o_proj | 111.9452896118164, 105.5058364868164, 0.1649218648672104, 0.14267532527446747\n",
      "Layer: model.layers.9.self_attn.o_proj | Similarity with GT Delta: 0.9810\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  35%|████████████████████████▏                                             | 68/197 [00:33<00:54,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.9.mlp.gate_proj | 278.0399169921875, 273.2672424316406, 0.48458331823349, 0.23608769476413727\n",
      "Layer: model.layers.9.mlp.gate_proj | Similarity with GT Delta: 0.9894\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  35%|████████████████████████▌                                             | 69/197 [00:33<01:01,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.9.mlp.up_proj | 276.5679931640625, 267.3401794433594, 0.4315437972545624, 0.22675365209579468\n",
      "Layer: model.layers.9.mlp.up_proj | Similarity with GT Delta: 0.9865\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  36%|████████████████████████▊                                             | 70/197 [00:35<01:40,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.9.mlp.down_proj | 280.3621520996094, 272.5422668457031, 0.2818582355976105, 0.041012201458215714\n",
      "Layer: model.layers.9.mlp.down_proj | Similarity with GT Delta: 0.9858\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  36%|█████████████████████████▏                                            | 71/197 [00:35<01:22,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.10.self_attn.q_proj | 110.16830444335938, 107.26847076416016, 0.1550094485282898, 0.12105074524879456\n",
      "Layer: model.layers.10.self_attn.q_proj | Similarity with GT Delta: 0.9823\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.10.self_attn.k_proj | 39.30081558227539, 36.87860870361328, 0.06508941948413849, 0.03366990387439728\n",
      "Layer: model.layers.10.self_attn.k_proj | Similarity with GT Delta: 0.9277\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.10.self_attn.v_proj | 40.95128631591797, 37.51689910888672, 0.05360716953873634, 0.04559672623872757\n",
      "Layer: model.layers.10.self_attn.v_proj | Similarity with GT Delta: 0.9429\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  38%|██████████████████████████▎                                           | 74/197 [00:36<00:44,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.10.self_attn.o_proj | 109.3443603515625, 106.73062896728516, 0.13964930176734924, 0.08791907131671906\n",
      "Layer: model.layers.10.self_attn.o_proj | Similarity with GT Delta: 0.9810\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  38%|██████████████████████████▋                                           | 75/197 [00:36<00:52,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.10.mlp.gate_proj | 277.1257019042969, 276.71356201171875, 0.628277599811554, 0.2409777045249939\n",
      "Layer: model.layers.10.mlp.gate_proj | Similarity with GT Delta: 0.9897\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  39%|███████████████████████████                                           | 76/197 [00:37<00:57,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.10.mlp.up_proj | 279.42889404296875, 267.6861877441406, 0.4425427317619324, 0.2670813202857971\n",
      "Layer: model.layers.10.mlp.up_proj | Similarity with GT Delta: 0.9885\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  39%|███████████████████████████▎                                          | 77/197 [00:39<01:31,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.10.mlp.down_proj | 277.6838684082031, 272.30987548828125, 0.30234962701797485, 0.045116547495126724\n",
      "Layer: model.layers.10.mlp.down_proj | Similarity with GT Delta: 0.9790\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  40%|███████████████████████████▋                                          | 78/197 [00:39<01:14,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.11.self_attn.q_proj | 111.07334899902344, 109.67222595214844, 0.17935700714588165, 0.10416219383478165\n",
      "Layer: model.layers.11.self_attn.q_proj | Similarity with GT Delta: 0.9799\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.11.self_attn.k_proj | 38.27239990234375, 33.922882080078125, 0.04951122775673866, 0.04131976515054703\n",
      "Layer: model.layers.11.self_attn.k_proj | Similarity with GT Delta: 0.9397\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.11.self_attn.v_proj | 37.3255729675293, 35.08582305908203, 0.11269477009773254, 0.03522943705320358\n",
      "Layer: model.layers.11.self_attn.v_proj | Similarity with GT Delta: 0.9527\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  41%|████████████████████████████▊                                         | 81/197 [00:39<00:39,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.11.self_attn.o_proj | 110.86724853515625, 107.94328308105469, 0.18985895812511444, 0.09018168598413467\n",
      "Layer: model.layers.11.self_attn.o_proj | Similarity with GT Delta: 0.9808\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  42%|█████████████████████████████▏                                        | 82/197 [00:40<00:46,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.11.mlp.gate_proj | 274.0498046875, 273.5718994140625, 0.8072840571403503, 0.18053488433361053\n",
      "Layer: model.layers.11.mlp.gate_proj | Similarity with GT Delta: 0.9906\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  42%|█████████████████████████████▍                                        | 83/197 [00:41<00:52,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.11.mlp.up_proj | 277.87286376953125, 276.7088928222656, 0.7223234176635742, 0.18623313307762146\n",
      "Layer: model.layers.11.mlp.up_proj | Similarity with GT Delta: 0.9921\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  43%|█████████████████████████████▊                                        | 84/197 [00:43<01:36,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.11.mlp.down_proj | 277.0653381347656, 274.83984375, 0.3969075381755829, 0.03776922449469566\n",
      "Layer: model.layers.11.mlp.down_proj | Similarity with GT Delta: 0.9899\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  43%|██████████████████████████████▏                                       | 85/197 [00:43<01:18,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.12.self_attn.q_proj | 111.01239776611328, 110.46485900878906, 0.1445566713809967, 0.0941631868481636\n",
      "Layer: model.layers.12.self_attn.q_proj | Similarity with GT Delta: 0.9791\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.12.self_attn.k_proj | 39.572689056396484, 36.60842514038086, 0.04573749378323555, 0.03609710931777954\n",
      "Layer: model.layers.12.self_attn.k_proj | Similarity with GT Delta: 0.9291\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.12.self_attn.v_proj | 38.740211486816406, 37.36473846435547, 0.05157984793186188, 0.04936651512980461\n",
      "Layer: model.layers.12.self_attn.v_proj | Similarity with GT Delta: 0.9274\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  45%|███████████████████████████████▎                                      | 88/197 [00:43<00:41,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.12.self_attn.o_proj | 110.07315063476562, 108.2112045288086, 0.19404976069927216, 0.10633488744497299\n",
      "Layer: model.layers.12.self_attn.o_proj | Similarity with GT Delta: 0.9792\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  45%|███████████████████████████████▌                                      | 89/197 [00:44<00:47,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.12.mlp.gate_proj | 283.2618408203125, 279.18048095703125, 0.9257503151893616, 0.17418599128723145\n",
      "Layer: model.layers.12.mlp.gate_proj | Similarity with GT Delta: 0.9895\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  46%|███████████████████████████████▉                                      | 90/197 [00:45<00:52,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.12.mlp.up_proj | 276.7546691894531, 267.1258850097656, 0.5544308423995972, 0.2201249748468399\n",
      "Layer: model.layers.12.mlp.up_proj | Similarity with GT Delta: 0.9862\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  46%|████████████████████████████████▎                                     | 91/197 [00:46<01:24,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.12.mlp.down_proj | 274.11285400390625, 272.1598815917969, 0.26305198669433594, 0.06814450770616531\n",
      "Layer: model.layers.12.mlp.down_proj | Similarity with GT Delta: 0.9806\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  47%|████████████████████████████████▋                                     | 92/197 [00:47<01:08,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.13.self_attn.q_proj | 110.5389175415039, 110.38910675048828, 0.2077789306640625, 0.09598813951015472\n",
      "Layer: model.layers.13.self_attn.q_proj | Similarity with GT Delta: 0.9814\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.13.self_attn.k_proj | 39.80934524536133, 35.41564178466797, 0.08535709232091904, 0.05173316225409508\n",
      "Layer: model.layers.13.self_attn.k_proj | Similarity with GT Delta: 0.9416\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.13.self_attn.v_proj | 38.738861083984375, 37.72490310668945, 0.04791073501110077, 0.03782567009329796\n",
      "Layer: model.layers.13.self_attn.v_proj | Similarity with GT Delta: 0.9328\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  48%|█████████████████████████████████▊                                    | 95/197 [00:47<00:36,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.13.self_attn.o_proj | 112.36717987060547, 105.55532836914062, 0.14523658156394958, 0.12409108877182007\n",
      "Layer: model.layers.13.self_attn.o_proj | Similarity with GT Delta: 0.9809\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  49%|██████████████████████████████████                                    | 96/197 [00:47<00:41,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.13.mlp.gate_proj | 276.7406311035156, 273.4859619140625, 0.6745027303695679, 0.18833349645137787\n",
      "Layer: model.layers.13.mlp.gate_proj | Similarity with GT Delta: 0.9876\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  49%|██████████████████████████████████▍                                   | 97/197 [00:48<00:46,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.13.mlp.up_proj | 281.2792663574219, 273.6503601074219, 0.5997910499572754, 0.21204641461372375\n",
      "Layer: model.layers.13.mlp.up_proj | Similarity with GT Delta: 0.9900\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  50%|██████████████████████████████████▊                                   | 98/197 [00:50<01:15,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.13.mlp.down_proj | 278.35748291015625, 270.3955993652344, 0.2559039890766144, 0.07582943886518478\n",
      "Layer: model.layers.13.mlp.down_proj | Similarity with GT Delta: 0.9811\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  50%|███████████████████████████████████▏                                  | 99/197 [00:50<01:00,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.14.self_attn.q_proj | 110.22110748291016, 109.42473602294922, 0.12223678827285767, 0.07883540540933609\n",
      "Layer: model.layers.14.self_attn.q_proj | Similarity with GT Delta: 0.9806\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.14.self_attn.k_proj | 38.50234603881836, 36.7510986328125, 0.0483417846262455, 0.03137435019016266\n",
      "Layer: model.layers.14.self_attn.k_proj | Similarity with GT Delta: 0.9395\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.14.self_attn.v_proj | 39.9095344543457, 37.969970703125, 0.07270173728466034, 0.031338877975940704\n",
      "Layer: model.layers.14.self_attn.v_proj | Similarity with GT Delta: 0.9273\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  52%|███████████████████████████████████▋                                 | 102/197 [00:50<00:31,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.14.self_attn.o_proj | 109.67046356201172, 108.27428436279297, 0.13120463490486145, 0.07248702645301819\n",
      "Layer: model.layers.14.self_attn.o_proj | Similarity with GT Delta: 0.9780\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  52%|████████████████████████████████████                                 | 103/197 [00:51<00:36,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.14.mlp.gate_proj | 276.0188903808594, 270.9357604980469, 0.6892342567443848, 0.17299555242061615\n",
      "Layer: model.layers.14.mlp.gate_proj | Similarity with GT Delta: 0.9879\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  53%|████████████████████████████████████▍                                | 104/197 [00:51<00:41,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.14.mlp.up_proj | 282.3651428222656, 271.6136779785156, 0.5055112838745117, 0.16590264439582825\n",
      "Layer: model.layers.14.mlp.up_proj | Similarity with GT Delta: 0.9893\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  53%|████████████████████████████████████▊                                | 105/197 [00:53<01:07,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.14.mlp.down_proj | 280.7732849121094, 272.6461181640625, 0.27798521518707275, 0.10951904952526093\n",
      "Layer: model.layers.14.mlp.down_proj | Similarity with GT Delta: 0.9860\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  54%|█████████████████████████████████████▏                               | 106/197 [00:53<00:54,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.15.self_attn.q_proj | 111.44007873535156, 109.1690902709961, 0.1671949177980423, 0.1364515721797943\n",
      "Layer: model.layers.15.self_attn.q_proj | Similarity with GT Delta: 0.9826\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.15.self_attn.k_proj | 38.99250411987305, 35.90082931518555, 0.0493631549179554, 0.04275345429778099\n",
      "Layer: model.layers.15.self_attn.k_proj | Similarity with GT Delta: 0.9420\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.15.self_attn.v_proj | 39.445125579833984, 38.14332962036133, 0.054361630231142044, 0.044958651065826416\n",
      "Layer: model.layers.15.self_attn.v_proj | Similarity with GT Delta: 0.9395\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  55%|██████████████████████████████████████▏                              | 109/197 [00:54<00:28,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.15.self_attn.o_proj | 110.67411804199219, 109.66769409179688, 0.1373947113752365, 0.09553930908441544\n",
      "Layer: model.layers.15.self_attn.o_proj | Similarity with GT Delta: 0.9797\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  56%|██████████████████████████████████████▌                              | 110/197 [00:54<00:35,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.15.mlp.gate_proj | 275.84625244140625, 275.00445556640625, 0.7775593400001526, 0.1341181993484497\n",
      "Layer: model.layers.15.mlp.gate_proj | Similarity with GT Delta: 0.9878\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  56%|██████████████████████████████████████▉                              | 111/197 [00:55<00:39,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.15.mlp.up_proj | 280.5062255859375, 278.74981689453125, 0.5178309679031372, 0.16789256036281586\n",
      "Layer: model.layers.15.mlp.up_proj | Similarity with GT Delta: 0.9871\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  57%|███████████████████████████████████████▏                             | 112/197 [00:57<01:03,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.15.mlp.down_proj | 280.8782958984375, 277.8939514160156, 0.2795078158378601, 0.05738886073231697\n",
      "Layer: model.layers.15.mlp.down_proj | Similarity with GT Delta: 0.9822\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  57%|███████████████████████████████████████▌                             | 113/197 [00:57<00:50,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.16.self_attn.q_proj | 111.37142944335938, 106.7929916381836, 0.23215050995349884, 0.07539543509483337\n",
      "Layer: model.layers.16.self_attn.q_proj | Similarity with GT Delta: 0.9770\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.16.self_attn.k_proj | 39.927955627441406, 38.04740905761719, 0.10524144768714905, 0.052171677350997925\n",
      "Layer: model.layers.16.self_attn.k_proj | Similarity with GT Delta: 0.9333\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.16.self_attn.v_proj | 37.59397506713867, 36.012882232666016, 0.047051310539245605, 0.03621501848101616\n",
      "Layer: model.layers.16.self_attn.v_proj | Similarity with GT Delta: 0.9376\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  59%|████████████████████████████████████████▋                            | 116/197 [00:57<00:26,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.16.self_attn.o_proj | 110.1729736328125, 107.65238952636719, 0.12780147790908813, 0.08801715821027756\n",
      "Layer: model.layers.16.self_attn.o_proj | Similarity with GT Delta: 0.9810\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  59%|████████████████████████████████████████▉                            | 117/197 [00:58<00:33,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.16.mlp.gate_proj | 281.87213134765625, 277.533203125, 0.9412097930908203, 0.16034838557243347\n",
      "Layer: model.layers.16.mlp.gate_proj | Similarity with GT Delta: 0.9916\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  60%|█████████████████████████████████████████▎                           | 118/197 [00:59<00:40,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.16.mlp.up_proj | 275.3270568847656, 270.7093200683594, 0.5499832034111023, 0.25733333826065063\n",
      "Layer: model.layers.16.mlp.up_proj | Similarity with GT Delta: 0.9873\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  60%|█████████████████████████████████████████▋                           | 119/197 [01:00<01:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.16.mlp.down_proj | 276.1710510253906, 275.00067138671875, 0.38797059655189514, 0.044239919632673264\n",
      "Layer: model.layers.16.mlp.down_proj | Similarity with GT Delta: 0.9868\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  61%|██████████████████████████████████████████                           | 120/197 [01:00<00:49,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.17.self_attn.q_proj | 112.30655670166016, 108.8755111694336, 0.2530466616153717, 0.06904374063014984\n",
      "Layer: model.layers.17.self_attn.q_proj | Similarity with GT Delta: 0.9817\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.17.self_attn.k_proj | 39.828651428222656, 37.739776611328125, 0.10788936913013458, 0.049015626311302185\n",
      "Layer: model.layers.17.self_attn.k_proj | Similarity with GT Delta: 0.9449\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.17.self_attn.v_proj | 40.16897964477539, 35.471858978271484, 0.11596398800611496, 0.06181235983967781\n",
      "Layer: model.layers.17.self_attn.v_proj | Similarity with GT Delta: 0.9363\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  62%|███████████████████████████████████████████                          | 123/197 [01:01<00:25,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.17.self_attn.o_proj | 111.37178802490234, 107.47724914550781, 0.17080168426036835, 0.11719631403684616\n",
      "Layer: model.layers.17.self_attn.o_proj | Similarity with GT Delta: 0.9837\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  63%|███████████████████████████████████████████▍                         | 124/197 [01:01<00:29,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.17.mlp.gate_proj | 274.6238708496094, 270.4223937988281, 1.1046768426895142, 0.15394844114780426\n",
      "Layer: model.layers.17.mlp.gate_proj | Similarity with GT Delta: 0.9884\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  63%|███████████████████████████████████████████▊                         | 125/197 [01:02<00:32,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.17.mlp.up_proj | 277.0458984375, 272.542236328125, 0.6274974346160889, 0.29970690608024597\n",
      "Layer: model.layers.17.mlp.up_proj | Similarity with GT Delta: 0.9916\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  64%|████████████████████████████████████████████▏                        | 126/197 [01:04<00:53,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.17.mlp.down_proj | 275.9671630859375, 271.9403076171875, 0.3176044821739197, 0.035258788615465164\n",
      "Layer: model.layers.17.mlp.down_proj | Similarity with GT Delta: 0.9874\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  64%|████████████████████████████████████████████▍                        | 127/197 [01:04<00:43,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.18.self_attn.q_proj | 110.42918395996094, 107.10454559326172, 0.3243634104728699, 0.06465329974889755\n",
      "Layer: model.layers.18.self_attn.q_proj | Similarity with GT Delta: 0.9834\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.18.self_attn.k_proj | 39.03596496582031, 37.54548645019531, 0.07657285034656525, 0.044542912393808365\n",
      "Layer: model.layers.18.self_attn.k_proj | Similarity with GT Delta: 0.9500\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.18.self_attn.v_proj | 39.14024353027344, 38.33680725097656, 0.0455276258289814, 0.033524930477142334\n",
      "Layer: model.layers.18.self_attn.v_proj | Similarity with GT Delta: 0.9463\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  66%|█████████████████████████████████████████████▌                       | 130/197 [01:04<00:22,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.18.self_attn.o_proj | 112.39617919921875, 109.28357696533203, 0.18361587822437286, 0.10685648024082184\n",
      "Layer: model.layers.18.self_attn.o_proj | Similarity with GT Delta: 0.9800\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  66%|█████████████████████████████████████████████▉                       | 131/197 [01:05<00:27,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.18.mlp.gate_proj | 273.6048889160156, 268.865478515625, 0.7916801571846008, 0.16358104348182678\n",
      "Layer: model.layers.18.mlp.gate_proj | Similarity with GT Delta: 0.9906\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  67%|██████████████████████████████████████████████▏                      | 132/197 [01:05<00:30,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.18.mlp.up_proj | 277.2304382324219, 276.5451354980469, 0.573366105556488, 0.3060220181941986\n",
      "Layer: model.layers.18.mlp.up_proj | Similarity with GT Delta: 0.9887\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  68%|██████████████████████████████████████████████▌                      | 133/197 [01:07<00:50,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.18.mlp.down_proj | 276.2782897949219, 271.5544128417969, 0.3607039451599121, 0.03558184206485748\n",
      "Layer: model.layers.18.mlp.down_proj | Similarity with GT Delta: 0.9864\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  68%|██████████████████████████████████████████████▉                      | 134/197 [01:08<00:40,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.19.self_attn.q_proj | 110.83521270751953, 109.043701171875, 0.23147790133953094, 0.06263015419244766\n",
      "Layer: model.layers.19.self_attn.q_proj | Similarity with GT Delta: 0.9816\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.19.self_attn.k_proj | 38.7314338684082, 37.795623779296875, 0.04403253272175789, 0.04068448767066002\n",
      "Layer: model.layers.19.self_attn.k_proj | Similarity with GT Delta: 0.9461\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.19.self_attn.v_proj | 38.230987548828125, 37.469329833984375, 0.0877838209271431, 0.04421813786029816\n",
      "Layer: model.layers.19.self_attn.v_proj | Similarity with GT Delta: 0.9411\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  70%|███████████████████████████████████████████████▉                     | 137/197 [01:08<00:21,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.19.self_attn.o_proj | 111.51698303222656, 108.58216857910156, 0.1483129858970642, 0.0721948966383934\n",
      "Layer: model.layers.19.self_attn.o_proj | Similarity with GT Delta: 0.9814\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  70%|████████████████████████████████████████████████▎                    | 138/197 [01:08<00:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.19.mlp.gate_proj | 281.2154235839844, 271.5481872558594, 0.6487441658973694, 0.17094583809375763\n",
      "Layer: model.layers.19.mlp.gate_proj | Similarity with GT Delta: 0.9879\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  71%|████████████████████████████████████████████████▋                    | 139/197 [01:09<00:26,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.19.mlp.up_proj | 276.48541259765625, 274.5344543457031, 0.44392529129981995, 0.26541244983673096\n",
      "Layer: model.layers.19.mlp.up_proj | Similarity with GT Delta: 0.9826\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  71%|█████████████████████████████████████████████████                    | 140/197 [01:11<00:43,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.19.mlp.down_proj | 273.21099853515625, 272.003662109375, 0.32191917300224304, 0.03453708440065384\n",
      "Layer: model.layers.19.mlp.down_proj | Similarity with GT Delta: 0.9861\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  72%|█████████████████████████████████████████████████▍                   | 141/197 [01:11<00:34,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.20.self_attn.q_proj | 111.53251647949219, 110.16461181640625, 0.20509123802185059, 0.10240726172924042\n",
      "Layer: model.layers.20.self_attn.q_proj | Similarity with GT Delta: 0.9793\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.20.self_attn.k_proj | 37.318031311035156, 36.10966110229492, 0.058422066271305084, 0.03639904037117958\n",
      "Layer: model.layers.20.self_attn.k_proj | Similarity with GT Delta: 0.9392\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.20.self_attn.v_proj | 38.784847259521484, 36.743255615234375, 0.04552547261118889, 0.03282822668552399\n",
      "Layer: model.layers.20.self_attn.v_proj | Similarity with GT Delta: 0.9392\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  73%|██████████████████████████████████████████████████▍                  | 144/197 [01:11<00:17,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.20.self_attn.o_proj | 109.88546752929688, 109.56369018554688, 0.10263765603303909, 0.07127542793750763\n",
      "Layer: model.layers.20.self_attn.o_proj | Similarity with GT Delta: 0.9790\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  74%|██████████████████████████████████████████████████▊                  | 145/197 [01:12<00:20,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.20.mlp.gate_proj | 275.4870910644531, 271.4277038574219, 1.004343032836914, 0.1571260392665863\n",
      "Layer: model.layers.20.mlp.gate_proj | Similarity with GT Delta: 0.9921\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  74%|███████████████████████████████████████████████████▏                 | 146/197 [01:12<00:22,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.20.mlp.up_proj | 275.2750244140625, 270.6521911621094, 0.6343724131584167, 0.1608044058084488\n",
      "Layer: model.layers.20.mlp.up_proj | Similarity with GT Delta: 0.9932\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  75%|███████████████████████████████████████████████████▍                 | 147/197 [01:14<00:36,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.20.mlp.down_proj | 281.25933837890625, 272.65576171875, 0.32248273491859436, 0.03319647163152695\n",
      "Layer: model.layers.20.mlp.down_proj | Similarity with GT Delta: 0.9844\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  75%|███████████████████████████████████████████████████▊                 | 148/197 [01:14<00:29,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.21.self_attn.q_proj | 111.31095886230469, 108.9306640625, 0.10022396594285965, 0.08656185120344162\n",
      "Layer: model.layers.21.self_attn.q_proj | Similarity with GT Delta: 0.9792\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.21.self_attn.k_proj | 40.199951171875, 37.93290328979492, 0.0512516088783741, 0.03330208733677864\n",
      "Layer: model.layers.21.self_attn.k_proj | Similarity with GT Delta: 0.9448\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.21.self_attn.v_proj | 37.76042938232422, 34.69292068481445, 0.08171819150447845, 0.03603323549032211\n",
      "Layer: model.layers.21.self_attn.v_proj | Similarity with GT Delta: 0.9479\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  77%|████████████████████████████████████████████████████▉                | 151/197 [01:15<00:15,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.21.self_attn.o_proj | 111.63408660888672, 108.21355438232422, 0.16806884109973907, 0.05325572192668915\n",
      "Layer: model.layers.21.self_attn.o_proj | Similarity with GT Delta: 0.9749\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.21.mlp.gate_proj | 274.2074279785156, 265.13458251953125, 0.9907698035240173, 0.13417832553386688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  77%|█████████████████████████████████████████████████████▏               | 152/197 [01:15<00:19,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.21.mlp.gate_proj | Similarity with GT Delta: 0.9909\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  78%|█████████████████████████████████████████████████████▌               | 153/197 [01:16<00:22,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.21.mlp.up_proj | 278.81695556640625, 270.4696350097656, 0.5482696890830994, 0.1700267195701599\n",
      "Layer: model.layers.21.mlp.up_proj | Similarity with GT Delta: 0.9889\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  78%|█████████████████████████████████████████████████████▉               | 154/197 [01:18<00:34,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.21.mlp.down_proj | 279.2121276855469, 275.1603088378906, 0.3674505650997162, 0.03502563014626503\n",
      "Layer: model.layers.21.mlp.down_proj | Similarity with GT Delta: 0.9913\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  79%|██████████████████████████████████████████████████████▎              | 155/197 [01:18<00:27,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.22.self_attn.q_proj | 112.00166320800781, 110.05059051513672, 0.18571554124355316, 0.0583159476518631\n",
      "Layer: model.layers.22.self_attn.q_proj | Similarity with GT Delta: 0.9796\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.22.self_attn.k_proj | 39.07984161376953, 37.925296783447266, 0.05204858258366585, 0.034946613013744354\n",
      "Layer: model.layers.22.self_attn.k_proj | Similarity with GT Delta: 0.9432\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.22.self_attn.v_proj | 38.80064392089844, 36.38239288330078, 0.06109244376420975, 0.03575604781508446\n",
      "Layer: model.layers.22.self_attn.v_proj | Similarity with GT Delta: 0.9447\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  80%|███████████████████████████████████████████████████████▎             | 158/197 [01:18<00:13,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.22.self_attn.o_proj | 111.63626861572266, 108.78975677490234, 0.12012165784835815, 0.07909326255321503\n",
      "Layer: model.layers.22.self_attn.o_proj | Similarity with GT Delta: 0.9792\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  81%|███████████████████████████████████████████████████████▋             | 159/197 [01:19<00:15,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.22.mlp.gate_proj | 276.8620910644531, 270.01019287109375, 0.7707730531692505, 0.16903343796730042\n",
      "Layer: model.layers.22.mlp.gate_proj | Similarity with GT Delta: 0.9911\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  81%|████████████████████████████████████████████████████████             | 160/197 [01:20<00:18,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.22.mlp.up_proj | 277.35650634765625, 269.172607421875, 0.6120890378952026, 0.15810653567314148\n",
      "Layer: model.layers.22.mlp.up_proj | Similarity with GT Delta: 0.9921\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  82%|████████████████████████████████████████████████████████▍            | 161/197 [01:22<00:34,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.22.mlp.down_proj | 278.2409362792969, 271.94940185546875, 0.4274173378944397, 0.038949593901634216\n",
      "Layer: model.layers.22.mlp.down_proj | Similarity with GT Delta: 0.9884\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  82%|████████████████████████████████████████████████████████▋            | 162/197 [01:22<00:26,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.23.self_attn.q_proj | 112.37100982666016, 109.91889953613281, 0.1740429401397705, 0.06292832642793655\n",
      "Layer: model.layers.23.self_attn.q_proj | Similarity with GT Delta: 0.9836\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.23.self_attn.k_proj | 39.00136184692383, 38.489864349365234, 0.038923971354961395, 0.032140713185071945\n",
      "Layer: model.layers.23.self_attn.k_proj | Similarity with GT Delta: 0.9407\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.23.self_attn.v_proj | 38.70315170288086, 36.034996032714844, 0.05201216787099838, 0.02805844508111477\n",
      "Layer: model.layers.23.self_attn.v_proj | Similarity with GT Delta: 0.9437\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  84%|█████████████████████████████████████████████████████████▊           | 165/197 [01:23<00:13,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.23.self_attn.o_proj | 109.77008056640625, 107.47990417480469, 0.1486213356256485, 0.06894455850124359\n",
      "Layer: model.layers.23.self_attn.o_proj | Similarity with GT Delta: 0.9802\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.23.mlp.gate_proj | 278.0340270996094, 273.5116882324219, 0.841010332107544, 0.1258513182401657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  84%|██████████████████████████████████████████████████████████▏          | 166/197 [01:24<00:15,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.23.mlp.gate_proj | Similarity with GT Delta: 0.9905\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  85%|██████████████████████████████████████████████████████████▍          | 167/197 [01:24<00:17,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.23.mlp.up_proj | 276.887939453125, 261.5813293457031, 0.5560832023620605, 0.1395244002342224\n",
      "Layer: model.layers.23.mlp.up_proj | Similarity with GT Delta: 0.9904\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  85%|██████████████████████████████████████████████████████████▊          | 168/197 [01:26<00:24,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.23.mlp.down_proj | 277.0162658691406, 265.4448547363281, 0.4004605710506439, 0.038935258984565735\n",
      "Layer: model.layers.23.mlp.down_proj | Similarity with GT Delta: 0.9884\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  86%|███████████████████████████████████████████████████████████▏         | 169/197 [01:26<00:19,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.24.self_attn.q_proj | 112.3567886352539, 106.86404418945312, 0.2242582142353058, 0.06560062617063522\n",
      "Layer: model.layers.24.self_attn.q_proj | Similarity with GT Delta: 0.9839\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.24.self_attn.k_proj | 38.85023880004883, 37.70838928222656, 0.05851459130644798, 0.03212250769138336\n",
      "Layer: model.layers.24.self_attn.k_proj | Similarity with GT Delta: 0.9479\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.24.self_attn.v_proj | 38.714576721191406, 38.1502571105957, 0.16076987981796265, 0.024743111804127693\n",
      "Layer: model.layers.24.self_attn.v_proj | Similarity with GT Delta: 0.9493\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  87%|████████████████████████████████████████████████████████████▏        | 172/197 [01:27<00:09,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.24.self_attn.o_proj | 111.43502807617188, 110.87969970703125, 0.18136820197105408, 0.06980206072330475\n",
      "Layer: model.layers.24.self_attn.o_proj | Similarity with GT Delta: 0.9738\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  88%|████████████████████████████████████████████████████████████▌        | 173/197 [01:27<00:10,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.24.mlp.gate_proj | 279.1400146484375, 272.120361328125, 0.5838091373443604, 0.1239049881696701\n",
      "Layer: model.layers.24.mlp.gate_proj | Similarity with GT Delta: 0.9898\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  88%|████████████████████████████████████████████████████████████▉        | 174/197 [01:28<00:10,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.24.mlp.up_proj | 277.0525207519531, 274.2684326171875, 0.5944727063179016, 0.10929163545370102\n",
      "Layer: model.layers.24.mlp.up_proj | Similarity with GT Delta: 0.9882\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  89%|█████████████████████████████████████████████████████████████▎       | 175/197 [01:30<00:17,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.24.mlp.down_proj | 274.1455383300781, 270.7792053222656, 0.44574862718582153, 0.03146762773394585\n",
      "Layer: model.layers.24.mlp.down_proj | Similarity with GT Delta: 0.9920\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  89%|█████████████████████████████████████████████████████████████▋       | 176/197 [01:30<00:13,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.25.self_attn.q_proj | 113.21033477783203, 110.73108673095703, 0.2139054536819458, 0.07609104365110397\n",
      "Layer: model.layers.25.self_attn.q_proj | Similarity with GT Delta: 0.9783\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.25.self_attn.k_proj | 38.81414794921875, 36.44108581542969, 0.06476050615310669, 0.03043142333626747\n",
      "Layer: model.layers.25.self_attn.k_proj | Similarity with GT Delta: 0.9442\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.25.self_attn.v_proj | 39.05497360229492, 38.3491096496582, 0.13970328867435455, 0.03442889451980591\n",
      "Layer: model.layers.25.self_attn.v_proj | Similarity with GT Delta: 0.9138\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  91%|██████████████████████████████████████████████████████████████▋      | 179/197 [01:30<00:06,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.25.self_attn.o_proj | 110.38140106201172, 108.28736114501953, 0.24067933857440948, 0.03806107118725777\n",
      "Layer: model.layers.25.self_attn.o_proj | Similarity with GT Delta: 0.9872\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  91%|███████████████████████████████████████████████████████████████      | 180/197 [01:31<00:07,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.25.mlp.gate_proj | 279.3456726074219, 276.4491271972656, 1.1169087886810303, 0.09005490690469742\n",
      "Layer: model.layers.25.mlp.gate_proj | Similarity with GT Delta: 0.9931\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  92%|███████████████████████████████████████████████████████████████▍     | 181/197 [01:32<00:08,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.25.mlp.up_proj | 278.8735656738281, 276.3610534667969, 1.0454851388931274, 0.10543873906135559\n",
      "Layer: model.layers.25.mlp.up_proj | Similarity with GT Delta: 0.9951\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  92%|███████████████████████████████████████████████████████████████▋     | 182/197 [01:34<00:13,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.25.mlp.down_proj | 276.4455871582031, 273.4921569824219, 0.30411496758461, 0.049024228006601334\n",
      "Layer: model.layers.25.mlp.down_proj | Similarity with GT Delta: 0.9862\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  93%|████████████████████████████████████████████████████████████████     | 183/197 [01:34<00:10,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.26.self_attn.q_proj | 110.07878875732422, 109.00446319580078, 0.16488775610923767, 0.058232903480529785\n",
      "Layer: model.layers.26.self_attn.q_proj | Similarity with GT Delta: 0.9779\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.26.self_attn.k_proj | 39.457115173339844, 38.325042724609375, 0.03399258106946945, 0.028621802106499672\n",
      "Layer: model.layers.26.self_attn.k_proj | Similarity with GT Delta: 0.9436\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.26.self_attn.v_proj | 40.214012145996094, 37.67263412475586, 0.09901975840330124, 0.02945864386856556\n",
      "Layer: model.layers.26.self_attn.v_proj | Similarity with GT Delta: 0.9443\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  94%|█████████████████████████████████████████████████████████████████▏   | 186/197 [01:34<00:04,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.26.self_attn.o_proj | 111.42637634277344, 108.66690063476562, 0.19790475070476532, 0.07407218217849731\n",
      "Layer: model.layers.26.self_attn.o_proj | Similarity with GT Delta: 0.9764\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  95%|█████████████████████████████████████████████████████████████████▍   | 187/197 [01:35<00:04,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.26.mlp.gate_proj | 274.0673828125, 268.7582702636719, 1.405515432357788, 0.07168006151914597\n",
      "Layer: model.layers.26.mlp.gate_proj | Similarity with GT Delta: 0.9943\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  95%|█████████████████████████████████████████████████████████████████▊   | 188/197 [01:36<00:04,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.26.mlp.up_proj | 278.0096740722656, 276.13232421875, 1.4271153211593628, 0.08147498965263367\n",
      "Layer: model.layers.26.mlp.up_proj | Similarity with GT Delta: 0.9897\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  96%|██████████████████████████████████████████████████████████████████▏  | 189/197 [01:38<00:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.26.mlp.down_proj | 277.1803894042969, 273.0318603515625, 0.6283296346664429, 0.1640027016401291\n",
      "Layer: model.layers.26.mlp.down_proj | Similarity with GT Delta: 0.9907\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  96%|██████████████████████████████████████████████████████████████████▌  | 190/197 [01:38<00:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.27.self_attn.q_proj | 111.46566772460938, 109.5405044555664, 0.1684560775756836, 0.08194519579410553\n",
      "Layer: model.layers.27.self_attn.q_proj | Similarity with GT Delta: 0.9809\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.27.self_attn.k_proj | 39.51285934448242, 38.94816207885742, 0.044218774884939194, 0.0297615434974432\n",
      "Layer: model.layers.27.self_attn.k_proj | Similarity with GT Delta: 0.9434\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n",
      "Layer: model.layers.27.self_attn.v_proj | 40.16179275512695, 37.19783020019531, 0.3939391076564789, 0.016476113349199295\n",
      "Layer: model.layers.27.self_attn.v_proj | Similarity with GT Delta: 0.9366\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  98%|███████████████████████████████████████████████████████████████████▌ | 193/197 [01:38<00:01,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.27.self_attn.o_proj | 110.674072265625, 109.43048095703125, 0.4649595618247986, 0.01790720969438553\n",
      "Layer: model.layers.27.self_attn.o_proj | Similarity with GT Delta: 0.9820\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  98%|███████████████████████████████████████████████████████████████████▉ | 194/197 [01:39<00:01,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.27.mlp.gate_proj | 276.4203186035156, 274.726806640625, 1.3655744791030884, 0.12721987068653107\n",
      "Layer: model.layers.27.mlp.gate_proj | Similarity with GT Delta: 0.9900\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering:  99%|████████████████████████████████████████████████████████████████████▎| 195/197 [01:39<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.27.mlp.up_proj | 279.9798889160156, 273.4003601074219, 1.3477942943572998, 0.10458143055438995\n",
      "Layer: model.layers.27.mlp.up_proj | Similarity with GT Delta: 0.9919\n",
      "size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering: 100%|█████████████████████████████████████████████████████████████████████| 197/197 [01:41<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layers.27.mlp.down_proj | 275.9679260253906, 273.4568786621094, 0.17545060813426971, 0.03926514461636543\n",
      "Layer: model.layers.27.mlp.down_proj | Similarity with GT Delta: 0.9711\n",
      "Keeping Base Weights for lm_head\n",
      "Saving recovered model to /mnt/e/untitled folder/codebase/LoRO_attack/recovered_qwen_1_5B_model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4022638341f4fdfa60198319d2105bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e0b86116c14423b5e8fea7ad374baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9836879ef6e4bf2aa45d0b37f35b55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e609823887834683a79b09ac3137ed07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. 配置\n",
    "# ==========================================\n",
    "# 你的 Base 模型 (攻击者先验)\n",
    "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "# 你的 GT 模型 (仅用于验证攻击结果)\n",
    "target_model_id = \"zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct\"\n",
    "# 混淆后的 Checkpoint 路径\n",
    "obfuscated_checkpoint = \"/mnt/e/untitled folder/codebase/LoRO_attack/loro_qwen_1_5B.pt\"\n",
    "# 恢复模型的保存路径\n",
    "save_path_recovered = \"/mnt/e/untitled folder/codebase/LoRO_attack/recovered_qwen_1_5B_model\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === 攻击关键参数 ===\n",
    "REMOVE_RANK = 24\n",
    "\n",
    "# ==========================================\n",
    "# 2. 模型加载\n",
    "# ==========================================\n",
    "print(f\"1. Loading Base Model (Prior): {base_model_id}...\")\n",
    "# 必须加 trust_remote_code=True 以支持 Qwen\n",
    "recovered_model = AutoModelForCausalLM.from_pretrained(base_model_id, trust_remote_code=True).to(device)\n",
    "\n",
    "print(f\"2. Loading Obfuscated Checkpoint: {obfuscated_checkpoint}...\")\n",
    "if not os.path.exists(obfuscated_checkpoint):\n",
    "    raise FileNotFoundError(\"混淆 Checkpoint 未找到，请先运行 Cell 1 生成。\")\n",
    "obfus_state_dict = torch.load(obfuscated_checkpoint, map_location=device)\n",
    "\n",
    "print(f\"3. Loading Ground Truth (Validation): {target_model_id}...\")\n",
    "gt_model = AutoModelForCausalLM.from_pretrained(target_model_id, trust_remote_code=True).to(device)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 执行 SVD 去噪攻击 (SVD Denoising)\n",
    "# ==========================================\n",
    "print(f\"\\nSTARTING RECOVERY (Removing Top-{REMOVE_RANK} Singular Values as Noise)...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "similarities = []\n",
    "relative_errors = []\n",
    "\n",
    "# 遍历 Base 模型的每一层\n",
    "# 我们需要修改 recovered_model 的权重\n",
    "all_modules = list(recovered_model.named_modules())\n",
    "linear_layers = [(n, m) for n, m in all_modules if isinstance(m, nn.Linear)]\n",
    "\n",
    "progress_bar = tqdm(linear_layers, desc=\"Recovering\")\n",
    "\n",
    "for name, module in progress_bar:\n",
    "\n",
    "    if \"lm_head\" in name:\n",
    "        print(f\"Keeping Base Weights for {name}\")\n",
    "        continue\n",
    "\n",
    "    # 1. 构造 LoRO 保存的 key\n",
    "    # 根据 LoroLinear 代码，权重保存在 \"obfus_linear.weight\n",
    "    obfus_key = f\"{name}.obfus_linear.weight\"\n",
    "    \n",
    "    # 检查该层是否被混淆 (如果没在 checkpoint 里找到，说明该层未混淆，保持 Base 原样)\n",
    "    if obfus_key not in obfus_state_dict:\n",
    "        continue\n",
    "        \n",
    "    # 2. 获取数据\n",
    "    W_base = module.weight.detach() # [out, in]\n",
    "    W_obfus = obfus_state_dict[obfus_key].detach() # [out, in]\n",
    "    \n",
    "    # 3. 计算 Diff (包含 Fine-tuning 更新 + LoRO 噪声)\n",
    "    # Diff = (W_base + Delta_FT + Noise) - W_base = Delta_FT + Noise\n",
    "    print(\"size of W_obfus: {W_obfus.shape} | size of W_base: {W_base.shape}\")\n",
    "    Diff = W_obfus - W_base\n",
    "    \n",
    "    # 4. SVD 分解\n",
    "    # 使用 float32 保证精度，Diff 形状通常是 [out_features, in_features]\n",
    "    U, S, Vh = torch.linalg.svd(Diff.float(), full_matrices=False)\n",
    "\n",
    "    print(f\"Layer: {name} | {S[REMOVE_RANK - 2]}, {S[REMOVE_RANK - 1]}, {S[REMOVE_RANK]}, {S[REMOVE_RANK + 1]}\")\n",
    "    \n",
    "    # --- 攻击核心逻辑 ---\n",
    "    # 根据 LoroLinear 定义，噪声是 (B@A).T，其秩为 r (REMOVE_RANK)。\n",
    "    # 且因为 noise_mag 很大，这 r 个奇异值会非常大，位于 S 的最前端。\n",
    "    # 我们将前 r 个奇异值置零，即移除了 LoRO 噪声。\n",
    "    S_clean = S.clone()\n",
    "    S_clean[:REMOVE_RANK] = 0.0 \n",
    "    \n",
    "    # 5. 重构纯净的 Delta (即估算的 Delta_FT)\n",
    "    Delta_Recovered = (U @ torch.diag(S_clean) @ Vh).to(W_base.dtype)\n",
    "    \n",
    "    # 6. 恢复权重并写入模型\n",
    "    # W_rec = W_base + Delta_Recovered\n",
    "    module.weight.data = W_base + Delta_Recovered\n",
    "    \n",
    "    # 7. 恢复 Bias\n",
    "    # LoroLinear 代码中: self.obfus_linear.bias = original_linear.bias\n",
    "    # Bias 没有加噪声，直接从 checkpoint 读取覆盖即可\n",
    "    obfus_bias_key = f\"{name}.obfus_linear.bias\"\n",
    "    if obfus_bias_key in obfus_state_dict and module.bias is not None:\n",
    "        module.bias.data = obfus_state_dict[obfus_bias_key].detach()\n",
    "    \n",
    "    # ==========================\n",
    "    # 验证环节 (对比 GT)\n",
    "    # ==========================\n",
    "    if name in dict(gt_model.named_modules()):\n",
    "        W_gt = dict(gt_model.named_modules())[name].weight.detach()\n",
    "        Delta_True = W_gt - W_base\n",
    "        \n",
    "        # 计算相似度: 我们的恢复结果 vs 真实的微调增量\n",
    "        # 如果 sim 接近 1.0，说明我们成功剥离了噪声，保留了微调增量\n",
    "        sim = torch.nn.functional.cosine_similarity(Delta_True.flatten(), Delta_Recovered.flatten(), dim=0).item()\n",
    "        \n",
    "        print(f\"Layer: {name} | Similarity with GT Delta: {sim:.4f}\")\n",
    "        \n",
    "        similarities.append(sim)\n",
    "        # progress_bar.set_postfix({\"Avg Sim\": f\"{sum(similarities)/len(similarities):.4f}\", \"Last Sim\": f\"{sim:.4f}\"})\n",
    "\n",
    "# ==========================================\n",
    "# 4. 结果保存\n",
    "# ==========================================\n",
    "\n",
    "print(f\"Saving recovered model to {save_path_recovered}...\")\n",
    "recovered_model.save_pretrained(save_path_recovered)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)\n",
    "tokenizer.save_pretrained(save_path_recovered)\n",
    "print(\"Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010ff3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Target Model (GT): zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct...\n",
      "Loading Recovered Model: /mnt/e/untitled folder/codebase/LoRO_attack/recovered_qwen_1_5B_model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c308545e2cb446fbd3c22de42581024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Comparison (Target GT vs. Recovered)...\n",
      "******************************************************************************************\n",
      "Layer Name                                         | Cos Sim    | Diff Norm    | Rel Diff (%)\n",
      "------------------------------------------------------------------------------------------\n",
      "model.layers.0.self_attn.q_proj | 1.000144   | 0.0425       | 0.0569%\n",
      "model.layers.0.self_attn.k_proj | 0.999990   | 0.0259       | 0.0739%\n",
      "model.layers.0.self_attn.v_proj | 0.999983   | 0.0297       | 0.2532%\n",
      "model.layers.0.self_attn.o_proj | 1.000018   | 0.0487       | 0.1383%\n",
      "model.layers.0.mlp.gate_proj | 1.000890   | 0.1093       | 0.0958%\n",
      "model.layers.0.mlp.up_proj | 1.000911   | 0.1012       | 0.1069%\n",
      "model.layers.0.mlp.down_proj | 1.000916   | 0.0669       | 0.0673%\n",
      "model.layers.1.self_attn.q_proj | 0.999997   | 0.0480       | 0.0939%\n",
      "model.layers.1.self_attn.k_proj | 0.999992   | 0.0344       | 0.1236%\n",
      "model.layers.1.self_attn.v_proj | 0.999981   | 0.0496       | 0.3931%\n",
      "model.layers.1.self_attn.o_proj | 1.000011   | 0.0633       | 0.1758%\n",
      "model.layers.1.mlp.gate_proj | 1.000742   | 0.1092       | 0.0914%\n",
      "model.layers.1.mlp.up_proj | 1.001016   | 0.1096       | 0.1026%\n",
      "model.layers.1.mlp.down_proj | 1.001001   | 0.3081       | 0.2987%\n",
      "model.layers.2.self_attn.q_proj | 1.000002   | 0.0451       | 0.0954%\n",
      "model.layers.2.self_attn.k_proj | 0.999986   | 0.0332       | 0.1444%\n",
      "model.layers.2.self_attn.v_proj | 0.999986   | 0.0460       | 0.3173%\n",
      "model.layers.2.self_attn.o_proj | 1.000011   | 0.0487       | 0.1251%\n",
      "model.layers.2.mlp.gate_proj | 1.000667   | 0.1090       | 0.0881%\n",
      "model.layers.2.mlp.up_proj | 1.000997   | 0.1100       | 0.1108%\n",
      "model.layers.2.mlp.down_proj | 1.000979   | 0.2414       | 0.2442%\n",
      "model.layers.3.self_attn.q_proj | 1.000014   | 0.0448       | 0.0928%\n",
      "model.layers.3.self_attn.k_proj | 0.999985   | 0.0374       | 0.1688%\n",
      "model.layers.3.self_attn.v_proj | 0.999988   | 0.0401       | 0.2451%\n",
      "model.layers.3.self_attn.o_proj | 1.000012   | 0.0536       | 0.1359%\n",
      "model.layers.3.mlp.gate_proj | 1.000649   | 0.1098       | 0.0855%\n",
      "model.layers.3.mlp.up_proj | 1.000935   | 0.1090       | 0.1138%\n",
      "model.layers.3.mlp.down_proj | 1.000898   | 0.0579       | 0.0612%\n",
      "model.layers.4.self_attn.q_proj | 1.000009   | 0.0492       | 0.1047%\n",
      "model.layers.4.self_attn.k_proj | 0.999985   | 0.0303       | 0.1451%\n",
      "model.layers.4.self_attn.v_proj | 0.999987   | 0.0376       | 0.2187%\n",
      "model.layers.4.self_attn.o_proj | 1.000012   | 0.0498       | 0.1241%\n",
      "model.layers.4.mlp.gate_proj | 1.000763   | 0.0977       | 0.0802%\n",
      "model.layers.4.mlp.up_proj | 1.000962   | 0.0991       | 0.1022%\n",
      "model.layers.4.mlp.down_proj | 1.000920   | 0.0629       | 0.0654%\n",
      "model.layers.5.self_attn.q_proj | 1.000014   | 0.0462       | 0.1043%\n",
      "model.layers.5.self_attn.k_proj | 0.999990   | 0.0282       | 0.1482%\n",
      "model.layers.5.self_attn.v_proj | 0.999985   | 0.0349       | 0.1841%\n",
      "model.layers.5.self_attn.o_proj | 1.000016   | 0.0453       | 0.1074%\n",
      "model.layers.5.mlp.gate_proj | 1.000716   | 0.1368       | 0.1111%\n",
      "model.layers.5.mlp.up_proj | 1.000968   | 0.1130       | 0.1149%\n",
      "model.layers.5.mlp.down_proj | 1.000931   | 0.0593       | 0.0622%\n",
      "model.layers.6.self_attn.q_proj | 1.000047   | 0.0472       | 0.1011%\n",
      "model.layers.6.self_attn.k_proj | 0.999988   | 0.0302       | 0.1446%\n",
      "model.layers.6.self_attn.v_proj | 0.999984   | 0.0660       | 0.3969%\n",
      "model.layers.6.self_attn.o_proj | 1.000012   | 0.0458       | 0.1243%\n",
      "model.layers.6.mlp.gate_proj | 1.000878   | 0.1252       | 0.1111%\n",
      "model.layers.6.mlp.up_proj | 1.000954   | 0.1047       | 0.1017%\n",
      "model.layers.6.mlp.down_proj | 1.000950   | 0.0636       | 0.0630%\n",
      "model.layers.7.self_attn.q_proj | 1.000029   | 0.0554       | 0.1221%\n",
      "model.layers.7.self_attn.k_proj | 0.999986   | 0.0362       | 0.1815%\n",
      "model.layers.7.self_attn.v_proj | 0.999985   | 0.0462       | 0.2665%\n",
      "model.layers.7.self_attn.o_proj | 1.000015   | 0.0482       | 0.1216%\n",
      "model.layers.7.mlp.gate_proj | 1.000936   | 0.1079       | 0.0986%\n",
      "model.layers.7.mlp.up_proj | 1.000969   | 0.1025       | 0.0974%\n",
      "model.layers.7.mlp.down_proj | 1.000985   | 0.0614       | 0.0595%\n",
      "model.layers.8.self_attn.q_proj | 1.000023   | 0.0446       | 0.0962%\n",
      "model.layers.8.self_attn.k_proj | 0.999985   | 0.0366       | 0.1858%\n",
      "model.layers.8.self_attn.v_proj | 0.999990   | 0.0373       | 0.2276%\n",
      "model.layers.8.self_attn.o_proj | 1.000014   | 0.0514       | 0.1313%\n",
      "model.layers.8.mlp.gate_proj | 1.000936   | 0.1033       | 0.0949%\n",
      "model.layers.8.mlp.up_proj | 1.000964   | 0.0992       | 0.0956%\n",
      "model.layers.8.mlp.down_proj | 1.000955   | 0.0688       | 0.0680%\n",
      "model.layers.9.self_attn.q_proj | 1.000041   | 0.0541       | 0.1160%\n",
      "model.layers.9.self_attn.k_proj | 0.999988   | 0.0320       | 0.1562%\n",
      "model.layers.9.self_attn.v_proj | 0.999987   | 0.0405       | 0.2489%\n",
      "model.layers.9.self_attn.o_proj | 1.000013   | 0.0557       | 0.1427%\n",
      "model.layers.9.mlp.gate_proj | 1.000944   | 0.1035       | 0.0976%\n",
      "model.layers.9.mlp.up_proj | 1.000968   | 0.1075       | 0.1034%\n",
      "model.layers.9.mlp.down_proj | 1.000975   | 0.0566       | 0.0557%\n",
      "model.layers.10.self_attn.q_proj | 1.000003   | 0.0514       | 0.1152%\n",
      "model.layers.10.self_attn.k_proj | 0.999989   | 0.0407       | 0.2192%\n",
      "model.layers.10.self_attn.v_proj | 0.999987   | 0.0341       | 0.1959%\n",
      "model.layers.10.self_attn.o_proj | 1.000018   | 0.0501       | 0.1211%\n",
      "model.layers.10.mlp.gate_proj | 1.000989   | 0.1180       | 0.1102%\n",
      "model.layers.10.mlp.up_proj | 1.000966   | 0.1049       | 0.1010%\n",
      "model.layers.10.mlp.down_proj | 1.000976   | 0.0716       | 0.0716%\n",
      "model.layers.11.self_attn.q_proj | 1.000014   | 0.0535       | 0.1193%\n",
      "model.layers.11.self_attn.k_proj | 0.999987   | 0.0334       | 0.1708%\n",
      "model.layers.11.self_attn.v_proj | 0.999987   | 0.0418       | 0.2557%\n",
      "model.layers.11.self_attn.o_proj | 1.000022   | 0.0486       | 0.1236%\n",
      "model.layers.11.mlp.gate_proj | 1.001006   | 0.1340       | 0.1220%\n",
      "model.layers.11.mlp.up_proj | 1.000984   | 0.1137       | 0.1105%\n",
      "model.layers.11.mlp.down_proj | 1.000984   | 0.0658       | 0.0669%\n",
      "model.layers.12.self_attn.q_proj | 1.000015   | 0.0545       | 0.1214%\n",
      "model.layers.12.self_attn.k_proj | 0.999985   | 0.0366       | 0.1892%\n",
      "model.layers.12.self_attn.v_proj | 0.999989   | 0.0403       | 0.2628%\n",
      "model.layers.12.self_attn.o_proj | 1.000021   | 0.0534       | 0.1394%\n",
      "model.layers.12.mlp.gate_proj | 1.001043   | 0.1582       | 0.1480%\n",
      "model.layers.12.mlp.up_proj | 1.000996   | 0.1192       | 0.1163%\n",
      "model.layers.12.mlp.down_proj | 1.000988   | 0.0643       | 0.0654%\n",
      "model.layers.13.self_attn.q_proj | 0.999992   | 0.0528       | 0.1155%\n",
      "model.layers.13.self_attn.k_proj | 0.999985   | 0.0464       | 0.2239%\n",
      "model.layers.13.self_attn.v_proj | 0.999990   | 0.0358       | 0.2242%\n",
      "model.layers.13.self_attn.o_proj | 1.000023   | 0.0537       | 0.1388%\n",
      "model.layers.13.mlp.gate_proj | 1.001045   | 0.1312       | 0.1254%\n",
      "model.layers.13.mlp.up_proj | 1.000995   | 0.1097       | 0.1075%\n",
      "model.layers.13.mlp.down_proj | 1.000977   | 0.0627       | 0.0638%\n",
      "model.layers.14.self_attn.q_proj | 1.000042   | 0.0454       | 0.1064%\n",
      "model.layers.14.self_attn.k_proj | 0.999989   | 0.0306       | 0.1697%\n",
      "model.layers.14.self_attn.v_proj | 0.999989   | 0.0413       | 0.2725%\n",
      "model.layers.14.self_attn.o_proj | 1.000034   | 0.0442       | 0.1171%\n",
      "model.layers.14.mlp.gate_proj | 1.001039   | 0.1311       | 0.1311%\n",
      "model.layers.14.mlp.up_proj | 1.001011   | 0.1004       | 0.0997%\n",
      "model.layers.14.mlp.down_proj | 1.000990   | 0.0590       | 0.0603%\n",
      "model.layers.15.self_attn.q_proj | 1.000017   | 0.0517       | 0.1130%\n",
      "model.layers.15.self_attn.k_proj | 0.999988   | 0.0352       | 0.1950%\n",
      "model.layers.15.self_attn.v_proj | 0.999986   | 0.0384       | 0.2205%\n",
      "model.layers.15.self_attn.o_proj | 1.000023   | 0.0518       | 0.1284%\n",
      "model.layers.15.mlp.gate_proj | 1.001085   | 0.1436       | 0.1382%\n",
      "model.layers.15.mlp.up_proj | 1.001005   | 0.1072       | 0.1053%\n",
      "model.layers.15.mlp.down_proj | 1.000980   | 0.0634       | 0.0650%\n",
      "model.layers.16.self_attn.q_proj | 1.000013   | 0.0598       | 0.1399%\n",
      "model.layers.16.self_attn.k_proj | 0.999988   | 0.0525       | 0.3023%\n",
      "model.layers.16.self_attn.v_proj | 0.999989   | 0.0330       | 0.2060%\n",
      "model.layers.16.self_attn.o_proj | 1.000028   | 0.0460       | 0.1180%\n",
      "model.layers.16.mlp.gate_proj | 1.001076   | 0.1465       | 0.1441%\n",
      "model.layers.16.mlp.up_proj | 1.001022   | 0.1187       | 0.1173%\n",
      "model.layers.16.mlp.down_proj | 1.000970   | 0.0728       | 0.0755%\n",
      "model.layers.17.self_attn.q_proj | 1.000041   | 0.0563       | 0.1399%\n",
      "model.layers.17.self_attn.k_proj | 0.999986   | 0.0470       | 0.3395%\n",
      "model.layers.17.self_attn.v_proj | 0.999984   | 0.0557       | 0.3015%\n",
      "model.layers.17.self_attn.o_proj | 1.000017   | 0.0499       | 0.1206%\n",
      "model.layers.17.mlp.gate_proj | 1.001091   | 0.1932       | 0.1889%\n",
      "model.layers.17.mlp.up_proj | 1.000999   | 0.1081       | 0.1045%\n",
      "model.layers.17.mlp.down_proj | 1.000981   | 0.0589       | 0.0596%\n",
      "model.layers.18.self_attn.q_proj | 1.000030   | 0.0651       | 0.1537%\n",
      "model.layers.18.self_attn.k_proj | 0.999988   | 0.0374       | 0.2175%\n",
      "model.layers.18.self_attn.v_proj | 0.999987   | 0.0315       | 0.1817%\n",
      "model.layers.18.self_attn.o_proj | 1.000016   | 0.0556       | 0.1396%\n",
      "model.layers.18.mlp.gate_proj | 1.001109   | 0.1311       | 0.1280%\n",
      "model.layers.18.mlp.up_proj | 1.001008   | 0.1168       | 0.1126%\n",
      "model.layers.18.mlp.down_proj | 1.001010   | 0.0688       | 0.0692%\n",
      "model.layers.19.self_attn.q_proj | 1.000038   | 0.0514       | 0.1237%\n",
      "model.layers.19.self_attn.k_proj | 0.999992   | 0.0319       | 0.2151%\n",
      "model.layers.19.self_attn.v_proj | 0.999986   | 0.0438       | 0.2513%\n",
      "model.layers.19.self_attn.o_proj | 1.000016   | 0.0442       | 0.1108%\n",
      "model.layers.19.mlp.gate_proj | 1.001108   | 0.1227       | 0.1202%\n",
      "model.layers.19.mlp.up_proj | 1.001027   | 0.1244       | 0.1162%\n",
      "model.layers.19.mlp.down_proj | 1.001029   | 0.0621       | 0.0608%\n",
      "model.layers.20.self_attn.q_proj | 1.000034   | 0.0533       | 0.1241%\n",
      "model.layers.20.self_attn.k_proj | 0.999990   | 0.0367       | 0.2413%\n",
      "model.layers.20.self_attn.v_proj | 0.999986   | 0.0322       | 0.1539%\n",
      "model.layers.20.self_attn.o_proj | 1.000009   | 0.0434       | 0.1018%\n",
      "model.layers.20.mlp.gate_proj | 1.001045   | 0.1488       | 0.1435%\n",
      "model.layers.20.mlp.up_proj | 1.000929   | 0.0921       | 0.0854%\n",
      "model.layers.20.mlp.down_proj | 1.000975   | 0.0655       | 0.0635%\n",
      "model.layers.21.self_attn.q_proj | 1.000025   | 0.0455       | 0.1111%\n",
      "model.layers.21.self_attn.k_proj | 0.999992   | 0.0331       | 0.2316%\n",
      "model.layers.21.self_attn.v_proj | 0.999985   | 0.0361       | 0.1731%\n",
      "model.layers.21.self_attn.o_proj | 1.000009   | 0.0517       | 0.1194%\n",
      "model.layers.21.mlp.gate_proj | 1.001060   | 0.1558       | 0.1493%\n",
      "model.layers.21.mlp.up_proj | 1.000958   | 0.1055       | 0.0969%\n",
      "model.layers.21.mlp.down_proj | 1.000998   | 0.0577       | 0.0556%\n",
      "model.layers.22.self_attn.q_proj | 1.000011   | 0.0481       | 0.1076%\n",
      "model.layers.22.self_attn.k_proj | 0.999991   | 0.0312       | 0.1850%\n",
      "model.layers.22.self_attn.v_proj | 0.999990   | 0.0353       | 0.1795%\n",
      "model.layers.22.self_attn.o_proj | 1.000007   | 0.0432       | 0.1001%\n",
      "model.layers.22.mlp.gate_proj | 1.001058   | 0.1248       | 0.1171%\n",
      "model.layers.22.mlp.up_proj | 1.000948   | 0.0982       | 0.0901%\n",
      "model.layers.22.mlp.down_proj | 1.001005   | 0.0742       | 0.0715%\n",
      "model.layers.23.self_attn.q_proj | 1.000051   | 0.0430       | 0.0997%\n",
      "model.layers.23.self_attn.k_proj | 0.999991   | 0.0301       | 0.2115%\n",
      "model.layers.23.self_attn.v_proj | 0.999987   | 0.0313       | 0.1585%\n",
      "model.layers.23.self_attn.o_proj | 1.000008   | 0.0435       | 0.1003%\n",
      "model.layers.23.mlp.gate_proj | 1.000991   | 0.1370       | 0.1286%\n",
      "model.layers.23.mlp.up_proj | 1.000903   | 0.0984       | 0.0891%\n",
      "model.layers.23.mlp.down_proj | 1.000978   | 0.0706       | 0.0663%\n",
      "model.layers.24.self_attn.q_proj | 1.000067   | 0.0472       | 0.1114%\n",
      "model.layers.24.self_attn.k_proj | 0.999991   | 0.0294       | 0.1950%\n",
      "model.layers.24.self_attn.v_proj | 0.999989   | 0.0560       | 0.2382%\n",
      "model.layers.24.self_attn.o_proj | 1.000010   | 0.0541       | 0.1133%\n",
      "model.layers.24.mlp.gate_proj | 1.000943   | 0.1020       | 0.0963%\n",
      "model.layers.24.mlp.up_proj | 1.000881   | 0.1110       | 0.0998%\n",
      "model.layers.24.mlp.down_proj | 1.000946   | 0.0659       | 0.0607%\n",
      "model.layers.25.self_attn.q_proj | 1.000036   | 0.0579       | 0.1332%\n",
      "model.layers.25.self_attn.k_proj | 0.999987   | 0.0326       | 0.2566%\n",
      "model.layers.25.self_attn.v_proj | 0.999982   | 0.0676       | 0.3447%\n",
      "model.layers.25.self_attn.o_proj | 1.000023   | 0.0414       | 0.0892%\n",
      "model.layers.25.mlp.gate_proj | 1.000967   | 0.1533       | 0.1476%\n",
      "model.layers.25.mlp.up_proj | 1.000858   | 0.1268       | 0.1124%\n",
      "model.layers.25.mlp.down_proj | 1.000908   | 0.0596       | 0.0540%\n",
      "model.layers.26.self_attn.q_proj | 1.000056   | 0.0450       | 0.1085%\n",
      "model.layers.26.self_attn.k_proj | 0.999991   | 0.0273       | 0.2042%\n",
      "model.layers.26.self_attn.v_proj | 0.999993   | 0.0405       | 0.1350%\n",
      "model.layers.26.self_attn.o_proj | 1.000002   | 0.0539       | 0.1037%\n",
      "model.layers.26.mlp.gate_proj | 1.000998   | 0.1754       | 0.1718%\n",
      "model.layers.26.mlp.up_proj | 1.000867   | 0.2284       | 0.2005%\n",
      "model.layers.26.mlp.down_proj | 1.000913   | 0.1009       | 0.0923%\n",
      "model.layers.27.self_attn.q_proj | 1.000027   | 0.0445       | 0.1108%\n",
      "model.layers.27.self_attn.k_proj | 0.999986   | 0.0294       | 0.2499%\n",
      "model.layers.27.self_attn.v_proj | 0.999978   | 0.1487       | 0.5245%\n",
      "model.layers.27.self_attn.o_proj | 1.000026   | 0.0914       | 0.1761%\n",
      "model.layers.27.mlp.gate_proj | 1.001020   | 0.2160       | 0.2100%\n",
      "model.layers.27.mlp.up_proj | 1.000989   | 0.1953       | 0.1851%\n",
      "model.layers.27.mlp.down_proj | 1.000951   | 0.0532       | 0.0567%\n",
      "lm_head | 1.079851   | 0.0000       | 0.0000%\n",
      "------------------------------------------------------------------------------------------\n",
      "Summary (Target vs Recovered):\n",
      "Avg Cosine Similarity: 1.000819 (Target: 1.0)\n",
      "Avg Relative Diff:     0.141848% (Target: 0.0%)\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 配置：对比 Ground Truth (Target) 与 恢复模型 (Recovered)\n",
    "# ==========================================\n",
    "\n",
    "target_model_id = \"zfdev/squad_v2-16bit-Qwen2.5-1.5B-Instruct\" \n",
    "recovered_model_path = \"/mnt/e/untitled folder/codebase/LoRO_attack/recovered_qwen_1_5B_model\"\n",
    "\n",
    "device = \"cpu\" # 对比只需 CPU 即可，省显存\n",
    "\n",
    "print(f\"Loading Target Model (GT): {target_model_id}...\")\n",
    "try:\n",
    "    model_gt = AutoModelForCausalLM.from_pretrained(target_model_id, trust_remote_code=True).to(device)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading GT model: {e}\")\n",
    "    # 如果显存不够，可以尝试加 device_map=\"cpu\" 或 torch_dtype=torch.float16\n",
    "\n",
    "print(f\"Loading Recovered Model: {recovered_model_path}...\")\n",
    "\n",
    "try:\n",
    "    model_recovered = AutoModelForCausalLM.from_pretrained(recovered_model_path, trust_remote_code=True).to(device)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading Recovered model: {e}\")\n",
    "    raise e\n",
    "\n",
    "print(\"\\nStarting Comparison (Target GT vs. Recovered)...\")\n",
    "print(\"*\" * 90)\n",
    "print(f\"{'Layer Name':<50} | {'Cos Sim':<10} | {'Diff Norm':<12} | {'Rel Diff (%)':<12}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "results = []\n",
    "modules_recovered = dict(model_recovered.named_modules())\n",
    "\n",
    "# 遍历 GT 模型的层\n",
    "for name, module_gt in model_gt.named_modules():\n",
    "    if isinstance(module_gt, torch.nn.Linear):\n",
    "        if name in modules_recovered:\n",
    "            module_rec = modules_recovered[name]\n",
    "            \n",
    "            # 获取权重\n",
    "            w_gt = module_gt.weight.detach()\n",
    "            w_rec = module_rec.weight.detach()\n",
    "            \n",
    "            # 检查形状\n",
    "            if w_gt.shape != w_rec.shape:\n",
    "                continue\n",
    "                \n",
    "            # 1. 计算余弦相似度\n",
    "            cos_sim = torch.nn.functional.cosine_similarity(\n",
    "                w_gt.flatten(), w_rec.flatten(), dim=0\n",
    "            ).item()\n",
    "            \n",
    "            # 2. 计算差异 (Diff = GT - Recovered)\n",
    "            # 如果攻击完美，Diff 应该全是 0\n",
    "            diff = w_gt - w_rec\n",
    "            norm_diff = torch.norm(diff).item()\n",
    "            norm_gt = torch.norm(w_gt).item()\n",
    "            \n",
    "            # 相对差异\n",
    "            rel_diff = norm_diff / norm_gt if norm_gt > 0 else 0.0\n",
    "            \n",
    "            # 打印结果 (只打印部分层，或者差异较大的层)\n",
    "            # 如果 Cos Sim < 0.99 或者 Diff 比较大，说明恢复有问题\n",
    "            print(f\"{name} | {cos_sim:.6f}   | {norm_diff:.4f}       | {rel_diff*100:.4f}%\")\n",
    "            \n",
    "            results.append({\n",
    "                \"Layer\": name, \n",
    "                \"Cos_Sim\": cos_sim, \n",
    "                \"Diff_Norm\": norm_diff, \n",
    "                \"Rel_Diff\": rel_diff\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"-\" * 90)\n",
    "print(f\"Summary (Target vs Recovered):\")\n",
    "print(f\"Avg Cosine Similarity: {df['Cos_Sim'].mean():.6f} (Target: 1.0)\")\n",
    "print(f\"Avg Relative Diff:     {df['Rel_Diff'].mean()*100:.6f}% (Target: 0.0%)\")\n",
    "print(\"-\" * 90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24512dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full-FT with Knockoff (skipped)\n",
    "# then test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ebdb8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7972e5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Recovered Model from: /mnt/e/untitled folder/codebase/LoRO_attack/recovered_qwen_1_5B_model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from '/mnt/e/untitled folder/codebase/LoRO_attack/recovered_qwen_1_5B_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923ea0a18e9b454d8550bf53e5ffd146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SQuAD v2 validation dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed49114903194dcebcd7496374bff276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b2f2afab164273b1814b469534a27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "squad_v2/train-00000-of-00001.parquet:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e61562b6e5844b4aa16297c64534e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "squad_v2/validation-00000-of-00001.parqu(…):   0%|          | 0.00/1.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee00953380a3438b85d688f858850c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd4c613129848008c042e5edda8138f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluating on 11873 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/11873 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "  0%|                                                      | 1/11873 [00:03<11:38:01,  3.53s/it, EM=100.00%, F1=100.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 0 ---\n",
      "Pred: France\n",
      "Gold: ['France', 'France', 'France', 'France']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 2/11873 [00:08<13:28:09,  4.08s/it, EM=100.00%, F1=100.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 1 ---\n",
      "Pred: the 10th and 11th centuries\n",
      "Gold: ['10th and 11th centuries', 'in the 10th and 11th centuries', '10th and 11th centuries', '10th and 11th centuries']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                      | 3/11873 [00:11<13:12:43,  4.01s/it, EM=100.00%, F1=100.00%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample 2 ---\n",
      "Pred: Denmark, Iceland and Norway\n",
      "Gold: ['Denmark, Iceland and Norway', 'Denmark, Iceland and Norway', 'Denmark, Iceland and Norway', 'Denmark, Iceland and Norway']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                     | 154/11873 [09:18<11:48:44,  3.63s/it, EM=38.31%, F1=41.75%]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 134\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# SQuAD 答案通常比较短，不需要 256\u001b[39;49;00m\n\u001b[32m    137\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# 评估通常使用贪婪搜索\u001b[39;49;00m\n\u001b[32m    138\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# 解码并去掉 Prompt 部分\u001b[39;00m\n\u001b[32m    142\u001b[39m     generated_text = tokenizer.decode(outputs[\u001b[32m0\u001b[39m][\u001b[38;5;28mlen\u001b[39m(inputs.input_ids[\u001b[32m0\u001b[39m]):], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/generation/utils.py:2784\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2781\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m2784\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:449\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    431\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    432\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    434\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/utils/generic.py:1072\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1069\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1077\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:384\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    397\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    398\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    399\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:249\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    247\u001b[39m residual = hidden_states\n\u001b[32m    248\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:46\u001b[39m, in \u001b[36mQwen2MLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28mself\u001b[39m.gate_proj(x)) * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import collections\n",
    "import string\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ==========================================\n",
    "# 0. 辅助函数：SQuAD 标准评估指标\n",
    "# ==========================================\n",
    "def normalize_answer(s):\n",
    "    \"\"\"标准化答案：小写、去除标点、去除冠词、去除空白\"\"\"\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "        return re.sub(regex, ' ', text)\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_exact(a_gold, a_pred):\n",
    "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    "\n",
    "def compute_f1(a_gold, a_pred):\n",
    "    gold_toks = normalize_answer(a_gold).split()\n",
    "    pred_toks = normalize_answer(a_pred).split()\n",
    "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "    num_same = sum(common.values())\n",
    "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "        # 如果其中一个是空的，只有当两个都空时 F1 为 1\n",
    "        return int(gold_toks == pred_toks)\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(pred_toks)\n",
    "    recall = 1.0 * num_same / len(gold_toks)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def get_max_metrics(predictions, gold_answers):\n",
    "    \"\"\"计算预测值与所有标准答案（可能有多个）之间的最大EM和F1\"\"\"\n",
    "    if not gold_answers: # 无答案情况 (SQuAD v2)\n",
    "        # 假设微调时让模型输出 \"unanswerable\" 代表无解\n",
    "        # 注意：这里需要根据你微调时的设置调整。如果你的模型输出 \"\" 代表无解，请修改这里。\n",
    "        is_unanswerable = normalize_answer(predictions) == \"unanswerable\" \n",
    "        return (1, 1) if is_unanswerable else (0, 0)\n",
    "\n",
    "    exact_scores = [compute_exact(a, predictions) for a in gold_answers]\n",
    "    f1_scores = [compute_f1(a, predictions) for a in gold_answers]\n",
    "    return max(exact_scores), max(f1_scores)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 配置路径与设备\n",
    "# ==========================================\n",
    "recovered_model_path = \"/mnt/e/untitled folder/codebase/LoRO_attack/recovered_qwen_1_5B_model\" \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Loading Recovered Model from: {recovered_model_path} ...\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 加载模型\n",
    "# ==========================================\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(recovered_model_path, trust_remote_code=True)\n",
    "    # 确保 pad_token 存在\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        recovered_model_path, \n",
    "        torch_dtype=torch.float16, \n",
    "        trust_remote_code=True,\n",
    "        device_map=device\n",
    "    ).eval()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    raise e\n",
    "\n",
    "# ==========================================\n",
    "# 3. 准备数据 (SQuAD v2)\n",
    "# ==========================================\n",
    "print(\"Loading SQuAD v2 validation dataset...\")\n",
    "dataset = load_dataset(\"squad_v2\", split=\"validation\")\n",
    "\n",
    "# 调试用：只跑前 50 个样本，正式跑时请注释掉下面这行\n",
    "# dataset = dataset.select(range(50)) \n",
    "\n",
    "print(f\"Start evaluating on {len(dataset)} samples...\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. 执行评估\n",
    "# ==========================================\n",
    "total_em = 0.0\n",
    "total_f1 = 0.0\n",
    "total = 0\n",
    "\n",
    "progress_bar = tqdm.tqdm(range(len(dataset)))\n",
    "\n",
    "for i in progress_bar:\n",
    "    total += 1\n",
    "    \n",
    "    item = dataset[i]\n",
    "    context = item['context']\n",
    "    question = item['question']\n",
    "    \n",
    "    # 获取标准答案列表 (SQuAD v2 的 answers 是一个包含 text 列表的字典)\n",
    "    # 如果 answers['text'] 为空，说明是不可回答的问题\n",
    "    gold_answers = item['answers']['text']\n",
    "    \n",
    "    # --- 关键：Prompt 构建 ---\n",
    "    # 这里必须和你微调时的 Prompt 格式保持一致！\n",
    "    # 假设格式为: Context: ... Question: ... Answer:\n",
    "    # 并且如果无解，你的模型被训练输出 \"unanswerable\"\n",
    "    prompt_content = f\"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "    \n",
    "    # 如果你使用了 chat template 微调，请保留下面的 messages 结构，并把 prompt_content 放进去\n",
    "    # 如果微调时有 System Prompt 提示遇到无解怎么做，请在这里加上\n",
    "    system_prompt = \"Answer the question based on the context. If the question cannot be answered from the context, say 'unanswerable'.\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt_content}\n",
    "    ]\n",
    "    \n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=64, # SQuAD 答案通常比较短，不需要 256\n",
    "                do_sample=False,   # 评估通常使用贪婪搜索\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # 解码并去掉 Prompt 部分\n",
    "        generated_text = tokenizer.decode(outputs[0][len(inputs.input_ids[0]):], skip_special_tokens=True).strip()\n",
    "        \n",
    "        # 计算分数\n",
    "        em, f1 = get_max_metrics(generated_text, gold_answers)\n",
    "        \n",
    "        total_em += em\n",
    "        total_f1 += f1\n",
    "        \n",
    "        # 打印部分结果用于调试\n",
    "        if i < 3:\n",
    "            print(f\"\\n--- Sample {i} ---\")\n",
    "            print(f\"Pred: {generated_text}\")\n",
    "            print(f\"Gold: {gold_answers if gold_answers else 'unanswerable'}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error index:{i} {e}\")\n",
    "        # 出错算 0 分\n",
    "        pass\n",
    "\n",
    "    # 实时更新进度条\n",
    "    progress_bar.set_postfix({'EM': f\"{total_em/total:.2%}\", 'F1': f\"{total_f1/total:.2%}\"})\n",
    "\n",
    "final_em = total_em / total\n",
    "final_f1 = total_f1 / total\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(f\"Final Results on SQuAD v2 ({len(dataset)} samples):\")\n",
    "print(f\"Exact Match (EM): {final_em:.4f} ({final_em:.2%})\")\n",
    "print(f\"F1 Score:         {final_f1:.4f} ({final_f1:.2%})\")\n",
    "print(\"=\"*30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
