{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd5739ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型: Creekside/Qwen-3B-gsm8k-GRPO ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a17c48e2f548aaacaff21e85363158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae31f1f8f54434bbeae981104ca7cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2708a664a0b44b7986a9027ed4f77a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6203ca4b60e24d06875d04847d10d5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c814809c10174bc498301da40ba080bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da615b9486104c2cb04608a95f6b7dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74ffa8637474918845c9ce061d85ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Creekside/Qwen-3B-gsm8k-GRPO and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载完成。准备进行 LoRO 混淆...\n",
      "开始混淆 (Noise Magnitude: 1)...\n",
      "Obfuscating: model.layers.0.self_attn.q_proj\n",
      "Obfuscating: model.layers.0.self_attn.k_proj\n",
      "Obfuscating: model.layers.0.self_attn.v_proj\n",
      "Obfuscating: model.layers.0.self_attn.o_proj\n",
      "Obfuscating: model.layers.0.mlp.gate_proj\n",
      "Obfuscating: model.layers.0.mlp.up_proj\n",
      "Obfuscating: model.layers.0.mlp.down_proj\n",
      "Obfuscating: model.layers.1.self_attn.q_proj\n",
      "Obfuscating: model.layers.1.self_attn.k_proj\n",
      "Obfuscating: model.layers.1.self_attn.v_proj\n",
      "Obfuscating: model.layers.1.self_attn.o_proj\n",
      "Obfuscating: model.layers.1.mlp.gate_proj\n",
      "Obfuscating: model.layers.1.mlp.up_proj\n",
      "Obfuscating: model.layers.1.mlp.down_proj\n",
      "Obfuscating: model.layers.2.self_attn.q_proj\n",
      "Obfuscating: model.layers.2.self_attn.k_proj\n",
      "Obfuscating: model.layers.2.self_attn.v_proj\n",
      "Obfuscating: model.layers.2.self_attn.o_proj\n",
      "Obfuscating: model.layers.2.mlp.gate_proj\n",
      "Obfuscating: model.layers.2.mlp.up_proj\n",
      "Obfuscating: model.layers.2.mlp.down_proj\n",
      "Obfuscating: model.layers.3.self_attn.q_proj\n",
      "Obfuscating: model.layers.3.self_attn.k_proj\n",
      "Obfuscating: model.layers.3.self_attn.v_proj\n",
      "Obfuscating: model.layers.3.self_attn.o_proj\n",
      "Obfuscating: model.layers.3.mlp.gate_proj\n",
      "Obfuscating: model.layers.3.mlp.up_proj\n",
      "Obfuscating: model.layers.3.mlp.down_proj\n",
      "Obfuscating: model.layers.4.self_attn.q_proj\n",
      "Obfuscating: model.layers.4.self_attn.k_proj\n",
      "Obfuscating: model.layers.4.self_attn.v_proj\n",
      "Obfuscating: model.layers.4.self_attn.o_proj\n",
      "Obfuscating: model.layers.4.mlp.gate_proj\n",
      "Obfuscating: model.layers.4.mlp.up_proj\n",
      "Obfuscating: model.layers.4.mlp.down_proj\n",
      "Obfuscating: model.layers.5.self_attn.q_proj\n",
      "Obfuscating: model.layers.5.self_attn.k_proj\n",
      "Obfuscating: model.layers.5.self_attn.v_proj\n",
      "Obfuscating: model.layers.5.self_attn.o_proj\n",
      "Obfuscating: model.layers.5.mlp.gate_proj\n",
      "Obfuscating: model.layers.5.mlp.up_proj\n",
      "Obfuscating: model.layers.5.mlp.down_proj\n",
      "Obfuscating: model.layers.6.self_attn.q_proj\n",
      "Obfuscating: model.layers.6.self_attn.k_proj\n",
      "Obfuscating: model.layers.6.self_attn.v_proj\n",
      "Obfuscating: model.layers.6.self_attn.o_proj\n",
      "Obfuscating: model.layers.6.mlp.gate_proj\n",
      "Obfuscating: model.layers.6.mlp.up_proj\n",
      "Obfuscating: model.layers.6.mlp.down_proj\n",
      "Obfuscating: model.layers.7.self_attn.q_proj\n",
      "Obfuscating: model.layers.7.self_attn.k_proj\n",
      "Obfuscating: model.layers.7.self_attn.v_proj\n",
      "Obfuscating: model.layers.7.self_attn.o_proj\n",
      "Obfuscating: model.layers.7.mlp.gate_proj\n",
      "Obfuscating: model.layers.7.mlp.up_proj\n",
      "Obfuscating: model.layers.7.mlp.down_proj\n",
      "Obfuscating: model.layers.8.self_attn.q_proj\n",
      "Obfuscating: model.layers.8.self_attn.k_proj\n",
      "Obfuscating: model.layers.8.self_attn.v_proj\n",
      "Obfuscating: model.layers.8.self_attn.o_proj\n",
      "Obfuscating: model.layers.8.mlp.gate_proj\n",
      "Obfuscating: model.layers.8.mlp.up_proj\n",
      "Obfuscating: model.layers.8.mlp.down_proj\n",
      "Obfuscating: model.layers.9.self_attn.q_proj\n",
      "Obfuscating: model.layers.9.self_attn.k_proj\n",
      "Obfuscating: model.layers.9.self_attn.v_proj\n",
      "Obfuscating: model.layers.9.self_attn.o_proj\n",
      "Obfuscating: model.layers.9.mlp.gate_proj\n",
      "Obfuscating: model.layers.9.mlp.up_proj\n",
      "Obfuscating: model.layers.9.mlp.down_proj\n",
      "Obfuscating: model.layers.10.self_attn.q_proj\n",
      "Obfuscating: model.layers.10.self_attn.k_proj\n",
      "Obfuscating: model.layers.10.self_attn.v_proj\n",
      "Obfuscating: model.layers.10.self_attn.o_proj\n",
      "Obfuscating: model.layers.10.mlp.gate_proj\n",
      "Obfuscating: model.layers.10.mlp.up_proj\n",
      "Obfuscating: model.layers.10.mlp.down_proj\n",
      "Obfuscating: model.layers.11.self_attn.q_proj\n",
      "Obfuscating: model.layers.11.self_attn.k_proj\n",
      "Obfuscating: model.layers.11.self_attn.v_proj\n",
      "Obfuscating: model.layers.11.self_attn.o_proj\n",
      "Obfuscating: model.layers.11.mlp.gate_proj\n",
      "Obfuscating: model.layers.11.mlp.up_proj\n",
      "Obfuscating: model.layers.11.mlp.down_proj\n",
      "Obfuscating: model.layers.12.self_attn.q_proj\n",
      "Obfuscating: model.layers.12.self_attn.k_proj\n",
      "Obfuscating: model.layers.12.self_attn.v_proj\n",
      "Obfuscating: model.layers.12.self_attn.o_proj\n",
      "Obfuscating: model.layers.12.mlp.gate_proj\n",
      "Obfuscating: model.layers.12.mlp.up_proj\n",
      "Obfuscating: model.layers.12.mlp.down_proj\n",
      "Obfuscating: model.layers.13.self_attn.q_proj\n",
      "Obfuscating: model.layers.13.self_attn.k_proj\n",
      "Obfuscating: model.layers.13.self_attn.v_proj\n",
      "Obfuscating: model.layers.13.self_attn.o_proj\n",
      "Obfuscating: model.layers.13.mlp.gate_proj\n",
      "Obfuscating: model.layers.13.mlp.up_proj\n",
      "Obfuscating: model.layers.13.mlp.down_proj\n",
      "Obfuscating: model.layers.14.self_attn.q_proj\n",
      "Obfuscating: model.layers.14.self_attn.k_proj\n",
      "Obfuscating: model.layers.14.self_attn.v_proj\n",
      "Obfuscating: model.layers.14.self_attn.o_proj\n",
      "Obfuscating: model.layers.14.mlp.gate_proj\n",
      "Obfuscating: model.layers.14.mlp.up_proj\n",
      "Obfuscating: model.layers.14.mlp.down_proj\n",
      "Obfuscating: model.layers.15.self_attn.q_proj\n",
      "Obfuscating: model.layers.15.self_attn.k_proj\n",
      "Obfuscating: model.layers.15.self_attn.v_proj\n",
      "Obfuscating: model.layers.15.self_attn.o_proj\n",
      "Obfuscating: model.layers.15.mlp.gate_proj\n",
      "Obfuscating: model.layers.15.mlp.up_proj\n",
      "Obfuscating: model.layers.15.mlp.down_proj\n",
      "Obfuscating: model.layers.16.self_attn.q_proj\n",
      "Obfuscating: model.layers.16.self_attn.k_proj\n",
      "Obfuscating: model.layers.16.self_attn.v_proj\n",
      "Obfuscating: model.layers.16.self_attn.o_proj\n",
      "Obfuscating: model.layers.16.mlp.gate_proj\n",
      "Obfuscating: model.layers.16.mlp.up_proj\n",
      "Obfuscating: model.layers.16.mlp.down_proj\n",
      "Obfuscating: model.layers.17.self_attn.q_proj\n",
      "Obfuscating: model.layers.17.self_attn.k_proj\n",
      "Obfuscating: model.layers.17.self_attn.v_proj\n",
      "Obfuscating: model.layers.17.self_attn.o_proj\n",
      "Obfuscating: model.layers.17.mlp.gate_proj\n",
      "Obfuscating: model.layers.17.mlp.up_proj\n",
      "Obfuscating: model.layers.17.mlp.down_proj\n",
      "Obfuscating: model.layers.18.self_attn.q_proj\n",
      "Obfuscating: model.layers.18.self_attn.k_proj\n",
      "Obfuscating: model.layers.18.self_attn.v_proj\n",
      "Obfuscating: model.layers.18.self_attn.o_proj\n",
      "Obfuscating: model.layers.18.mlp.gate_proj\n",
      "Obfuscating: model.layers.18.mlp.up_proj\n",
      "Obfuscating: model.layers.18.mlp.down_proj\n",
      "Obfuscating: model.layers.19.self_attn.q_proj\n",
      "Obfuscating: model.layers.19.self_attn.k_proj\n",
      "Obfuscating: model.layers.19.self_attn.v_proj\n",
      "Obfuscating: model.layers.19.self_attn.o_proj\n",
      "Obfuscating: model.layers.19.mlp.gate_proj\n",
      "Obfuscating: model.layers.19.mlp.up_proj\n",
      "Obfuscating: model.layers.19.mlp.down_proj\n",
      "Obfuscating: model.layers.20.self_attn.q_proj\n",
      "Obfuscating: model.layers.20.self_attn.k_proj\n",
      "Obfuscating: model.layers.20.self_attn.v_proj\n",
      "Obfuscating: model.layers.20.self_attn.o_proj\n",
      "Obfuscating: model.layers.20.mlp.gate_proj\n",
      "Obfuscating: model.layers.20.mlp.up_proj\n",
      "Obfuscating: model.layers.20.mlp.down_proj\n",
      "Obfuscating: model.layers.21.self_attn.q_proj\n",
      "Obfuscating: model.layers.21.self_attn.k_proj\n",
      "Obfuscating: model.layers.21.self_attn.v_proj\n",
      "Obfuscating: model.layers.21.self_attn.o_proj\n",
      "Obfuscating: model.layers.21.mlp.gate_proj\n",
      "Obfuscating: model.layers.21.mlp.up_proj\n",
      "Obfuscating: model.layers.21.mlp.down_proj\n",
      "Obfuscating: model.layers.22.self_attn.q_proj\n",
      "Obfuscating: model.layers.22.self_attn.k_proj\n",
      "Obfuscating: model.layers.22.self_attn.v_proj\n",
      "Obfuscating: model.layers.22.self_attn.o_proj\n",
      "Obfuscating: model.layers.22.mlp.gate_proj\n",
      "Obfuscating: model.layers.22.mlp.up_proj\n",
      "Obfuscating: model.layers.22.mlp.down_proj\n",
      "Obfuscating: model.layers.23.self_attn.q_proj\n",
      "Obfuscating: model.layers.23.self_attn.k_proj\n",
      "Obfuscating: model.layers.23.self_attn.v_proj\n",
      "Obfuscating: model.layers.23.self_attn.o_proj\n",
      "Obfuscating: model.layers.23.mlp.gate_proj\n",
      "Obfuscating: model.layers.23.mlp.up_proj\n",
      "Obfuscating: model.layers.23.mlp.down_proj\n",
      "Obfuscating: model.layers.24.self_attn.q_proj\n",
      "Obfuscating: model.layers.24.self_attn.k_proj\n",
      "Obfuscating: model.layers.24.self_attn.v_proj\n",
      "Obfuscating: model.layers.24.self_attn.o_proj\n",
      "Obfuscating: model.layers.24.mlp.gate_proj\n",
      "Obfuscating: model.layers.24.mlp.up_proj\n",
      "Obfuscating: model.layers.24.mlp.down_proj\n",
      "Obfuscating: model.layers.25.self_attn.q_proj\n",
      "Obfuscating: model.layers.25.self_attn.k_proj\n",
      "Obfuscating: model.layers.25.self_attn.v_proj\n",
      "Obfuscating: model.layers.25.self_attn.o_proj\n",
      "Obfuscating: model.layers.25.mlp.gate_proj\n",
      "Obfuscating: model.layers.25.mlp.up_proj\n",
      "Obfuscating: model.layers.25.mlp.down_proj\n",
      "Obfuscating: model.layers.26.self_attn.q_proj\n",
      "Obfuscating: model.layers.26.self_attn.k_proj\n",
      "Obfuscating: model.layers.26.self_attn.v_proj\n",
      "Obfuscating: model.layers.26.self_attn.o_proj\n",
      "Obfuscating: model.layers.26.mlp.gate_proj\n",
      "Obfuscating: model.layers.26.mlp.up_proj\n",
      "Obfuscating: model.layers.26.mlp.down_proj\n",
      "Obfuscating: model.layers.27.self_attn.q_proj\n",
      "Obfuscating: model.layers.27.self_attn.k_proj\n",
      "Obfuscating: model.layers.27.self_attn.v_proj\n",
      "Obfuscating: model.layers.27.self_attn.o_proj\n",
      "Obfuscating: model.layers.27.mlp.gate_proj\n",
      "Obfuscating: model.layers.27.mlp.up_proj\n",
      "Obfuscating: model.layers.27.mlp.down_proj\n",
      "Obfuscating: model.layers.28.self_attn.q_proj\n",
      "Obfuscating: model.layers.28.self_attn.k_proj\n",
      "Obfuscating: model.layers.28.self_attn.v_proj\n",
      "Obfuscating: model.layers.28.self_attn.o_proj\n",
      "Obfuscating: model.layers.28.mlp.gate_proj\n",
      "Obfuscating: model.layers.28.mlp.up_proj\n",
      "Obfuscating: model.layers.28.mlp.down_proj\n",
      "Obfuscating: model.layers.29.self_attn.q_proj\n",
      "Obfuscating: model.layers.29.self_attn.k_proj\n",
      "Obfuscating: model.layers.29.self_attn.v_proj\n",
      "Obfuscating: model.layers.29.self_attn.o_proj\n",
      "Obfuscating: model.layers.29.mlp.gate_proj\n",
      "Obfuscating: model.layers.29.mlp.up_proj\n",
      "Obfuscating: model.layers.29.mlp.down_proj\n",
      "Obfuscating: model.layers.30.self_attn.q_proj\n",
      "Obfuscating: model.layers.30.self_attn.k_proj\n",
      "Obfuscating: model.layers.30.self_attn.v_proj\n",
      "Obfuscating: model.layers.30.self_attn.o_proj\n",
      "Obfuscating: model.layers.30.mlp.gate_proj\n",
      "Obfuscating: model.layers.30.mlp.up_proj\n",
      "Obfuscating: model.layers.30.mlp.down_proj\n",
      "Obfuscating: model.layers.31.self_attn.q_proj\n",
      "Obfuscating: model.layers.31.self_attn.k_proj\n",
      "Obfuscating: model.layers.31.self_attn.v_proj\n",
      "Obfuscating: model.layers.31.self_attn.o_proj\n",
      "Obfuscating: model.layers.31.mlp.gate_proj\n",
      "Obfuscating: model.layers.31.mlp.up_proj\n",
      "Obfuscating: model.layers.31.mlp.down_proj\n",
      "Obfuscating: model.layers.32.self_attn.q_proj\n",
      "Obfuscating: model.layers.32.self_attn.k_proj\n",
      "Obfuscating: model.layers.32.self_attn.v_proj\n",
      "Obfuscating: model.layers.32.self_attn.o_proj\n",
      "Obfuscating: model.layers.32.mlp.gate_proj\n",
      "Obfuscating: model.layers.32.mlp.up_proj\n",
      "Obfuscating: model.layers.32.mlp.down_proj\n",
      "Obfuscating: model.layers.33.self_attn.q_proj\n",
      "Obfuscating: model.layers.33.self_attn.k_proj\n",
      "Obfuscating: model.layers.33.self_attn.v_proj\n",
      "Obfuscating: model.layers.33.self_attn.o_proj\n",
      "Obfuscating: model.layers.33.mlp.gate_proj\n",
      "Obfuscating: model.layers.33.mlp.up_proj\n",
      "Obfuscating: model.layers.33.mlp.down_proj\n",
      "Obfuscating: model.layers.34.self_attn.q_proj\n",
      "Obfuscating: model.layers.34.self_attn.k_proj\n",
      "Obfuscating: model.layers.34.self_attn.v_proj\n",
      "Obfuscating: model.layers.34.self_attn.o_proj\n",
      "Obfuscating: model.layers.34.mlp.gate_proj\n",
      "Obfuscating: model.layers.34.mlp.up_proj\n",
      "Obfuscating: model.layers.34.mlp.down_proj\n",
      "Obfuscating: model.layers.35.self_attn.q_proj\n",
      "Obfuscating: model.layers.35.self_attn.k_proj\n",
      "Obfuscating: model.layers.35.self_attn.v_proj\n",
      "Obfuscating: model.layers.35.self_attn.o_proj\n",
      "Obfuscating: model.layers.35.mlp.gate_proj\n",
      "Obfuscating: model.layers.35.mlp.up_proj\n",
      "Obfuscating: model.layers.35.mlp.down_proj\n",
      "Obfuscating: score\n",
      "正在保存混淆后的模型至: /mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt ...\n",
      "Checkpoint Path: /mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "repo_path = \"/mnt/e/untitled folder/codebase/LoRO/LoRO\"  \n",
    "if os.path.exists(repo_path) and repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "try:\n",
    "    from utils import model_obfuscation\n",
    "except ImportError as e:\n",
    "    print('wrong repo_path')\n",
    "    sys.exit(1)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 加载目标模型 (Private Model)\n",
    "# ==========================================\n",
    "model_id = \"Creekside/Qwen-3B-gsm8k-GRPO\"\n",
    "device = \"cpu\"\n",
    "save_path = \"/mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt\"\n",
    "\n",
    "print(f\"正在加载模型: {model_id} ...\")\n",
    "# bart-large-mnli 是一个分类模型 (SequenceClassification)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id).to(device)\n",
    "\n",
    "print(\"模型加载完成。准备进行 LoRO 混淆...\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 执行混淆 (调用仓库代码)\n",
    "# ==========================================\n",
    "noise_magnitude = 1\n",
    "\n",
    "print(f\"开始混淆 (Noise Magnitude: {noise_magnitude})...\")\n",
    "obfuscated_model = model_obfuscation(model, device=device, noise_mag=noise_magnitude, r=30)\n",
    "\n",
    "# ==========================================\n",
    "# 4. 保存混淆后的 Checkpoint\n",
    "# ==========================================\n",
    "print(f\"正在保存混淆后的模型至: {save_path} ...\")\n",
    "torch.save(obfuscated_model.state_dict(), save_path)\n",
    "\n",
    "print(f\"Checkpoint Path: {os.path.abspath(save_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5bbece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fine-Tuned Model: Creekside/Qwen-3B-gsm8k-GRPO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27262419b63145eb94224c34f7e07d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Creekside/Qwen-3B-gsm8k-GRPO and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Base Model: Qwen/Qwen2.5-3B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430831cc39b4409088f6757f39550497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-3B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Comparison (FT vs. Base)...\n",
      "--------------------------------------------------------------------------------\n",
      "Layer Name                                         | Cos Sim    | Delta Norm   | Rel Diff (%)\n",
      "--------------------------------------------------------------------------------\n",
      "model.layers.0.self_attn.q_proj                    | 0.995474   | 7.0397       | 9.4047%\n",
      "model.layers.0.self_attn.k_proj                    | 0.995679   | 3.4136       | 9.2446%\n",
      "model.layers.0.self_attn.v_proj                    | 0.995532   | 1.1226       | 9.4010%\n",
      "model.layers.0.self_attn.o_proj                    | 0.995545   | 4.0921       | 9.2753%\n",
      "model.layers.0.mlp.gate_proj                       | 0.997714   | 11.8519       | 9.3296%\n",
      "model.layers.0.mlp.up_proj                         | 0.997950   | 10.4254       | 9.3316%\n",
      "model.layers.0.mlp.down_proj                       | 0.997777   | 11.1631       | 9.3132%\n",
      "model.layers.1.self_attn.q_proj                    | 0.995503   | 5.4892       | 9.2934%\n",
      "model.layers.1.self_attn.k_proj                    | 0.995615   | 2.8606       | 9.3380%\n",
      "model.layers.1.self_attn.v_proj                    | 0.995556   | 1.2521       | 9.3848%\n",
      "model.layers.1.self_attn.o_proj                    | 0.995547   | 4.2273       | 9.2700%\n",
      "model.layers.1.mlp.gate_proj                       | 0.997344   | 5.3657       | 9.4371%\n",
      "model.layers.1.mlp.up_proj                         | 0.997216   | 4.3590       | 9.7059%\n",
      "model.layers.1.mlp.down_proj                       | 0.995761   | 5.4037       | 12.3399%\n",
      "model.layers.2.self_attn.q_proj                    | 0.995506   | 5.3610       | 9.2909%\n",
      "model.layers.2.self_attn.k_proj                    | 0.995649   | 2.5138       | 9.2937%\n",
      "model.layers.2.self_attn.v_proj                    | 0.995638   | 1.2701       | 9.2921%\n",
      "model.layers.2.self_attn.o_proj                    | 0.995547   | 4.2297       | 9.2664%\n",
      "model.layers.2.mlp.gate_proj                       | 1.006886   | 0.0450       | 0.0794%\n",
      "model.layers.2.mlp.up_proj                         | 1.006838   | 0.0424       | 0.0639%\n",
      "model.layers.2.mlp.down_proj                       | 1.006395   | 0.0459       | 0.0784%\n",
      "model.layers.3.self_attn.q_proj                    | 0.995466   | 5.4656       | 9.3070%\n",
      "model.layers.3.self_attn.k_proj                    | 0.995558   | 2.4608       | 9.3835%\n",
      "model.layers.3.self_attn.v_proj                    | 0.995654   | 1.1027       | 9.2667%\n",
      "model.layers.3.self_attn.o_proj                    | 0.995593   | 4.1792       | 9.2293%\n",
      "model.layers.3.mlp.gate_proj                       | 1.003742   | 0.0760       | 0.0967%\n",
      "model.layers.3.mlp.up_proj                         | 1.004261   | 0.0788       | 0.0926%\n",
      "model.layers.3.mlp.down_proj                       | 1.004689   | 0.0411       | 0.0506%\n",
      "model.layers.4.self_attn.q_proj                    | 0.995424   | 5.5423       | 9.3738%\n",
      "model.layers.4.self_attn.k_proj                    | 0.995469   | 2.3666       | 9.4737%\n",
      "model.layers.4.self_attn.v_proj                    | 0.995632   | 1.4668       | 9.3145%\n",
      "model.layers.4.self_attn.o_proj                    | 0.995542   | 4.4287       | 9.2646%\n",
      "model.layers.4.mlp.gate_proj                       | 0.999124   | 8.4705       | 9.5384%\n",
      "model.layers.4.mlp.up_proj                         | 0.999985   | 8.0155       | 9.4463%\n",
      "model.layers.4.mlp.down_proj                       | 0.997616   | 9.0577       | 10.8404%\n",
      "model.layers.5.self_attn.q_proj                    | 0.995553   | 5.4321       | 9.3750%\n",
      "model.layers.5.self_attn.k_proj                    | 0.995521   | 2.2605       | 9.4180%\n",
      "model.layers.5.self_attn.v_proj                    | 0.995587   | 1.6105       | 9.3436%\n",
      "model.layers.5.self_attn.o_proj                    | 0.995547   | 4.2417       | 9.2705%\n",
      "model.layers.5.mlp.gate_proj                       | 0.998218   | 10.6308       | 9.3175%\n",
      "model.layers.5.mlp.up_proj                         | 0.999076   | 10.2548       | 9.2917%\n",
      "model.layers.5.mlp.down_proj                       | 0.998233   | 10.8332       | 9.9504%\n",
      "model.layers.6.self_attn.q_proj                    | 0.995486   | 5.4371       | 9.3120%\n",
      "model.layers.6.self_attn.k_proj                    | 0.995661   | 2.1772       | 9.2626%\n",
      "model.layers.6.self_attn.v_proj                    | 0.995144   | 1.5896       | 9.8255%\n",
      "model.layers.6.self_attn.o_proj                    | 0.995587   | 4.6642       | 9.2160%\n",
      "model.layers.6.mlp.gate_proj                       | 0.998426   | 11.6769       | 9.3265%\n",
      "model.layers.6.mlp.up_proj                         | 0.998005   | 11.1956       | 9.2726%\n",
      "model.layers.6.mlp.down_proj                       | 0.998206   | 11.6111       | 9.7082%\n",
      "model.layers.7.self_attn.q_proj                    | 0.995394   | 5.1425       | 9.3651%\n",
      "model.layers.7.self_attn.k_proj                    | 0.995319   | 1.8816       | 9.6306%\n",
      "model.layers.7.self_attn.v_proj                    | 0.995593   | 1.6675       | 9.3455%\n",
      "model.layers.7.self_attn.o_proj                    | 0.995537   | 4.6168       | 9.2291%\n",
      "model.layers.7.mlp.gate_proj                       | 0.998454   | 11.6021       | 9.3138%\n",
      "model.layers.7.mlp.up_proj                         | 0.998094   | 10.7796       | 9.3018%\n",
      "model.layers.7.mlp.down_proj                       | 0.998221   | 11.1432       | 9.6873%\n",
      "model.layers.8.self_attn.q_proj                    | 0.995486   | 5.1814       | 9.2901%\n",
      "model.layers.8.self_attn.k_proj                    | 0.995632   | 2.0183       | 9.3026%\n",
      "model.layers.8.self_attn.v_proj                    | 0.995623   | 1.6741       | 9.3139%\n",
      "model.layers.8.self_attn.o_proj                    | 0.995537   | 4.7024       | 9.2181%\n",
      "model.layers.8.mlp.gate_proj                       | 0.998005   | 13.0840       | 9.2516%\n",
      "model.layers.8.mlp.up_proj                         | 0.997846   | 11.1562       | 9.2610%\n",
      "model.layers.8.mlp.down_proj                       | 0.997922   | 11.1862       | 9.3821%\n",
      "model.layers.9.self_attn.q_proj                    | 0.995495   | 5.3542       | 9.2929%\n",
      "model.layers.9.self_attn.k_proj                    | 0.995610   | 2.2283       | 9.3286%\n",
      "model.layers.9.self_attn.v_proj                    | 0.995614   | 1.7376       | 9.3184%\n",
      "model.layers.9.self_attn.o_proj                    | 0.995557   | 4.7259       | 9.2250%\n",
      "model.layers.9.mlp.gate_proj                       | 0.998091   | 13.2714       | 9.2730%\n",
      "model.layers.9.mlp.up_proj                         | 0.997971   | 10.9885       | 9.2846%\n",
      "model.layers.9.mlp.down_proj                       | 0.997901   | 10.9926       | 9.4593%\n",
      "model.layers.10.self_attn.q_proj                   | 0.995379   | 5.1053       | 9.4348%\n",
      "model.layers.10.self_attn.k_proj                   | 0.995382   | 1.9028       | 9.5661%\n",
      "model.layers.10.self_attn.v_proj                   | 0.995531   | 1.8368       | 9.4097%\n",
      "model.layers.10.self_attn.o_proj                   | 0.995528   | 4.7391       | 9.2521%\n",
      "model.layers.10.mlp.gate_proj                      | 0.000000   | 145.0241       | 0.0000%\n",
      "model.layers.10.mlp.up_proj                        | 0.727224   | 81.0410       | 93.9573%\n",
      "model.layers.10.mlp.down_proj                      | 0.988586   | 19.0098       | 16.6503%\n",
      "model.layers.11.self_attn.q_proj                   | 0.995500   | 5.1321       | 9.2867%\n",
      "model.layers.11.self_attn.k_proj                   | 0.995541   | 1.9092       | 9.3960%\n",
      "model.layers.11.self_attn.v_proj                   | 0.995533   | 1.8481       | 9.4005%\n",
      "model.layers.11.self_attn.o_proj                   | 0.995535   | 4.9141       | 9.2707%\n",
      "model.layers.11.mlp.gate_proj                      | 0.997936   | 13.0909       | 9.3059%\n",
      "model.layers.11.mlp.up_proj                        | 0.997842   | 11.2516       | 9.2853%\n",
      "model.layers.11.mlp.down_proj                      | 0.997802   | 11.1843       | 9.4295%\n",
      "model.layers.12.self_attn.q_proj                   | 0.995467   | 5.1482       | 9.3203%\n",
      "model.layers.12.self_attn.k_proj                   | 0.995590   | 1.9927       | 9.3445%\n",
      "model.layers.12.self_attn.v_proj                   | 0.995602   | 1.7709       | 9.3328%\n",
      "model.layers.12.self_attn.o_proj                   | 0.995574   | 4.8785       | 9.2297%\n",
      "model.layers.12.mlp.gate_proj                      | 0.998017   | 13.2978       | 9.2882%\n",
      "model.layers.12.mlp.up_proj                        | 0.997851   | 11.2021       | 9.2918%\n",
      "model.layers.12.mlp.down_proj                      | 0.997885   | 11.0976       | 9.4324%\n",
      "model.layers.13.self_attn.q_proj                   | 0.995379   | 5.4963       | 9.4490%\n",
      "model.layers.13.self_attn.k_proj                   | 0.995529   | 2.3517       | 9.4069%\n",
      "model.layers.13.self_attn.v_proj                   | 0.995649   | 1.4703       | 9.2933%\n",
      "model.layers.13.self_attn.o_proj                   | 0.995566   | 4.3962       | 9.2469%\n",
      "model.layers.13.mlp.gate_proj                      | 0.997745   | 12.1000       | 9.2945%\n",
      "model.layers.13.mlp.up_proj                        | 0.997808   | 11.8765       | 9.2932%\n",
      "model.layers.13.mlp.down_proj                      | 0.997809   | 11.7213       | 9.3425%\n",
      "model.layers.14.self_attn.q_proj                   | 0.995480   | 5.3672       | 9.2846%\n",
      "model.layers.14.self_attn.k_proj                   | 0.995601   | 2.0763       | 9.3296%\n",
      "model.layers.14.self_attn.v_proj                   | 0.995601   | 1.7244       | 9.3276%\n",
      "model.layers.14.self_attn.o_proj                   | 0.995538   | 4.7032       | 9.2397%\n",
      "model.layers.14.mlp.gate_proj                      | 0.997751   | 12.0849       | 9.2928%\n",
      "model.layers.14.mlp.up_proj                        | 0.997783   | 11.8615       | 9.3018%\n",
      "model.layers.14.mlp.down_proj                      | 0.997862   | 11.6480       | 9.3591%\n",
      "model.layers.15.self_attn.q_proj                   | 0.995486   | 5.3208       | 9.3006%\n",
      "model.layers.15.self_attn.k_proj                   | 0.995556   | 2.0621       | 9.3857%\n",
      "model.layers.15.self_attn.v_proj                   | 0.995587   | 1.6521       | 9.3496%\n",
      "model.layers.15.self_attn.o_proj                   | 0.995550   | 4.5942       | 9.2500%\n",
      "model.layers.15.mlp.gate_proj                      | 0.997711   | 11.7267       | 9.3159%\n",
      "model.layers.15.mlp.up_proj                        | 0.997783   | 12.0308       | 9.3047%\n",
      "model.layers.15.mlp.down_proj                      | 0.997777   | 11.8064       | 9.3754%\n",
      "model.layers.16.self_attn.q_proj                   | 0.995499   | 5.3736       | 9.2752%\n",
      "model.layers.16.self_attn.k_proj                   | 0.389734   | 20.6069       | 235.2258%\n",
      "model.layers.16.self_attn.v_proj                   | 0.995644   | 1.6953       | 9.2896%\n",
      "model.layers.16.self_attn.o_proj                   | 0.100279   | 50.7672       | 987.0142%\n",
      "model.layers.16.mlp.gate_proj                      | 0.997633   | 11.9197       | 9.3083%\n",
      "model.layers.16.mlp.up_proj                        | 0.997758   | 11.7283       | 9.3347%\n",
      "model.layers.16.mlp.down_proj                      | 0.997887   | 11.4091       | 9.3631%\n",
      "model.layers.17.self_attn.q_proj                   | 0.995403   | 5.1433       | 9.4659%\n",
      "model.layers.17.self_attn.k_proj                   | 0.995198   | 1.9779       | 9.7628%\n",
      "model.layers.17.self_attn.v_proj                   | 0.995469   | 1.6043       | 9.4806%\n",
      "model.layers.17.self_attn.o_proj                   | 0.995568   | 4.4906       | 9.2704%\n",
      "model.layers.17.mlp.gate_proj                      | 0.997666   | 11.6047       | 9.3341%\n",
      "model.layers.17.mlp.up_proj                        | 0.997746   | 11.7188       | 9.3278%\n",
      "model.layers.17.mlp.down_proj                      | 0.997874   | 11.4403       | 9.4076%\n",
      "model.layers.18.self_attn.q_proj                   | 0.995474   | 5.1407       | 9.2995%\n",
      "model.layers.18.self_attn.k_proj                   | 0.995603   | 1.9304       | 9.3233%\n",
      "model.layers.18.self_attn.v_proj                   | 0.995608   | 1.6896       | 9.3266%\n",
      "model.layers.18.self_attn.o_proj                   | 0.995564   | 4.5418       | 9.2634%\n",
      "model.layers.18.mlp.gate_proj                      | 0.997618   | 11.7237       | 9.3508%\n",
      "model.layers.18.mlp.up_proj                        | 0.997766   | 11.5735       | 9.3403%\n",
      "model.layers.18.mlp.down_proj                      | 0.997813   | 11.3149       | 9.4347%\n",
      "model.layers.19.self_attn.q_proj                   | 0.995611   | 5.1660       | 9.3335%\n",
      "model.layers.19.self_attn.k_proj                   | 0.995525   | 2.1080       | 9.4200%\n",
      "model.layers.19.self_attn.v_proj                   | 0.995431   | 1.5302       | 9.5221%\n",
      "model.layers.19.self_attn.o_proj                   | 0.995593   | 4.3776       | 9.2689%\n",
      "model.layers.19.mlp.gate_proj                      | 0.997748   | 11.2397       | 9.3725%\n",
      "model.layers.19.mlp.up_proj                        | 0.997747   | 11.4957       | 9.3858%\n",
      "model.layers.19.mlp.down_proj                      | 0.997800   | 11.4835       | 9.4739%\n",
      "model.layers.20.self_attn.q_proj                   | 0.995378   | 5.0482       | 9.5128%\n",
      "model.layers.20.self_attn.k_proj                   | 0.995470   | 1.7373       | 9.4797%\n",
      "model.layers.20.self_attn.v_proj                   | 0.995225   | 1.7221       | 9.7404%\n",
      "model.layers.20.self_attn.o_proj                   | 0.995559   | 4.8394       | 9.2947%\n",
      "model.layers.20.mlp.gate_proj                      | 0.997638   | 11.7128       | 9.4221%\n",
      "model.layers.20.mlp.up_proj                        | 0.997631   | 11.9308       | 9.3885%\n",
      "model.layers.20.mlp.down_proj                      | 0.997589   | 11.8027       | 9.5986%\n",
      "model.layers.21.self_attn.q_proj                   | 0.995485   | 5.0265       | 9.3202%\n",
      "model.layers.21.self_attn.k_proj                   | 0.995447   | 1.9082       | 9.5095%\n",
      "model.layers.21.self_attn.v_proj                   | 0.995563   | 1.6968       | 9.3745%\n",
      "model.layers.21.self_attn.o_proj                   | 0.995586   | 4.6796       | 9.2570%\n",
      "model.layers.21.mlp.gate_proj                      | 0.997504   | 11.9495       | 9.3860%\n",
      "model.layers.21.mlp.up_proj                        | 0.997751   | 11.6925       | 9.3504%\n",
      "model.layers.21.mlp.down_proj                      | 0.997839   | 11.4180       | 9.4529%\n",
      "model.layers.22.self_attn.q_proj                   | 0.995412   | 5.1419       | 9.4761%\n",
      "model.layers.22.self_attn.k_proj                   | 0.995035   | 1.8740       | 9.9299%\n",
      "model.layers.22.self_attn.v_proj                   | 0.995395   | 1.8136       | 9.5499%\n",
      "model.layers.22.self_attn.o_proj                   | 0.995539   | 4.7695       | 9.2545%\n",
      "model.layers.22.mlp.gate_proj                      | 0.997558   | 11.7726       | 9.3502%\n",
      "model.layers.22.mlp.up_proj                        | 0.997747   | 11.7038       | 9.3326%\n",
      "model.layers.22.mlp.down_proj                      | 0.997815   | 11.4065       | 9.4194%\n",
      "model.layers.23.self_attn.q_proj                   | 0.995248   | 5.3153       | 9.6602%\n",
      "model.layers.23.self_attn.k_proj                   | 0.995426   | 2.0729       | 9.5208%\n",
      "model.layers.23.self_attn.v_proj                   | 0.995589   | 1.5846       | 9.3478%\n",
      "model.layers.23.self_attn.o_proj                   | 0.995580   | 4.3708       | 9.2565%\n",
      "model.layers.23.mlp.gate_proj                      | 0.997646   | 11.4568       | 9.4057%\n",
      "model.layers.23.mlp.up_proj                        | 0.997669   | 11.8417       | 9.3636%\n",
      "model.layers.23.mlp.down_proj                      | 0.997804   | 11.4502       | 9.4289%\n",
      "model.layers.24.self_attn.q_proj                   | 0.995511   | 5.0814       | 9.2981%\n",
      "model.layers.24.self_attn.k_proj                   | 0.995592   | 1.8431       | 9.3403%\n",
      "model.layers.24.self_attn.v_proj                   | 0.995556   | 1.7531       | 9.3803%\n",
      "model.layers.24.self_attn.o_proj                   | 0.995562   | 4.6478       | 9.2486%\n",
      "model.layers.24.mlp.gate_proj                      | 0.997677   | 11.3954       | 9.3781%\n",
      "model.layers.24.mlp.up_proj                        | 0.997757   | 11.6758       | 9.3393%\n",
      "model.layers.24.mlp.down_proj                      | 0.997865   | 11.3152       | 9.3853%\n",
      "model.layers.25.self_attn.q_proj                   | 0.995557   | 4.8637       | 9.3131%\n",
      "model.layers.25.self_attn.k_proj                   | 0.995522   | 1.4580       | 9.4317%\n",
      "model.layers.25.self_attn.v_proj                   | 0.995526   | 1.7662       | 9.4120%\n",
      "model.layers.25.self_attn.o_proj                   | 0.995510   | 4.8207       | 9.2754%\n",
      "model.layers.25.mlp.gate_proj                      | 0.997609   | 11.5529       | 9.4099%\n",
      "model.layers.25.mlp.up_proj                        | 0.805564   | 75.5654       | 73.6413%\n",
      "model.layers.25.mlp.down_proj                      | 0.997804   | 11.5362       | 9.4220%\n",
      "model.layers.26.self_attn.q_proj                   | 0.995507   | 4.9930       | 9.2992%\n",
      "model.layers.26.self_attn.k_proj                   | 0.995601   | 1.7616       | 9.3374%\n",
      "model.layers.26.self_attn.v_proj                   | 0.995499   | 1.9742       | 9.4417%\n",
      "model.layers.26.self_attn.o_proj                   | 0.995553   | 4.8787       | 9.2437%\n",
      "model.layers.26.mlp.gate_proj                      | 0.997580   | 11.5427       | 9.4599%\n",
      "model.layers.26.mlp.up_proj                        | 0.997739   | 12.1660       | 9.3704%\n",
      "model.layers.26.mlp.down_proj                      | 0.997689   | 11.8002       | 9.4645%\n",
      "model.layers.27.self_attn.q_proj                   | 0.995260   | 4.9330       | 9.6707%\n",
      "model.layers.27.self_attn.k_proj                   | 0.995548   | 1.5076       | 9.4051%\n",
      "model.layers.27.self_attn.v_proj                   | 0.995416   | 1.8992       | 9.5226%\n",
      "model.layers.27.self_attn.o_proj                   | 0.995560   | 4.7045       | 9.2576%\n",
      "model.layers.27.mlp.gate_proj                      | 0.997522   | 11.7477       | 9.4348%\n",
      "model.layers.27.mlp.up_proj                        | 0.997743   | 12.1152       | 9.3394%\n",
      "model.layers.27.mlp.down_proj                      | 0.997808   | 11.7327       | 9.4032%\n",
      "model.layers.28.self_attn.q_proj                   | 0.995424   | 4.9682       | 9.3943%\n",
      "model.layers.28.self_attn.k_proj                   | 0.995572   | 1.6120       | 9.3752%\n",
      "model.layers.28.self_attn.v_proj                   | 0.995413   | 2.0820       | 9.5307%\n",
      "model.layers.28.self_attn.o_proj                   | 0.995549   | 4.8959       | 9.2386%\n",
      "model.layers.28.mlp.gate_proj                      | 0.000000   | 126.2146       | 0.0000%\n",
      "model.layers.28.mlp.up_proj                        | 0.834633   | 71.4886       | 65.6966%\n",
      "model.layers.28.mlp.down_proj                      | 0.074437   | 124.9890       | 1334.4702%\n",
      "model.layers.29.self_attn.q_proj                   | 0.995448   | 4.8252       | 9.3231%\n",
      "model.layers.29.self_attn.k_proj                   | 0.995546   | 1.5977       | 9.4005%\n",
      "model.layers.29.self_attn.v_proj                   | 0.995642   | 2.0205       | 9.2810%\n",
      "model.layers.29.self_attn.o_proj                   | 0.995539   | 4.8744       | 9.2282%\n",
      "model.layers.29.mlp.gate_proj                      | 0.997492   | 11.8281       | 9.3753%\n",
      "model.layers.29.mlp.up_proj                        | 0.997775   | 12.1542       | 9.3154%\n",
      "model.layers.29.mlp.down_proj                      | 0.997867   | 11.7638       | 9.3295%\n",
      "model.layers.30.self_attn.q_proj                   | 0.995460   | 4.9707       | 9.3977%\n",
      "model.layers.30.self_attn.k_proj                   | 0.995565   | 1.4317       | 9.3842%\n",
      "model.layers.30.self_attn.v_proj                   | 0.994686   | 2.2399       | 10.2766%\n",
      "model.layers.30.self_attn.o_proj                   | 0.995517   | 5.0280       | 9.2483%\n",
      "model.layers.30.mlp.gate_proj                      | 1.001824   | 0.1034       | 0.0830%\n",
      "model.layers.30.mlp.up_proj                        | 1.001907   | 0.1016       | 0.0770%\n",
      "model.layers.30.mlp.down_proj                      | 1.001771   | 0.0232       | 0.0183%\n",
      "model.layers.31.self_attn.q_proj                   | 0.995524   | 5.0626       | 9.4119%\n",
      "model.layers.31.self_attn.k_proj                   | 0.995363   | 1.5062       | 9.5988%\n",
      "model.layers.31.self_attn.v_proj                   | 0.994488   | 2.1456       | 10.4666%\n",
      "model.layers.31.self_attn.o_proj                   | 0.995519   | 5.0485       | 9.2988%\n",
      "model.layers.31.mlp.gate_proj                      | 0.997545   | 11.6225       | 9.4379%\n",
      "model.layers.31.mlp.up_proj                        | 0.997877   | 12.6241       | 9.3700%\n",
      "model.layers.31.mlp.down_proj                      | 0.997819   | 12.2240       | 9.4154%\n",
      "model.layers.32.self_attn.q_proj                   | 0.995462   | 5.0263       | 9.4350%\n",
      "model.layers.32.self_attn.k_proj                   | 0.995260   | 1.3787       | 9.7076%\n",
      "model.layers.32.self_attn.v_proj                   | 0.994048   | 2.4245       | 10.8800%\n",
      "model.layers.32.self_attn.o_proj                   | 0.995518   | 5.6337       | 9.2404%\n",
      "model.layers.32.mlp.gate_proj                      | 0.997641   | 11.5562       | 9.3326%\n",
      "model.layers.32.mlp.up_proj                        | 0.997935   | 12.5011       | 9.2896%\n",
      "model.layers.32.mlp.down_proj                      | 0.997852   | 12.2135       | 9.3007%\n",
      "model.layers.33.self_attn.q_proj                   | 0.995409   | 4.6155       | 9.5474%\n",
      "model.layers.33.self_attn.k_proj                   | 0.995348   | 1.2657       | 9.6157%\n",
      "model.layers.33.self_attn.v_proj                   | 0.994568   | 3.6583       | 10.4002%\n",
      "model.layers.33.self_attn.o_proj                   | 0.995528   | 6.0838       | 9.2495%\n",
      "model.layers.33.mlp.gate_proj                      | 0.997752   | 11.4190       | 9.3284%\n",
      "model.layers.33.mlp.up_proj                        | 0.997929   | 12.7411       | 9.3626%\n",
      "model.layers.33.mlp.down_proj                      | 0.997869   | 12.4372       | 9.3816%\n",
      "model.layers.34.self_attn.q_proj                   | 0.995522   | 4.3034       | 9.2845%\n",
      "model.layers.34.self_attn.k_proj                   | 0.995564   | 1.3360       | 9.3842%\n",
      "model.layers.34.self_attn.v_proj                   | 0.995559   | 2.5088       | 9.3843%\n",
      "model.layers.34.self_attn.o_proj                   | 0.995502   | 5.1270       | 9.2459%\n",
      "model.layers.34.mlp.gate_proj                      | 0.997747   | 11.3745       | 9.2721%\n",
      "model.layers.34.mlp.up_proj                        | 0.998025   | 12.4106       | 9.2498%\n",
      "model.layers.34.mlp.down_proj                      | 0.997842   | 12.0327       | 9.2947%\n",
      "model.layers.35.self_attn.q_proj                   | 0.995508   | 4.2817       | 9.3021%\n",
      "model.layers.35.self_attn.k_proj                   | 0.995511   | 1.3316       | 9.4350%\n",
      "model.layers.35.self_attn.v_proj                   | 0.995565   | 2.3714       | 9.3658%\n",
      "model.layers.35.self_attn.o_proj                   | 0.995495   | 5.1741       | 9.2494%\n",
      "model.layers.35.mlp.gate_proj                      | 0.997702   | 11.5994       | 9.2658%\n",
      "model.layers.35.mlp.up_proj                        | 0.997804   | 11.9809       | 9.2604%\n",
      "model.layers.35.mlp.down_proj                      | 0.997836   | 11.0310       | 9.4581%\n",
      "--------------------------------------------------------------------------------\n",
      "Summary Statistics:\n",
      "Average Cosine Similarity: 0.972752\n",
      "Average Relative Diff:     20.3516%\n",
      "Min Cosine Similarity:     -0.011673\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# 配置\n",
    "# ==========================================\n",
    "model_id_ft = \"Creekside/Qwen-3B-gsm8k-GRPO\"   # Target (Private/Fine-tuned)\n",
    "model_id_base = \"Qwen/Qwen2.5-3B-Instruct\"      # Prior (Public/Base)\n",
    "device = \"cpu\"\n",
    "\n",
    "print(f\"Loading Fine-Tuned Model: {model_id_ft}...\")\n",
    "model_ft = AutoModelForSequenceClassification.from_pretrained(model_id_ft).to(device)\n",
    "\n",
    "print(f\"Loading Base Model: {model_id_base}...\")\n",
    "\n",
    "model_base = AutoModelForSequenceClassification.from_pretrained(model_id_base).to(device)\n",
    "\n",
    "print(\"\\nStarting Comparison (FT vs. Base)...\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Layer Name':<50} | {'Cos Sim':<10} | {'Delta Norm':<12} | {'Rel Diff (%)':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results = []\n",
    "\n",
    "# 获取所有模块的字典\n",
    "modules_ft = dict(model_ft.named_modules())\n",
    "modules_base = dict(model_base.named_modules())\n",
    "\n",
    "# 遍历 FT 模型的层\n",
    "for name, module_ft in model_ft.named_modules():\n",
    "    if isinstance(module_ft, torch.nn.Linear):\n",
    "        # 确保 Base 模型中有同名层\n",
    "        if name in modules_base:\n",
    "            module_base = modules_base[name]\n",
    "            \n",
    "            # 获取权重 (Clone detached to avoid grad issues)\n",
    "            w_ft = module_ft.weight.detach()\n",
    "            w_base = module_base.weight.detach()\n",
    "            \n",
    "            # 检查形状是否一致 (分类头可能不一致)\n",
    "            if w_ft.shape != w_base.shape:\n",
    "                print(f\"[Skipping] {name}: Shapes mismatch {w_ft.shape} vs {w_base.shape} (Likely Classification Head)\")\n",
    "                continue\n",
    "                \n",
    "            # 1. 计算 Cosine Similarity\n",
    "            # Flatten 之后计算向量夹角\n",
    "            cos_sim = torch.nn.functional.cosine_similarity(\n",
    "                w_ft.flatten(), \n",
    "                w_base.flatten(), \n",
    "                dim=0\n",
    "            ).item()\n",
    "            \n",
    "            # 2. 计算 Delta (FT - Base)\n",
    "            delta = w_ft - w_base\n",
    "            norm_delta = torch.norm(delta).item()\n",
    "            \n",
    "            # 3. 计算 Base Norm\n",
    "            norm_base = torch.norm(w_base).item()\n",
    "            \n",
    "            # 4. 计算相对差异 (Relative Difference)\n",
    "            # diff / norm_base\n",
    "            rel_diff = norm_delta / norm_base if norm_base > 0 else 0.0\n",
    "            \n",
    "            # 打印部分层的结果 (为了展示整洁，可以每隔几层打印一次，或者打印所有)\n",
    "            # 这里打印所有 Encoder/Decoder 的投影层\n",
    "            if \"proj\" in name or \"fc\" in name:\n",
    "                print(f\"{name:<50} | {cos_sim:.6f}   | {norm_delta:.4f}       | {rel_diff*100:.4f}%\")\n",
    "            \n",
    "            results.append({\n",
    "                \"Layer\": name,\n",
    "                \"Cos_Sim\": cos_sim,\n",
    "                \"Delta_Norm\": norm_delta,\n",
    "                \"Base_Norm\": norm_base,\n",
    "                \"Rel_Diff\": rel_diff\n",
    "            })\n",
    "        else:\n",
    "            print(f\"[Missing] {name} not found in Base Model.\")\n",
    "\n",
    "# ==========================================\n",
    "# 统计摘要\n",
    "# ==========================================\n",
    "df = pd.DataFrame(results)\n",
    "print(\"-\" * 80)\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Average Cosine Similarity: {df['Cos_Sim'].mean():.6f}\")\n",
    "print(f\"Average Relative Diff:     {df['Rel_Diff'].mean()*100:.4f}%\")\n",
    "print(f\"Min Cosine Similarity:     {df['Cos_Sim'].min():.6f}\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf18c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Base Model (Prior): Qwen/Qwen2.5-3B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ace43611a4045dea5094fc15f35b412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-3B-Instruct and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading Obfuscated Checkpoint: /mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt...\n",
      "3. Loading Ground Truth (for validation): Creekside/Qwen-3B-gsm8k-GRPO...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9217894039cc485c901c259c1fa99487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Creekside/Qwen-3B-gsm8k-GRPO and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STARTING FULL MODEL RECOVERY (Removing Top-30 Singular Components)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering Layers: 100%|██████████████████████████████████████| 253/253 [05:57<00:00,  1.41s/it, Sim=0.0000, Err=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RECOVERY COMPLETE\n",
      "==================================================\n",
      "Total Layers Recovered: 253\n",
      "Average Cosine Similarity: 0.9579\n",
      "Average Relative Error:    0.2736\n",
      "Worst Layer Similarity:    0.0000\n",
      "\n",
      "[SUCCESS] 模型还原极其成功！基本等同于原始私有模型。\n",
      "\n",
      "Saving recovered model to /mnt/e/untitled folder/codebase/LoRO_attack/recovered_bart_model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23842f4b1ceb48b39cb368d95d532bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4e8f84c73745358922b76067161e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccca62574794909a05127e9562d3317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5121f0794832481a8e63b4deb198d18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved. You can now load this model with 'AutoModelForSequenceClassification.from_pretrained'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. 配置\n",
    "# ==========================================\n",
    "# 攻击者的目标：从 Obfuscated Checkpoint + Base Model 恢复出 Private Model\\\n",
    "base_model_id = \"Qwen/Qwen2.5-3B-Instruct\"        # 攻击者拥有的先验\n",
    "target_model_id = \"Creekside/Qwen-3B-gsm8k-GRPO\"  # 仅用于验证攻击成功率 (GT)\n",
    "obfuscated_checkpoint = \"/mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt\" # 您的混淆文件路径\n",
    "save_path_recovered = \"/mnt/e/untitled folder/codebase/LoRO_attack/recovered_bart_model\"    # 还原后的模型保存路径\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# SVD 攻击参数\n",
    "REMOVE_RANK = 30\n",
    "\n",
    "# ==========================================\n",
    "# 2. 模型加载\n",
    "# ==========================================\n",
    "print(f\"1. Loading Base Model (Prior): {base_model_id}...\")\n",
    "# 攻击者初始只有 Base 模型\n",
    "recovered_model = AutoModelForSequenceClassification.from_pretrained(base_model_id).to(device)\n",
    "\n",
    "print(f\"2. Loading Obfuscated Checkpoint: {obfuscated_checkpoint}...\")\n",
    "if not os.path.exists(obfuscated_checkpoint):\n",
    "    raise FileNotFoundError(\"混淆 Checkpoint 未找到，请检查路径。\")\n",
    "obfus_state_dict = torch.load(obfuscated_checkpoint, map_location=device)\n",
    "\n",
    "print(f\"3. Loading Ground Truth (for validation): {target_model_id}...\")\n",
    "gt_model = AutoModelForSequenceClassification.from_pretrained(target_model_id).to(device)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 执行全模型攻击\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"STARTING FULL MODEL RECOVERY (Removing Top-{REMOVE_RANK} Singular Components)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 用于统计恢复效果\n",
    "similarities = []\n",
    "relative_errors = []\n",
    "\n",
    "# 获取所有线性层\n",
    "# 我们遍历 recovered_model (即 base_model) 的模块，然后去 check state_dict 里有没有对应的混淆权重\n",
    "all_modules = list(recovered_model.named_modules())\n",
    "linear_layers = [(n, m) for n, m in all_modules if isinstance(m, nn.Linear)]\n",
    "\n",
    "progress_bar = tqdm(linear_layers, desc=\"Recovering Layers\")\n",
    "\n",
    "for name, module in progress_bar:\n",
    "    # 1. 获取 Base 权重 (Prior)\n",
    "    W_base = module.weight.detach()\n",
    "    \n",
    "    # 2. 获取 Obfuscated 权重 (Observation)\n",
    "    # LoRO 的 state_dict key 通常是 \"layer_name.obfus_linear.weight\"\n",
    "    obfus_key = f\"{name}.obfus_linear.weight\"\n",
    "    \n",
    "    # 如果找不到对应的 key，说明这一层可能没有被混淆（或者是分类头等特殊层）\n",
    "    # 但根据 LoRO 逻辑，Linear 层应该都被混淆了\n",
    "    if obfus_key not in obfus_state_dict:\n",
    "        # 尝试直接找 name.weight (有些层可能未被 LoRO 包装)\n",
    "        if f\"{name}.weight\" in obfus_state_dict:\n",
    "            # 如果没混淆，直接加载（或者攻击者认为这就是原样）\n",
    "            # 但这里我们假设攻击者不知道，只看混淆文件\n",
    "            continue\n",
    "        else:\n",
    "            # 可能是分类头，LoRO 有时也会混淆它。\n",
    "            # 如果 key 不匹配，跳过\n",
    "            continue\n",
    "            \n",
    "    W_obfus = obfus_state_dict[obfus_key].detach()\n",
    "    \n",
    "    # 3. 计算 Diff\n",
    "    # Diff = W_obfus - W_base\n",
    "    Diff = W_obfus - W_base\n",
    "    \n",
    "    # 4. SVD 攻击 (去噪)\n",
    "    # 使用 float32 进行 SVD 以保证精度\n",
    "    U, S, Vh = torch.linalg.svd(Diff.float(), full_matrices=False)\n",
    "    \n",
    "    # 剔除前 K 个奇异值 (认为它们是 LoRO 注入的低秩噪声)\n",
    "    S_clean = S.clone()\n",
    "    S_clean[:REMOVE_RANK] = 0.0\n",
    "    \n",
    "    # 重构 Delta\n",
    "    Delta_Recovered = (U @ torch.diag(S_clean) @ Vh).to(W_base.dtype)\n",
    "    \n",
    "    # 5. 恢复权重\n",
    "    # W_rec = W_base + Delta_rec\n",
    "    W_recovered = W_base + Delta_Recovered\n",
    "    \n",
    "    # 更新 recovered_model 的权重\n",
    "    module.weight.data = W_recovered\n",
    "    \n",
    "    # 处理 Bias (LoRO 代码中 Bias 是直接存储的，通常没有加噪声，或者加了也可以直接减)\n",
    "    # 检查 utils.py/loro.py: \"self.obfus_linear.bias = torch.nn.Parameter(original_linear.bias)\"\n",
    "    # Bias 没有加噪声！所以直接从 obfus_state_dict 读取即可（攻击者可以直接拿）\n",
    "    obfus_bias_key = f\"{name}.obfus_linear.bias\"\n",
    "    if obfus_bias_key in obfus_state_dict and module.bias is not None:\n",
    "        module.bias.data = obfus_state_dict[obfus_bias_key].detach()\n",
    "    \n",
    "    # 6. 验证 (与 GT 对比)\n",
    "    # 获取 GT 对应层的权重\n",
    "    # 注意：需通过 name 从 gt_model 索引\n",
    "    gt_module = dict(gt_model.named_modules())[name]\n",
    "    W_gt = gt_module.weight.detach()\n",
    "    \n",
    "    # 计算指标\n",
    "    # 真实的 Delta = W_gt - W_base\n",
    "    Delta_True = W_gt - W_base\n",
    "    \n",
    "    # 计算恢复出的 Delta 和 真实 Delta 的相似度\n",
    "    sim = torch.nn.functional.cosine_similarity(Delta_True.flatten(), Delta_Recovered.flatten(), dim=0).item()\n",
    "    rel_err = torch.norm(Delta_Recovered - Delta_True) / torch.norm(Delta_True)\n",
    "    \n",
    "    similarities.append(sim)\n",
    "    relative_errors.append(rel_err.item())\n",
    "    \n",
    "    # 更新进度条显示当前层的相似度\n",
    "    progress_bar.set_postfix({\"Sim\": f\"{sim:.4f}\", \"Err\": f\"{rel_err:.4f}\"})\n",
    "\n",
    "# ==========================================\n",
    "# 4. 结果汇总与保存\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RECOVERY COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "avg_sim = sum(similarities) / len(similarities)\n",
    "avg_err = sum(relative_errors) / len(relative_errors)\n",
    "min_sim = min(similarities)\n",
    "\n",
    "print(f\"Total Layers Recovered: {len(similarities)}\")\n",
    "print(f\"Average Cosine Similarity: {avg_sim:.4f}\")\n",
    "print(f\"Average Relative Error:    {avg_err:.4f}\")\n",
    "print(f\"Worst Layer Similarity:    {min_sim:.4f}\")\n",
    "\n",
    "if avg_sim > 0.95:\n",
    "    print(\"\\n[SUCCESS] 模型还原极其成功！基本等同于原始私有模型。\")\n",
    "else:\n",
    "    print(\"\\n[WARNING] 模型还原效果一般，可能需要调整 REMOVE_RANK 参数。\")\n",
    "\n",
    "# 保存模型\n",
    "print(f\"\\nSaving recovered model to {save_path_recovered}...\")\n",
    "recovered_model.save_pretrained(save_path_recovered)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "tokenizer.save_pretrained(save_path_recovered)\n",
    "print(\"Saved. You can now load this model with 'AutoModelForSequenceClassification.from_pretrained'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ecd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Recovered Model from: /mnt/e/untitled folder/codebase/LoRO_attack/recovered_bart_model ...\n",
      "Device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from '/mnt/e/untitled folder/codebase/LoRO_attack/recovered_bart_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Some weights of Qwen2ForCausalLM were not initialized from the model checkpoint at /mnt/e/untitled folder/codebase/LoRO_attack/recovered_bart_model and are newly initialized: ['lm_head.weight', 'model.embed_tokens.weight', 'model.layers.0.input_layernorm.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.post_attention_layernorm.weight', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.input_layernorm.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.input_layernorm.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.post_attention_layernorm.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.input_layernorm.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.post_attention_layernorm.weight', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.input_layernorm.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.post_attention_layernorm.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.input_layernorm.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.post_attention_layernorm.weight', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.input_layernorm.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.post_attention_layernorm.weight', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.input_layernorm.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.post_attention_layernorm.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.input_layernorm.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.post_attention_layernorm.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.input_layernorm.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.post_attention_layernorm.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.input_layernorm.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.post_attention_layernorm.weight', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.input_layernorm.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.post_attention_layernorm.weight', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.input_layernorm.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.post_attention_layernorm.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.input_layernorm.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.post_attention_layernorm.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.input_layernorm.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.post_attention_layernorm.weight', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.input_layernorm.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.post_attention_layernorm.weight', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.input_layernorm.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.post_attention_layernorm.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.input_layernorm.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.post_attention_layernorm.weight', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.32.input_layernorm.weight', 'model.layers.32.mlp.down_proj.weight', 'model.layers.32.mlp.gate_proj.weight', 'model.layers.32.mlp.up_proj.weight', 'model.layers.32.post_attention_layernorm.weight', 'model.layers.32.self_attn.k_proj.bias', 'model.layers.32.self_attn.k_proj.weight', 'model.layers.32.self_attn.o_proj.weight', 'model.layers.32.self_attn.q_proj.bias', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.v_proj.bias', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.33.input_layernorm.weight', 'model.layers.33.mlp.down_proj.weight', 'model.layers.33.mlp.gate_proj.weight', 'model.layers.33.mlp.up_proj.weight', 'model.layers.33.post_attention_layernorm.weight', 'model.layers.33.self_attn.k_proj.bias', 'model.layers.33.self_attn.k_proj.weight', 'model.layers.33.self_attn.o_proj.weight', 'model.layers.33.self_attn.q_proj.bias', 'model.layers.33.self_attn.q_proj.weight', 'model.layers.33.self_attn.v_proj.bias', 'model.layers.33.self_attn.v_proj.weight', 'model.layers.34.input_layernorm.weight', 'model.layers.34.mlp.down_proj.weight', 'model.layers.34.mlp.gate_proj.weight', 'model.layers.34.mlp.up_proj.weight', 'model.layers.34.post_attention_layernorm.weight', 'model.layers.34.self_attn.k_proj.bias', 'model.layers.34.self_attn.k_proj.weight', 'model.layers.34.self_attn.o_proj.weight', 'model.layers.34.self_attn.q_proj.bias', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.v_proj.bias', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.35.input_layernorm.weight', 'model.layers.35.mlp.down_proj.weight', 'model.layers.35.mlp.gate_proj.weight', 'model.layers.35.mlp.up_proj.weight', 'model.layers.35.post_attention_layernorm.weight', 'model.layers.35.self_attn.k_proj.bias', 'model.layers.35.self_attn.k_proj.weight', 'model.layers.35.self_attn.o_proj.weight', 'model.layers.35.self_attn.q_proj.bias', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.v_proj.bias', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.9.self_attn.v_proj.weight', 'model.norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GSM8K dataset (test split)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3df340036d54139b5053708a6cba7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ee65b20b43414fb2dea053bf55dadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a612537cf2534218abc7520ff4388a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f3fe2221d94d91bea23432fd889815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d2ca22b49549d3bc1bb4ea9f1edf7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start evaluating on 100 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/100 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "  1%|▋                                                                     | 1/100 [01:25<2:21:14, 85.60s/it, acc=0.00%]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. 配置路径\n",
    "# ==========================================\n",
    "recovered_model_path = \"/mnt/e/untitled folder/codebase/LoRO_attack/recovered_bart_model\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Loading Recovered Model from: {recovered_model_path} ...\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 加载模型与数据集\n",
    "# ==========================================\n",
    "try:\n",
    "    # 加载还原的模型\n",
    "    tokenizer = AutoTokenizer.from_pretrained(recovered_model_path)\n",
    "    model = AutoModelForCausalLM.from_pretrained(recovered_model_path, torch_dtype=torch.float16).to(device)\n",
    "    model.eval()\n",
    "except Exception as e:\n",
    "    print(f\"模型加载失败: {e}\")\n",
    "    print(\"请检查路径是否正确，或者模型文件是否完整。\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"Loading GSM8K dataset (test split)...\")\n",
    "# 加载 GSM8K 测试集\n",
    "dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
    "\n",
    "# 为了快速验证，您可以只测前 100 条。如果要测全集 (1319条)，请注释掉下面这行\n",
    "dataset = dataset.select(range(100)) \n",
    "\n",
    "print(f\"Start evaluating on {len(dataset)} samples...\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. 定义推理逻辑\n",
    "# ==========================================\n",
    "# 使用 text-generation pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if device==\"cuda\" else -1)\n",
    "\n",
    "def extract_answer(generated_text):\n",
    "    # 提取 #### 后面的数字\n",
    "    try:\n",
    "        # 找到最后出现的 ####\n",
    "        if \"####\" in generated_text:\n",
    "            ans = generated_text.split(\"####\")[-1].strip()\n",
    "            # 移除可能的非数字字符（保留数字和可能的负号/小数点）\n",
    "            # 这里简单处理：通常 GSM8K 答案是纯数字\n",
    "            ans = ans.replace(\",\", \"\") # 去掉千分位\n",
    "            return ans\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 4. 执行评估\n",
    "# ==========================================\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# 进度条\n",
    "progress_bar = tqdm.tqdm(dataset)\n",
    "\n",
    "for sample in progress_bar:\n",
    "    question = sample['question']\n",
    "    # GSM8K 的 answer 字段通常包含推理过程，最后是 #### 数字\n",
    "    # 我们只需要 #### 后面的部分作为 ground truth\n",
    "    ground_truth = sample['answer'].split('####')[-1].strip()\n",
    "    \n",
    "    # 构造 Prompt (参考原作者格式)\n",
    "    # Qwen 推荐使用 Chat 模板，或者按照 LoRO 原作者的 simple formatting\n",
    "    # 这里沿用您 notebook 中的 prompt 格式\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"{question} Please think step by step, give the final number in ONE new line after ####, without other words. Your answer will be considered wrong if not follow this rule.\"}\n",
    "    ]\n",
    "    \n",
    "    # 构建输入文本\n",
    "    prompt_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    # 推理\n",
    "    try:\n",
    "        # 设置 max_new_tokens 防止生成太长\n",
    "        outputs = pipe(prompt_text, max_new_tokens=512, do_sample=False, temperature=0.0)\n",
    "        generated_text = outputs[0]['generated_text']\n",
    "        \n",
    "        # 提取模型生成的回答部分 (去除 prompt)\n",
    "        # pipeline 返回通常包含 prompt，Qwen 的 chat template 可能会有特殊处理\n",
    "        # 简单处理：直接在生成的完整文本里找 ####\n",
    "        \n",
    "        pred_ans = extract_answer(generated_text)\n",
    "        \n",
    "        # 对比\n",
    "        # 简单的字符串匹配，或者数值对比\n",
    "        if pred_ans == ground_truth:\n",
    "            correct += 1\n",
    "        elif pred_ans is not None:\n",
    "             # 尝试转 float 对比 (处理 540.0 vs 540)\n",
    "            try:\n",
    "                if float(pred_ans) == float(ground_truth):\n",
    "                    correct += 1\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sample: {e}\")\n",
    "    \n",
    "    total += 1\n",
    "    progress_bar.set_postfix({'acc': f\"{correct/total:.2%}\"})\n",
    "\n",
    "# ==========================================\n",
    "# 5. 输出最终结果\n",
    "# ==========================================\n",
    "acc = correct / total\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"Evaluation Result on {total} samples\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Correct:  {correct}\")\n",
    "print(f\"Accuracy: {acc:.4%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
