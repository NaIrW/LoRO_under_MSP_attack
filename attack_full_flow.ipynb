{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5739ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载模型: facebook/bart-large-mnli ...\n",
      "模型加载完成。准备进行 LoRO 混淆...\n",
      "开始混淆 (Noise Magnitude: 1)...\n",
      "Obfuscating: model.encoder.layers.0.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.0.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.0.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.0.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.0.fc1\n",
      "Obfuscating: model.encoder.layers.0.fc2\n",
      "Obfuscating: model.encoder.layers.1.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.1.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.1.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.1.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.1.fc1\n",
      "Obfuscating: model.encoder.layers.1.fc2\n",
      "Obfuscating: model.encoder.layers.2.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.2.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.2.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.2.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.2.fc1\n",
      "Obfuscating: model.encoder.layers.2.fc2\n",
      "Obfuscating: model.encoder.layers.3.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.3.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.3.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.3.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.3.fc1\n",
      "Obfuscating: model.encoder.layers.3.fc2\n",
      "Obfuscating: model.encoder.layers.4.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.4.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.4.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.4.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.4.fc1\n",
      "Obfuscating: model.encoder.layers.4.fc2\n",
      "Obfuscating: model.encoder.layers.5.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.5.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.5.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.5.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.5.fc1\n",
      "Obfuscating: model.encoder.layers.5.fc2\n",
      "Obfuscating: model.encoder.layers.6.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.6.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.6.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.6.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.6.fc1\n",
      "Obfuscating: model.encoder.layers.6.fc2\n",
      "Obfuscating: model.encoder.layers.7.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.7.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.7.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.7.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.7.fc1\n",
      "Obfuscating: model.encoder.layers.7.fc2\n",
      "Obfuscating: model.encoder.layers.8.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.8.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.8.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.8.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.8.fc1\n",
      "Obfuscating: model.encoder.layers.8.fc2\n",
      "Obfuscating: model.encoder.layers.9.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.9.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.9.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.9.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.9.fc1\n",
      "Obfuscating: model.encoder.layers.9.fc2\n",
      "Obfuscating: model.encoder.layers.10.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.10.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.10.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.10.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.10.fc1\n",
      "Obfuscating: model.encoder.layers.10.fc2\n",
      "Obfuscating: model.encoder.layers.11.self_attn.k_proj\n",
      "Obfuscating: model.encoder.layers.11.self_attn.v_proj\n",
      "Obfuscating: model.encoder.layers.11.self_attn.q_proj\n",
      "Obfuscating: model.encoder.layers.11.self_attn.out_proj\n",
      "Obfuscating: model.encoder.layers.11.fc1\n",
      "Obfuscating: model.encoder.layers.11.fc2\n",
      "Obfuscating: model.decoder.layers.0.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.0.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.0.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.0.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.0.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.0.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.0.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.0.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.0.fc1\n",
      "Obfuscating: model.decoder.layers.0.fc2\n",
      "Obfuscating: model.decoder.layers.1.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.1.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.1.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.1.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.1.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.1.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.1.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.1.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.1.fc1\n",
      "Obfuscating: model.decoder.layers.1.fc2\n",
      "Obfuscating: model.decoder.layers.2.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.2.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.2.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.2.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.2.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.2.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.2.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.2.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.2.fc1\n",
      "Obfuscating: model.decoder.layers.2.fc2\n",
      "Obfuscating: model.decoder.layers.3.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.3.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.3.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.3.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.3.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.3.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.3.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.3.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.3.fc1\n",
      "Obfuscating: model.decoder.layers.3.fc2\n",
      "Obfuscating: model.decoder.layers.4.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.4.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.4.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.4.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.4.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.4.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.4.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.4.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.4.fc1\n",
      "Obfuscating: model.decoder.layers.4.fc2\n",
      "Obfuscating: model.decoder.layers.5.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.5.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.5.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.5.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.5.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.5.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.5.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.5.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.5.fc1\n",
      "Obfuscating: model.decoder.layers.5.fc2\n",
      "Obfuscating: model.decoder.layers.6.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.6.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.6.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.6.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.6.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.6.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.6.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.6.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.6.fc1\n",
      "Obfuscating: model.decoder.layers.6.fc2\n",
      "Obfuscating: model.decoder.layers.7.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.7.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.7.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.7.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.7.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.7.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.7.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.7.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.7.fc1\n",
      "Obfuscating: model.decoder.layers.7.fc2\n",
      "Obfuscating: model.decoder.layers.8.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.8.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.8.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.8.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.8.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.8.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.8.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.8.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.8.fc1\n",
      "Obfuscating: model.decoder.layers.8.fc2\n",
      "Obfuscating: model.decoder.layers.9.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.9.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.9.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.9.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.9.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.9.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.9.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.9.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.9.fc1\n",
      "Obfuscating: model.decoder.layers.9.fc2\n",
      "Obfuscating: model.decoder.layers.10.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.10.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.10.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.10.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.10.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.10.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.10.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.10.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.10.fc1\n",
      "Obfuscating: model.decoder.layers.10.fc2\n",
      "Obfuscating: model.decoder.layers.11.self_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.11.self_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.11.self_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.11.self_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.11.encoder_attn.k_proj\n",
      "Obfuscating: model.decoder.layers.11.encoder_attn.v_proj\n",
      "Obfuscating: model.decoder.layers.11.encoder_attn.q_proj\n",
      "Obfuscating: model.decoder.layers.11.encoder_attn.out_proj\n",
      "Obfuscating: model.decoder.layers.11.fc1\n",
      "Obfuscating: model.decoder.layers.11.fc2\n",
      "Obfuscating: classification_head.dense\n",
      "Obfuscating: classification_head.out_proj\n",
      "正在保存混淆后的模型至: /mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt ...\n",
      "Checkpoint Path: /mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "repo_path = \"/mnt/e/untitled folder/codebase/LoRO/LoRO\"  \n",
    "if os.path.exists(repo_path) and repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)\n",
    "\n",
    "try:\n",
    "    from utils import model_obfuscation\n",
    "except ImportError as e:\n",
    "    print('wrong repo_path')\n",
    "    sys.exit(1)\n",
    "\n",
    "# ==========================================\n",
    "# 1. 加载目标模型 (Private Model)\n",
    "# ==========================================\n",
    "model_id = \"facebook/bart-large-mnli\"\n",
    "device = \"cpu\"\n",
    "save_path = \"/mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt\"\n",
    "\n",
    "print(f\"正在加载模型: {model_id} ...\")\n",
    "# bart-large-mnli 是一个分类模型 (SequenceClassification)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id).to(device)\n",
    "\n",
    "print(\"模型加载完成。准备进行 LoRO 混淆...\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 执行混淆 (调用仓库代码)\n",
    "# ==========================================\n",
    "noise_magnitude = 1\n",
    "\n",
    "print(f\"开始混淆 (Noise Magnitude: {noise_magnitude})...\")\n",
    "obfuscated_model = model_obfuscation(model, device=device, noise_mag=noise_magnitude, r=16)\n",
    "\n",
    "# ==========================================\n",
    "# 4. 保存混淆后的 Checkpoint\n",
    "# ==========================================\n",
    "print(f\"正在保存混淆后的模型至: {save_path} ...\")\n",
    "torch.save(obfuscated_model.state_dict(), save_path)\n",
    "\n",
    "print(f\"Checkpoint Path: {os.path.abspath(save_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d5bbece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Fine-Tuned Model: facebook/bart-large-mnli...\n",
      "Loading Base Model: facebook/bart-large...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Comparison (FT vs. Base)...\n",
      "--------------------------------------------------------------------------------\n",
      "Layer Name                                         | Cos Sim    | Delta Norm   | Rel Diff (%)\n",
      "--------------------------------------------------------------------------------\n",
      "model.encoder.layers.0.self_attn.k_proj            | 0.999108   | 3.4783       | 4.2349%\n",
      "model.encoder.layers.0.self_attn.v_proj            | 0.996787   | 2.9122       | 8.0912%\n",
      "model.encoder.layers.0.self_attn.q_proj            | 0.999066   | 3.5483       | 4.3220%\n",
      "model.encoder.layers.0.self_attn.out_proj          | 0.996372   | 3.1320       | 8.5911%\n",
      "model.encoder.layers.0.fc1                         | 0.998407   | 6.7873       | 5.9929%\n",
      "model.encoder.layers.0.fc2                         | 0.998149   | 6.6759       | 6.4737%\n",
      "model.encoder.layers.1.self_attn.k_proj            | 0.999255   | 3.2776       | 3.8583%\n",
      "model.encoder.layers.1.self_attn.v_proj            | 0.997652   | 2.8943       | 6.8707%\n",
      "model.encoder.layers.1.self_attn.q_proj            | 0.999193   | 3.4085       | 4.0178%\n",
      "model.encoder.layers.1.self_attn.out_proj          | 0.997018   | 3.2393       | 7.7517%\n",
      "model.encoder.layers.1.fc1                         | 0.998902   | 6.7515       | 5.0634%\n",
      "model.encoder.layers.1.fc2                         | 0.998266   | 7.3194       | 6.2188%\n",
      "model.encoder.layers.2.self_attn.k_proj            | 0.999238   | 3.2737       | 3.9095%\n",
      "model.encoder.layers.2.self_attn.v_proj            | 0.998041   | 2.9271       | 6.2777%\n",
      "model.encoder.layers.2.self_attn.q_proj            | 0.999170   | 3.4065       | 4.0728%\n",
      "model.encoder.layers.2.self_attn.out_proj          | 0.997229   | 3.3303       | 7.4578%\n",
      "model.encoder.layers.2.fc1                         | 0.999054   | 6.6908       | 4.7900%\n",
      "model.encoder.layers.2.fc2                         | 0.998644   | 6.8220       | 5.5951%\n",
      "model.encoder.layers.3.self_attn.k_proj            | 0.999214   | 3.3402       | 3.9623%\n",
      "model.encoder.layers.3.self_attn.v_proj            | 0.997200   | 3.0104       | 7.5269%\n",
      "model.encoder.layers.3.self_attn.q_proj            | 0.999209   | 3.3864       | 3.9741%\n",
      "model.encoder.layers.3.self_attn.out_proj          | 0.996663   | 3.2094       | 8.2124%\n",
      "model.encoder.layers.3.fc1                         | 0.998705   | 6.7821       | 5.4381%\n",
      "model.encoder.layers.3.fc2                         | 0.998274   | 6.4515       | 6.2848%\n",
      "model.encoder.layers.4.self_attn.k_proj            | 0.999052   | 3.5159       | 4.3656%\n",
      "model.encoder.layers.4.self_attn.v_proj            | 0.997980   | 3.0085       | 6.3899%\n",
      "model.encoder.layers.4.self_attn.q_proj            | 0.999029   | 3.5458       | 4.4206%\n",
      "model.encoder.layers.4.self_attn.out_proj          | 0.997633   | 3.1280       | 6.8956%\n",
      "model.encoder.layers.4.fc1                         | 0.998628   | 6.7894       | 5.6064%\n",
      "model.encoder.layers.4.fc2                         | 0.998351   | 6.1911       | 6.1704%\n",
      "model.encoder.layers.5.self_attn.k_proj            | 0.999110   | 3.5111       | 4.2179%\n",
      "model.encoder.layers.5.self_attn.v_proj            | 0.998210   | 2.9562       | 6.0147%\n",
      "model.encoder.layers.5.self_attn.q_proj            | 0.999128   | 3.5046       | 4.1756%\n",
      "model.encoder.layers.5.self_attn.out_proj          | 0.998070   | 3.0634       | 6.2433%\n",
      "model.encoder.layers.5.fc1                         | 0.998579   | 6.7605       | 5.7203%\n",
      "model.encoder.layers.5.fc2                         | 0.998228   | 5.9251       | 6.3521%\n",
      "model.encoder.layers.6.self_attn.k_proj            | 0.999089   | 3.5618       | 4.2769%\n",
      "model.encoder.layers.6.self_attn.v_proj            | 0.998105   | 2.9297       | 6.1774%\n",
      "model.encoder.layers.6.self_attn.q_proj            | 0.999089   | 3.5667       | 4.2773%\n",
      "model.encoder.layers.6.self_attn.out_proj          | 0.998040   | 2.9892       | 6.2951%\n",
      "model.encoder.layers.6.fc1                         | 0.998448   | 6.6991       | 5.9717%\n",
      "model.encoder.layers.6.fc2                         | 0.998108   | 5.6334       | 6.5398%\n",
      "model.encoder.layers.7.self_attn.k_proj            | 0.999148   | 3.5482       | 4.1321%\n",
      "model.encoder.layers.7.self_attn.v_proj            | 0.998247   | 2.8760       | 5.9633%\n",
      "model.encoder.layers.7.self_attn.q_proj            | 0.999143   | 3.5487       | 4.1402%\n",
      "model.encoder.layers.7.self_attn.out_proj          | 0.998260   | 2.9146       | 5.9472%\n",
      "model.encoder.layers.7.fc1                         | 0.998321   | 6.5940       | 6.1902%\n",
      "model.encoder.layers.7.fc2                         | 0.998012   | 5.4390       | 6.7108%\n",
      "model.encoder.layers.8.self_attn.k_proj            | 0.999152   | 3.6021       | 4.1243%\n",
      "model.encoder.layers.8.self_attn.v_proj            | 0.997888   | 2.7551       | 6.5351%\n",
      "model.encoder.layers.8.self_attn.q_proj            | 0.999166   | 3.5902       | 4.0847%\n",
      "model.encoder.layers.8.self_attn.out_proj          | 0.998055   | 2.7256       | 6.2767%\n",
      "model.encoder.layers.8.fc1                         | 0.998258   | 6.5055       | 6.3001%\n",
      "model.encoder.layers.8.fc2                         | 0.998123   | 5.1097       | 6.5705%\n",
      "model.encoder.layers.9.self_attn.k_proj            | 0.999109   | 3.6262       | 4.2206%\n",
      "model.encoder.layers.9.self_attn.v_proj            | 0.998495   | 2.7295       | 5.5252%\n",
      "model.encoder.layers.9.self_attn.q_proj            | 0.999090   | 3.6568       | 4.2654%\n",
      "model.encoder.layers.9.self_attn.out_proj          | 0.998388   | 2.7817       | 5.7218%\n",
      "model.encoder.layers.9.fc1                         | 0.998254   | 6.2930       | 6.3266%\n",
      "model.encoder.layers.9.fc2                         | 0.998187   | 4.8752       | 6.4735%\n",
      "model.encoder.layers.10.self_attn.k_proj           | 0.999167   | 3.5732       | 4.0849%\n",
      "model.encoder.layers.10.self_attn.v_proj           | 0.998182   | 2.5860       | 6.0964%\n",
      "model.encoder.layers.10.self_attn.q_proj           | 0.999183   | 3.5762       | 4.0419%\n",
      "model.encoder.layers.10.self_attn.out_proj         | 0.998050   | 2.6049       | 6.3135%\n",
      "model.encoder.layers.10.fc1                        | 0.998176   | 6.2122       | 6.4535%\n",
      "model.encoder.layers.10.fc2                        | 0.998120   | 4.7511       | 6.5995%\n",
      "model.encoder.layers.11.self_attn.k_proj           | 0.999032   | 3.6626       | 4.4062%\n",
      "model.encoder.layers.11.self_attn.v_proj           | 0.998124   | 2.5203       | 6.2184%\n",
      "model.encoder.layers.11.self_attn.q_proj           | 0.998990   | 3.6489       | 4.4981%\n",
      "model.encoder.layers.11.self_attn.out_proj         | 0.997752   | 2.5204       | 6.7869%\n",
      "model.encoder.layers.11.fc1                        | 0.998156   | 5.9754       | 6.4784%\n",
      "model.encoder.layers.11.fc2                        | 0.998271   | 4.5455       | 6.3445%\n",
      "model.decoder.layers.0.self_attn.k_proj            | 0.998942   | 4.1716       | 4.6158%\n",
      "model.decoder.layers.0.self_attn.v_proj            | 0.994375   | 3.9412       | 11.3894%\n",
      "model.decoder.layers.0.self_attn.q_proj            | 0.998975   | 3.9475       | 4.5485%\n",
      "model.decoder.layers.0.self_attn.out_proj          | 0.993764   | 4.1976       | 11.8967%\n",
      "model.decoder.layers.0.encoder_attn.k_proj         | 0.999245   | 3.7042       | 3.8999%\n",
      "model.decoder.layers.0.encoder_attn.v_proj         | 0.998914   | 3.4329       | 4.6900%\n",
      "model.decoder.layers.0.encoder_attn.q_proj         | 0.999099   | 4.1144       | 4.2556%\n",
      "model.decoder.layers.0.encoder_attn.out_proj       | 0.998687   | 3.7827       | 5.1453%\n",
      "model.decoder.layers.0.fc1                         | 0.997172   | 8.4188       | 7.9111%\n",
      "model.decoder.layers.0.fc2                         | 0.997320   | 6.8407       | 7.6296%\n",
      "model.decoder.layers.1.self_attn.k_proj            | 0.998963   | 3.8222       | 4.5586%\n",
      "model.decoder.layers.1.self_attn.v_proj            | 0.996066   | 3.5346       | 9.1241%\n",
      "model.decoder.layers.1.self_attn.q_proj            | 0.998964   | 3.8316       | 4.5592%\n",
      "model.decoder.layers.1.self_attn.out_proj          | 0.995463   | 3.7481       | 9.7704%\n",
      "model.decoder.layers.1.encoder_attn.k_proj         | 0.999208   | 3.7372       | 3.9843%\n",
      "model.decoder.layers.1.encoder_attn.v_proj         | 0.998867   | 3.2922       | 4.8043%\n",
      "model.decoder.layers.1.encoder_attn.q_proj         | 0.999260   | 3.6750       | 3.8518%\n",
      "model.decoder.layers.1.encoder_attn.out_proj       | 0.998812   | 3.2810       | 4.9013%\n",
      "model.decoder.layers.1.fc1                         | 0.997576   | 7.9109       | 7.3604%\n",
      "model.decoder.layers.1.fc2                         | 0.997003   | 6.3293       | 8.1121%\n",
      "model.decoder.layers.2.self_attn.k_proj            | 0.998987   | 3.6375       | 4.5115%\n",
      "model.decoder.layers.2.self_attn.v_proj            | 0.997152   | 3.3094       | 7.6341%\n",
      "model.decoder.layers.2.self_attn.q_proj            | 0.998976   | 3.6260       | 4.5470%\n",
      "model.decoder.layers.2.self_attn.out_proj          | 0.996358   | 3.5139       | 8.6236%\n",
      "model.decoder.layers.2.encoder_attn.k_proj         | 0.999235   | 3.5868       | 3.9094%\n",
      "model.decoder.layers.2.encoder_attn.v_proj         | 0.999022   | 3.1991       | 4.4557%\n",
      "model.decoder.layers.2.encoder_attn.q_proj         | 0.999252   | 3.6381       | 3.8735%\n",
      "model.decoder.layers.2.encoder_attn.out_proj       | 0.998864   | 3.2794       | 4.7977%\n",
      "model.decoder.layers.2.fc1                         | 0.997668   | 7.6254       | 7.2359%\n",
      "model.decoder.layers.2.fc2                         | 0.997278   | 5.7210       | 7.7957%\n",
      "model.decoder.layers.3.self_attn.k_proj            | 0.998906   | 3.6687       | 4.6877%\n",
      "model.decoder.layers.3.self_attn.v_proj            | 0.997859   | 3.0695       | 6.5935%\n",
      "model.decoder.layers.3.self_attn.q_proj            | 0.998909   | 3.7000       | 4.6805%\n",
      "model.decoder.layers.3.self_attn.out_proj          | 0.997234   | 3.2693       | 7.4915%\n",
      "model.decoder.layers.3.encoder_attn.k_proj         | 0.999265   | 3.5259       | 3.8383%\n",
      "model.decoder.layers.3.encoder_attn.v_proj         | 0.998912   | 3.1471       | 4.6907%\n",
      "model.decoder.layers.3.encoder_attn.q_proj         | 0.999249   | 3.6516       | 3.8837%\n",
      "model.decoder.layers.3.encoder_attn.out_proj       | 0.998717   | 3.2928       | 5.0861%\n",
      "model.decoder.layers.3.fc1                         | 0.997717   | 7.3372       | 7.1789%\n",
      "model.decoder.layers.3.fc2                         | 0.997501   | 5.5575       | 7.4478%\n",
      "model.decoder.layers.4.self_attn.k_proj            | 0.998797   | 3.7709       | 4.9256%\n",
      "model.decoder.layers.4.self_attn.v_proj            | 0.997898   | 3.0793       | 6.5055%\n",
      "model.decoder.layers.4.self_attn.q_proj            | 0.998843   | 3.7340       | 4.8322%\n",
      "model.decoder.layers.4.self_attn.out_proj          | 0.997015   | 3.3696       | 7.7506%\n",
      "model.decoder.layers.4.encoder_attn.k_proj         | 0.999350   | 3.4782       | 3.6246%\n",
      "model.decoder.layers.4.encoder_attn.v_proj         | 0.998903   | 3.2850       | 4.7077%\n",
      "model.decoder.layers.4.encoder_attn.q_proj         | 0.999328   | 3.5820       | 3.6851%\n",
      "model.decoder.layers.4.encoder_attn.out_proj       | 0.998624   | 3.5790       | 5.2655%\n",
      "model.decoder.layers.4.fc1                         | 0.997583   | 7.1300       | 7.3498%\n",
      "model.decoder.layers.4.fc2                         | 0.997609   | 5.3693       | 7.2807%\n",
      "model.decoder.layers.5.self_attn.k_proj            | 0.998726   | 3.9122       | 5.0667%\n",
      "model.decoder.layers.5.self_attn.v_proj            | 0.997136   | 3.2644       | 7.6096%\n",
      "model.decoder.layers.5.self_attn.q_proj            | 0.998793   | 3.8725       | 4.9364%\n",
      "model.decoder.layers.5.self_attn.out_proj          | 0.996090   | 3.5143       | 8.9059%\n",
      "model.decoder.layers.5.encoder_attn.k_proj         | 0.999324   | 3.5700       | 3.7103%\n",
      "model.decoder.layers.5.encoder_attn.v_proj         | 0.998858   | 3.1224       | 4.8003%\n",
      "model.decoder.layers.5.encoder_attn.q_proj         | 0.999304   | 3.6737       | 3.7512%\n",
      "model.decoder.layers.5.encoder_attn.out_proj       | 0.998648   | 3.4263       | 5.2197%\n",
      "model.decoder.layers.5.fc1                         | 0.997558   | 7.1026       | 7.3856%\n",
      "model.decoder.layers.5.fc2                         | 0.997624   | 5.3134       | 7.2916%\n",
      "model.decoder.layers.6.self_attn.k_proj            | 0.998718   | 3.9613       | 5.0796%\n",
      "model.decoder.layers.6.self_attn.v_proj            | 0.996728   | 3.3780       | 8.1660%\n",
      "model.decoder.layers.6.self_attn.q_proj            | 0.998808   | 3.8887       | 4.8974%\n",
      "model.decoder.layers.6.self_attn.out_proj          | 0.995655   | 3.5474       | 9.4293%\n",
      "model.decoder.layers.6.encoder_attn.k_proj         | 0.999335   | 3.6288       | 3.6765%\n",
      "model.decoder.layers.6.encoder_attn.v_proj         | 0.998590   | 3.5378       | 5.3371%\n",
      "model.decoder.layers.6.encoder_attn.q_proj         | 0.999233   | 3.9876       | 3.9476%\n",
      "model.decoder.layers.6.encoder_attn.out_proj       | 0.998081   | 4.1361       | 6.2113%\n",
      "model.decoder.layers.6.fc1                         | 0.997427   | 7.1220       | 7.5728%\n",
      "model.decoder.layers.6.fc2                         | 0.997076   | 5.2280       | 8.0198%\n",
      "model.decoder.layers.7.self_attn.k_proj            | 0.998732   | 3.9631       | 5.0428%\n",
      "model.decoder.layers.7.self_attn.v_proj            | 0.996117   | 3.2616       | 8.9643%\n",
      "model.decoder.layers.7.self_attn.q_proj            | 0.998804   | 3.9249       | 4.9010%\n",
      "model.decoder.layers.7.self_attn.out_proj          | 0.994853   | 3.4245       | 10.3616%\n",
      "model.decoder.layers.7.encoder_attn.k_proj         | 0.999278   | 3.6642       | 3.8154%\n",
      "model.decoder.layers.7.encoder_attn.v_proj         | 0.998447   | 3.4903       | 5.6081%\n",
      "model.decoder.layers.7.encoder_attn.q_proj         | 0.999246   | 3.8341       | 3.9048%\n",
      "model.decoder.layers.7.encoder_attn.out_proj       | 0.998072   | 3.8699       | 6.2346%\n",
      "model.decoder.layers.7.fc1                         | 0.997413   | 6.9010       | 7.5726%\n",
      "model.decoder.layers.7.fc2                         | 0.997294   | 4.9442       | 7.7697%\n",
      "model.decoder.layers.8.self_attn.k_proj            | 0.998822   | 3.8528       | 4.8642%\n",
      "model.decoder.layers.8.self_attn.v_proj            | 0.996320   | 3.1578       | 8.7203%\n",
      "model.decoder.layers.8.self_attn.q_proj            | 0.998892   | 3.8620       | 4.7171%\n",
      "model.decoder.layers.8.self_attn.out_proj          | 0.994792   | 3.3668       | 10.4035%\n",
      "model.decoder.layers.8.encoder_attn.k_proj         | 0.999222   | 3.7434       | 3.9703%\n",
      "model.decoder.layers.8.encoder_attn.v_proj         | 0.998174   | 3.6607       | 6.1012%\n",
      "model.decoder.layers.8.encoder_attn.q_proj         | 0.999227   | 3.8068       | 3.9600%\n",
      "model.decoder.layers.8.encoder_attn.out_proj       | 0.997859   | 3.8749       | 6.6011%\n",
      "model.decoder.layers.8.fc1                         | 0.997531   | 6.6841       | 7.4182%\n",
      "model.decoder.layers.8.fc2                         | 0.997338   | 4.8945       | 7.7258%\n",
      "model.decoder.layers.9.self_attn.k_proj            | 0.998883   | 3.8073       | 4.7321%\n",
      "model.decoder.layers.9.self_attn.v_proj            | 0.996676   | 3.0803       | 8.2403%\n",
      "model.decoder.layers.9.self_attn.q_proj            | 0.998947   | 3.7893       | 4.5978%\n",
      "model.decoder.layers.9.self_attn.out_proj          | 0.994591   | 3.4512       | 10.5534%\n",
      "model.decoder.layers.9.encoder_attn.k_proj         | 0.999145   | 3.8969       | 4.1600%\n",
      "model.decoder.layers.9.encoder_attn.v_proj         | 0.997799   | 3.8953       | 6.7169%\n",
      "model.decoder.layers.9.encoder_attn.q_proj         | 0.999203   | 3.8463       | 4.0285%\n",
      "model.decoder.layers.9.encoder_attn.out_proj       | 0.997330   | 4.1798       | 7.3781%\n",
      "model.decoder.layers.9.fc1                         | 0.997533   | 6.6545       | 7.4985%\n",
      "model.decoder.layers.9.fc2                         | 0.997425   | 4.8104       | 7.5939%\n",
      "model.decoder.layers.10.self_attn.k_proj           | 0.998745   | 3.9287       | 5.0162%\n",
      "model.decoder.layers.10.self_attn.v_proj           | 0.996853   | 3.2908       | 7.9837%\n",
      "model.decoder.layers.10.self_attn.q_proj           | 0.998832   | 3.8487       | 4.8333%\n",
      "model.decoder.layers.10.self_attn.out_proj         | 0.995507   | 3.6729       | 9.5614%\n",
      "model.decoder.layers.10.encoder_attn.k_proj        | 0.999024   | 4.0954       | 4.4138%\n",
      "model.decoder.layers.10.encoder_attn.v_proj        | 0.998053   | 3.8886       | 6.2648%\n",
      "model.decoder.layers.10.encoder_attn.q_proj        | 0.999119   | 3.9845       | 4.2019%\n",
      "model.decoder.layers.10.encoder_attn.out_proj      | 0.997339   | 4.4707       | 7.3308%\n",
      "model.decoder.layers.10.fc1                        | 0.997408   | 6.4932       | 7.6209%\n",
      "model.decoder.layers.10.fc2                        | 0.997423   | 4.6835       | 7.6044%\n",
      "model.decoder.layers.11.self_attn.k_proj           | 0.998748   | 4.0771       | 5.0190%\n",
      "model.decoder.layers.11.self_attn.v_proj           | 0.996380   | 3.0151       | 8.5516%\n",
      "model.decoder.layers.11.self_attn.q_proj           | 0.998869   | 4.0527       | 4.7604%\n",
      "model.decoder.layers.11.self_attn.out_proj         | 0.996505   | 3.1544       | 8.3973%\n",
      "model.decoder.layers.11.encoder_attn.k_proj        | 0.999073   | 3.9669       | 4.3042%\n",
      "model.decoder.layers.11.encoder_attn.v_proj        | 0.998848   | 3.5003       | 4.9052%\n",
      "model.decoder.layers.11.encoder_attn.q_proj        | 0.999116   | 4.0757       | 4.2110%\n",
      "model.decoder.layers.11.encoder_attn.out_proj      | 0.998202   | 4.2008       | 6.1178%\n",
      "model.decoder.layers.11.fc1                        | 0.997404   | 6.0618       | 7.5436%\n",
      "model.decoder.layers.11.fc2                        | 0.996040   | 4.2453       | 9.1623%\n",
      "classification_head.out_proj                       | -0.017301   | 1.5867       | 142.6589%\n",
      "--------------------------------------------------------------------------------\n",
      "Summary Statistics:\n",
      "Average Cosine Similarity: 0.987776\n",
      "Average Relative Diff:     7.3708%\n",
      "Min Cosine Similarity:     -0.017301\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# 配置\n",
    "# ==========================================\n",
    "model_id_ft = \"facebook/bart-large-mnli\"   # Target (Private/Fine-tuned)\n",
    "model_id_base = \"facebook/bart-large\"      # Prior (Public/Base)\n",
    "device = \"cpu\"\n",
    "\n",
    "print(f\"Loading Fine-Tuned Model: {model_id_ft}...\")\n",
    "model_ft = AutoModelForSequenceClassification.from_pretrained(model_id_ft).to(device)\n",
    "\n",
    "print(f\"Loading Base Model: {model_id_base}...\")\n",
    "# 注意：bart-large 是基础模型，结构需要与 mnli 版本一致\n",
    "# AutoModelForSequenceClassification 会自动初始化分类头，\n",
    "# 但 backbone (encoder/decoder) 的参数应该能对应上。\n",
    "model_base = AutoModelForSequenceClassification.from_pretrained(model_id_base).to(device)\n",
    "\n",
    "print(\"\\nStarting Comparison (FT vs. Base)...\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Layer Name':<50} | {'Cos Sim':<10} | {'Delta Norm':<12} | {'Rel Diff (%)':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "results = []\n",
    "\n",
    "# 获取所有模块的字典\n",
    "modules_ft = dict(model_ft.named_modules())\n",
    "modules_base = dict(model_base.named_modules())\n",
    "\n",
    "# 遍历 FT 模型的层\n",
    "for name, module_ft in model_ft.named_modules():\n",
    "    if isinstance(module_ft, torch.nn.Linear):\n",
    "        # 确保 Base 模型中有同名层\n",
    "        if name in modules_base:\n",
    "            module_base = modules_base[name]\n",
    "            \n",
    "            # 获取权重 (Clone detached to avoid grad issues)\n",
    "            w_ft = module_ft.weight.detach()\n",
    "            w_base = module_base.weight.detach()\n",
    "            \n",
    "            # 检查形状是否一致 (分类头可能不一致)\n",
    "            if w_ft.shape != w_base.shape:\n",
    "                print(f\"[Skipping] {name}: Shapes mismatch {w_ft.shape} vs {w_base.shape} (Likely Classification Head)\")\n",
    "                continue\n",
    "                \n",
    "            # 1. 计算 Cosine Similarity\n",
    "            # Flatten 之后计算向量夹角\n",
    "            cos_sim = torch.nn.functional.cosine_similarity(\n",
    "                w_ft.flatten(), \n",
    "                w_base.flatten(), \n",
    "                dim=0\n",
    "            ).item()\n",
    "            \n",
    "            # 2. 计算 Delta (FT - Base)\n",
    "            delta = w_ft - w_base\n",
    "            norm_delta = torch.norm(delta).item()\n",
    "            \n",
    "            # 3. 计算 Base Norm\n",
    "            norm_base = torch.norm(w_base).item()\n",
    "            \n",
    "            # 4. 计算相对差异 (Relative Difference)\n",
    "            # diff / norm_base\n",
    "            rel_diff = norm_delta / norm_base if norm_base > 0 else 0.0\n",
    "            \n",
    "            # 打印部分层的结果 (为了展示整洁，可以每隔几层打印一次，或者打印所有)\n",
    "            # 这里打印所有 Encoder/Decoder 的投影层\n",
    "            if \"proj\" in name or \"fc\" in name:\n",
    "                print(f\"{name:<50} | {cos_sim:.6f}   | {norm_delta:.4f}       | {rel_diff*100:.4f}%\")\n",
    "            \n",
    "            results.append({\n",
    "                \"Layer\": name,\n",
    "                \"Cos_Sim\": cos_sim,\n",
    "                \"Delta_Norm\": norm_delta,\n",
    "                \"Base_Norm\": norm_base,\n",
    "                \"Rel_Diff\": rel_diff\n",
    "            })\n",
    "        else:\n",
    "            print(f\"[Missing] {name} not found in Base Model.\")\n",
    "\n",
    "# ==========================================\n",
    "# 统计摘要\n",
    "# ==========================================\n",
    "df = pd.DataFrame(results)\n",
    "print(\"-\" * 80)\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Average Cosine Similarity: {df['Cos_Sim'].mean():.6f}\")\n",
    "print(f\"Average Relative Diff:     {df['Rel_Diff'].mean()*100:.4f}%\")\n",
    "print(f\"Min Cosine Similarity:     {df['Cos_Sim'].min():.6f}\")\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf18c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading Base Model (Prior): facebook/bart-large...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Loading Obfuscated Checkpoint: /mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt...\n",
      "3. Loading Ground Truth (for validation): facebook/bart-large-mnli...\n",
      "\n",
      "==================================================\n",
      "STARTING FULL MODEL RECOVERY (Removing Top-16 Singular Components)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recovering Layers: 100%|████████████████████████████| 194/194 [01:12<00:00,  2.68it/s, Sim=0.0000, Err=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RECOVERY COMPLETE\n",
      "==================================================\n",
      "Total Layers Recovered: 194\n",
      "Average Cosine Similarity: 0.9796\n",
      "Average Relative Error:    0.1778\n",
      "Worst Layer Similarity:    0.0000\n",
      "\n",
      "[SUCCESS] 模型还原极其成功！基本等同于原始私有模型。\n",
      "\n",
      "Saving recovered model to /mnt/e/untitled folder/codebase/LoRO_attack/recovered_bart_model...\n",
      "Saved. You can now load this model with 'AutoModelForSequenceClassification.from_pretrained'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import os\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. 配置\n",
    "# ==========================================\n",
    "# 攻击者的目标：从 Obfuscated Checkpoint + Base Model 恢复出 Private Model\n",
    "base_model_id = \"facebook/bart-large\"       # 攻击者拥有的先验\n",
    "target_model_id = \"facebook/bart-large-mnli\"  # 仅用于验证攻击成功率 (GT)\n",
    "obfuscated_checkpoint = \"/mnt/e/untitled folder/codebase/LoRO_attack/loro_bart_obfuscated.pt\" # 您的混淆文件路径\n",
    "save_path_recovered = \"/mnt/e/untitled folder/codebase/LoRO_attack/recovered_bart_model\"    # 还原后的模型保存路径\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# SVD 攻击参数\n",
    "# 根据您的实验结果，Rank=16 效果很好。LoRO 默认 Rank=8，通常剔除稍多一点(比如 16 或 32)能更干净地去噪。\n",
    "REMOVE_RANK = 16 \n",
    "\n",
    "# ==========================================\n",
    "# 2. 模型加载\n",
    "# ==========================================\n",
    "print(f\"1. Loading Base Model (Prior): {base_model_id}...\")\n",
    "# 攻击者初始只有 Base 模型\n",
    "recovered_model = AutoModelForSequenceClassification.from_pretrained(base_model_id).to(device)\n",
    "\n",
    "print(f\"2. Loading Obfuscated Checkpoint: {obfuscated_checkpoint}...\")\n",
    "if not os.path.exists(obfuscated_checkpoint):\n",
    "    raise FileNotFoundError(\"混淆 Checkpoint 未找到，请检查路径。\")\n",
    "obfus_state_dict = torch.load(obfuscated_checkpoint, map_location=device)\n",
    "\n",
    "print(f\"3. Loading Ground Truth (for validation): {target_model_id}...\")\n",
    "gt_model = AutoModelForSequenceClassification.from_pretrained(target_model_id).to(device)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 执行全模型攻击\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"STARTING FULL MODEL RECOVERY (Removing Top-{REMOVE_RANK} Singular Components)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 用于统计恢复效果\n",
    "similarities = []\n",
    "relative_errors = []\n",
    "\n",
    "# 获取所有线性层\n",
    "# 我们遍历 recovered_model (即 base_model) 的模块，然后去 check state_dict 里有没有对应的混淆权重\n",
    "all_modules = list(recovered_model.named_modules())\n",
    "linear_layers = [(n, m) for n, m in all_modules if isinstance(m, nn.Linear)]\n",
    "\n",
    "progress_bar = tqdm(linear_layers, desc=\"Recovering Layers\")\n",
    "\n",
    "for name, module in progress_bar:\n",
    "    # 1. 获取 Base 权重 (Prior)\n",
    "    W_base = module.weight.detach()\n",
    "    \n",
    "    # 2. 获取 Obfuscated 权重 (Observation)\n",
    "    # LoRO 的 state_dict key 通常是 \"layer_name.obfus_linear.weight\"\n",
    "    obfus_key = f\"{name}.obfus_linear.weight\"\n",
    "    \n",
    "    # 如果找不到对应的 key，说明这一层可能没有被混淆（或者是分类头等特殊层）\n",
    "    # 但根据 LoRO 逻辑，Linear 层应该都被混淆了\n",
    "    if obfus_key not in obfus_state_dict:\n",
    "        # 尝试直接找 name.weight (有些层可能未被 LoRO 包装)\n",
    "        if f\"{name}.weight\" in obfus_state_dict:\n",
    "            # 如果没混淆，直接加载（或者攻击者认为这就是原样）\n",
    "            # 但这里我们假设攻击者不知道，只看混淆文件\n",
    "            continue\n",
    "        else:\n",
    "            # 可能是分类头，LoRO 有时也会混淆它。\n",
    "            # 如果 key 不匹配，跳过\n",
    "            continue\n",
    "            \n",
    "    W_obfus = obfus_state_dict[obfus_key].detach()\n",
    "    \n",
    "    # 3. 计算 Diff\n",
    "    # Diff = W_obfus - W_base\n",
    "    Diff = W_obfus - W_base\n",
    "    \n",
    "    # 4. SVD 攻击 (去噪)\n",
    "    # 使用 float32 进行 SVD 以保证精度\n",
    "    U, S, Vh = torch.linalg.svd(Diff.float(), full_matrices=False)\n",
    "    \n",
    "    # 剔除前 K 个奇异值 (认为它们是 LoRO 注入的低秩噪声)\n",
    "    S_clean = S.clone()\n",
    "    S_clean[:REMOVE_RANK] = 0.0\n",
    "    \n",
    "    # 重构 Delta\n",
    "    Delta_Recovered = (U @ torch.diag(S_clean) @ Vh).to(W_base.dtype)\n",
    "    \n",
    "    # 5. 恢复权重\n",
    "    # W_rec = W_base + Delta_rec\n",
    "    W_recovered = W_base + Delta_Recovered\n",
    "    \n",
    "    # 更新 recovered_model 的权重\n",
    "    module.weight.data = W_recovered\n",
    "    \n",
    "    # 处理 Bias (LoRO 代码中 Bias 是直接存储的，通常没有加噪声，或者加了也可以直接减)\n",
    "    # 检查 utils.py/loro.py: \"self.obfus_linear.bias = torch.nn.Parameter(original_linear.bias)\"\n",
    "    # Bias 没有加噪声！所以直接从 obfus_state_dict 读取即可（攻击者可以直接拿）\n",
    "    obfus_bias_key = f\"{name}.obfus_linear.bias\"\n",
    "    if obfus_bias_key in obfus_state_dict and module.bias is not None:\n",
    "        module.bias.data = obfus_state_dict[obfus_bias_key].detach()\n",
    "    \n",
    "    # 6. 验证 (与 GT 对比)\n",
    "    # 获取 GT 对应层的权重\n",
    "    # 注意：需通过 name 从 gt_model 索引\n",
    "    gt_module = dict(gt_model.named_modules())[name]\n",
    "    W_gt = gt_module.weight.detach()\n",
    "    \n",
    "    # 计算指标\n",
    "    # 真实的 Delta = W_gt - W_base\n",
    "    Delta_True = W_gt - W_base\n",
    "    \n",
    "    # 计算恢复出的 Delta 和 真实 Delta 的相似度\n",
    "    sim = torch.nn.functional.cosine_similarity(Delta_True.flatten(), Delta_Recovered.flatten(), dim=0).item()\n",
    "    rel_err = torch.norm(Delta_Recovered - Delta_True) / torch.norm(Delta_True)\n",
    "    \n",
    "    similarities.append(sim)\n",
    "    relative_errors.append(rel_err.item())\n",
    "    \n",
    "    # 更新进度条显示当前层的相似度\n",
    "    progress_bar.set_postfix({\"Sim\": f\"{sim:.4f}\", \"Err\": f\"{rel_err:.4f}\"})\n",
    "\n",
    "# ==========================================\n",
    "# 4. 结果汇总与保存\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RECOVERY COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "avg_sim = sum(similarities) / len(similarities)\n",
    "avg_err = sum(relative_errors) / len(relative_errors)\n",
    "min_sim = min(similarities)\n",
    "\n",
    "print(f\"Total Layers Recovered: {len(similarities)}\")\n",
    "print(f\"Average Cosine Similarity: {avg_sim:.4f}\")\n",
    "print(f\"Average Relative Error:    {avg_err:.4f}\")\n",
    "print(f\"Worst Layer Similarity:    {min_sim:.4f}\")\n",
    "\n",
    "if avg_sim > 0.95:\n",
    "    print(\"\\n[SUCCESS] 模型还原极其成功！基本等同于原始私有模型。\")\n",
    "else:\n",
    "    print(\"\\n[WARNING] 模型还原效果一般，可能需要调整 REMOVE_RANK 参数。\")\n",
    "\n",
    "# 保存模型\n",
    "print(f\"\\nSaving recovered model to {save_path_recovered}...\")\n",
    "recovered_model.save_pretrained(save_path_recovered)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n",
    "tokenizer.save_pretrained(save_path_recovered)\n",
    "print(\"Saved. You can now load this model with 'AutoModelForSequenceClassification.from_pretrained'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
